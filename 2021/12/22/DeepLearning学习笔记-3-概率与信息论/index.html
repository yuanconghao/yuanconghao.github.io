<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Just Do It"><title>DeepLearning-3.概率与信息论 | DeepLearner</title><link rel="stylesheet" type="text/css" href="../../../../css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="/static/css/normalize.css"><link rel="stylesheet" type="text/css" href="/static/css/pure-min.css"><link rel="stylesheet" type="text/css" href="/static/css/grids-responsive-min.css"><link rel="stylesheet" href="/static/css/font-awesome.min.css"><script type="text/javascript" src="/static/js/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="../../../../favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="../../../../favicon.ico"><link rel="apple-touch-icon" href="../../../../apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="../../../../apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="../../../../atom.xml"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-83251621-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + 'b207d9febf3295d375e6e9b42006f9eb';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/static/js/clipboard.min.js"></script><script type="text/javascript" src="/static/js/toastr.min.js"></script><link rel="stylesheet" href="/static/css/toastr.min.css"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">DeepLearning-3.概率与信息论</h1><a id="logo" href="../../../../.">DeepLearner</a><p class="description">Deep Learning Notes</p></div><div id="nav-menu"><a class="current" href="../../../../."><i class="fa fa-home"> 首页</i></a><a href="../../../../archives/"><i class="fa fa-archive"> 归档</i></a><a href="../../../../tagcloud/"><i class="fa fa-tags"> 标签</i></a><a href="../../../../resource/"><i class="fa fa-cloud"> 资源</i></a><a href="../../../../guestbook/"><i class="fa fa-wechat"> 留言</i></a><a href="../../../../codeline/"><i class="fa fa-circle"> 码迹</i></a><a href="../../../../resume/"><i class="fa fa-user"> 个人简历</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">DeepLearning-3.概率与信息论</h1><div class="post-meta">created:2021-12-22</div><div class="post-meta">updated:2023-07-30<span> | </span><span class="category"><a href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><a class="disqus-comment-count" href="#waline"><span class="waline-comment-count" id=""></span><span> 条评论</span></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8%E6%A6%82%E7%8E%87"><span class="toc-number">1.</span> <span class="toc-text">为什么要使用概率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F"><span class="toc-number">2.</span> <span class="toc-text">随机变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83"><span class="toc-number">3.</span> <span class="toc-text">概率分布</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E8%B4%A8%E9%87%8F%E5%87%BD%E6%95%B0"><span class="toc-number">3.1.</span> <span class="toc-text">概率质量函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0"><span class="toc-number">3.2.</span> <span class="toc-text">概率密度函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.3.</span> <span class="toc-text">代码实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%B9%E7%BC%98%E6%A6%82%E7%8E%87"><span class="toc-number">4.</span> <span class="toc-text">边缘概率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87"><span class="toc-number">5.</span> <span class="toc-text">条件概率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E7%9A%84%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99"><span class="toc-number">6.</span> <span class="toc-text">条件概率的链式法则</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8B%AC%E7%AB%8B%E6%80%A7%E5%92%8C%E6%9D%A1%E4%BB%B6%E7%8B%AC%E7%AB%8B%E6%80%A7"><span class="toc-number">7.</span> <span class="toc-text">独立性和条件独立性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%9F%E6%9C%9B%E3%80%81%E6%96%B9%E5%B7%AE%E5%92%8C%E5%8D%8F%E6%96%B9%E5%B7%AE"><span class="toc-number">8.</span> <span class="toc-text">期望、方差和协方差</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-1"><span class="toc-number">8.1.</span> <span class="toc-text">代码实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%8B%E5%8A%A8%E6%8E%A8%E7%AE%97"><span class="toc-number">8.2.</span> <span class="toc-text">手动推算</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83"><span class="toc-number">9.</span> <span class="toc-text">常用概率分布</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Bernoulli%E5%88%86%E5%B8%83"><span class="toc-number">9.1.</span> <span class="toc-text">Bernoulli分布</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-2"><span class="toc-number">9.2.</span> <span class="toc-text">代码实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%8B%E5%8A%A8%E6%8E%A8%E7%AE%97-1"><span class="toc-number">9.3.</span> <span class="toc-text">手动推算</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Multinoulli%E5%88%86%E5%B8%83"><span class="toc-number">9.4.</span> <span class="toc-text">Multinoulli分布</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-3"><span class="toc-number">9.5.</span> <span class="toc-text">代码实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%8B%E5%8A%A8%E6%8E%A8%E7%AE%97-2"><span class="toc-number">9.6.</span> <span class="toc-text">手动推算</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83"><span class="toc-number">9.7.</span> <span class="toc-text">高斯分布</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-4"><span class="toc-number">9.8.</span> <span class="toc-text">代码实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%8B%E5%8A%A8%E6%8E%A8%E7%AE%97-3"><span class="toc-number">9.9.</span> <span class="toc-text">手动推算</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%EF%BC%88%E5%A4%9A%E5%85%83%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%EF%BC%89"><span class="toc-number">9.10.</span> <span class="toc-text">多元高斯分布（多元正态分布）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-5"><span class="toc-number">9.11.</span> <span class="toc-text">代码实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%8B%E5%8A%A8%E6%8E%A8%E7%AE%97-4"><span class="toc-number">9.12.</span> <span class="toc-text">手动推算</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8C%87%E6%95%B0%E5%88%86%E5%B8%83"><span class="toc-number">9.13.</span> <span class="toc-text">指数分布</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-6"><span class="toc-number">9.14.</span> <span class="toc-text">代码实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%88%86%E5%B8%83"><span class="toc-number">9.15.</span> <span class="toc-text">拉普拉斯分布</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-7"><span class="toc-number">9.16.</span> <span class="toc-text">代码实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Dirac%E5%88%86%E5%B8%83%E5%92%8C%E7%BB%8F%E9%AA%8C%E5%88%86%E5%B8%83"><span class="toc-number">9.17.</span> <span class="toc-text">Dirac分布和经验分布</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%B7%E5%90%88%E5%88%86%E5%B8%83"><span class="toc-number">9.18.</span> <span class="toc-text">混合分布</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E7%9A%84%E6%9C%89%E7%94%A8%E6%80%A7%E8%B4%A8"><span class="toc-number">10.</span> <span class="toc-text">常用函数的有用性质</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Logistic-sigmoid%E5%87%BD%E6%95%B0"><span class="toc-number">10.1.</span> <span class="toc-text">Logistic sigmoid函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#softplus%E5%87%BD%E6%95%B0"><span class="toc-number">10.2.</span> <span class="toc-text">softplus函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-8"><span class="toc-number">10.3.</span> <span class="toc-text">代码实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-9"><span class="toc-number">10.4.</span> <span class="toc-text">代码实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E8%A7%84%E5%88%99"><span class="toc-number">11.</span> <span class="toc-text">贝叶斯规则</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E8%AE%BA"><span class="toc-number">12.</span> <span class="toc-text">信息论</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%84%E5%8C%96%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B"><span class="toc-number">13.</span> <span class="toc-text">结构化概率模型</span></a></li></ol></div></div><div class="post-content"><p>概率论用于表示不确定性声明的数学框架。人工智能领域，主要用于推理和统计分析AI系统行为。<br>概率论与统计学的区别，概率论和统计学解决的问题是可逆的。概率是已知模型和参数，推数据。统计是已知数据，推模型和参数。</p>
<span id="more"></span>

<h3 id="为什么要使用概率"><a href="#为什么要使用概率" class="headerlink" title="为什么要使用概率"></a>为什么要使用概率</h3><p>&emsp;&emsp;传统计算机编程，通过给CPU确定的指令，来完成相关工作。机器学习通常存在不确定量，如建模系统内在的随机性、不完全观测、不完全建模等，所以需要通过一种用于对不确定性进行表示和推理的方法，概率则可作为对不确定性的扩展逻辑，提供了一套形式化的规则，可在给定某些命题的真或假的假设下，判断另外一种命题是真还是假。</p>
<h3 id="随机变量"><a href="#随机变量" class="headerlink" title="随机变量"></a>随机变量</h3><p>&emsp;&emsp;<strong>随机变量 (Random Variable)</strong> :一个可能随机取不同值的变量。例如:抛掷一枚硬币，出现正面或者反面的结果。</p>
<h3 id="概率分布"><a href="#概率分布" class="headerlink" title="概率分布"></a>概率分布</h3><p>&emsp;&emsp;<strong>概率分布（Probability Distribution）</strong> 用来描述随机变量或一簇随机变量在每一个可能取到的状态的可能性大小。</p>
<h4 id="概率质量函数"><a href="#概率质量函数" class="headerlink" title="概率质量函数"></a>概率质量函数</h4><p>&emsp;&emsp;<strong>概率质量函数（Probability Mass Function,PMF）</strong> 常用于描述离散型变量的概率分布。通常用大写字母$P$表示，如$P(x)$,定义一个随机变量，用$\sim $符号来说明它遵循的分布：$x\sim P(x)$ 。</p>
<p>&emsp;&emsp;<strong>联合概率分布（Joint Probability Distribution）</strong> 常用于表示多个随机变量的概率分布，如$P(x,y)$，表示$x,y$同时发生的概率。</p>
<p>&emsp;&emsp;如果一个函数$P$是随机变量$x$的概率质量函数(PMF)，则必须满足以下条件：</p>
<ul>
<li>$P$的定义域必须是$x$所有可能状态的集合。</li>
<li>$\forall x\in X,0\leqslant P(x)\leqslant 1$ 。</li>
<li>归一化：$\sum_{x\in X}P(x)&#x3D;1$ 。</li>
</ul>
<h4 id="概率密度函数"><a href="#概率密度函数" class="headerlink" title="概率密度函数"></a>概率密度函数</h4><p>&emsp;&emsp;连续型随机变量用，<strong>概率密度函数（Probability Density Functino,PDF）</strong> 来描述它的概率分布，而不是概率质量函数。函数$p$是概率密度函数，必须满足以下条件：</p>
<ul>
<li>$p$的定义域必须是$x$所有可能状态的集合。</li>
<li>$\forall x\in X,p(x)\geqslant 0$ , 并不要求 $p(x)\leqslant 1$ 。</li>
<li>$\int p(x)d(x)&#x3D;1$ 。</li>
</ul>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> uniform</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成样本</span></span><br><span class="line">fix, ax = plt.subplots(<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">r = uniform.rvs(loc=<span class="number">0</span>, scale=<span class="number">1</span>, size=<span class="number">1000</span>)</span><br><span class="line">ax.hist(r, density=<span class="literal">True</span>, histtype=<span class="string">&#x27;stepfilled&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 均匀分布 pdf</span></span><br><span class="line">x = np.linspace(uniform.ppf(<span class="number">0.01</span>), uniform.ppf(<span class="number">0.99</span>), <span class="number">100</span>)</span><br><span class="line">ax.plot(x, uniform.pdf(x), <span class="string">&#x27;r-&#x27;</span>, lw=<span class="number">5</span>, alpha=<span class="number">0.8</span>, label=<span class="string">&#x27;uniform pdf&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output:</span></span><br></pre></td></tr></table></figure>

<p><img src="/images/uniform.png"></img></p>
<h3 id="边缘概率"><a href="#边缘概率" class="headerlink" title="边缘概率"></a>边缘概率</h3><p>&emsp;&emsp;一组变量的联合概率分布中的一个子集的概率分布称为<strong>边缘概率（Marginal Probability）</strong> 。例如：设离散型随机变量$x$和$y$，并且我们知道$P(x,y)$，可依据如下<strong>求和法则</strong>来计算$P(x)$:</p>
<center>$\forall x\in X,P(X=x)=\sum _{y}P(X=x,Y=y)$</center></br>

<p>&emsp;&emsp;连续型变量，可用积分替代求和：</p>
<center>$p(x)=\int p(x,y)dy$</center></br>

<h3 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h3><p>&emsp;&emsp;某个事件，在给定其他事件发生时出现的概率，这种概率称为<strong>条件概率（Conditional Probability）</strong> 。例如：我们给定$X&#x3D;x,Y&#x3D;y$发生的条件概率记为：$P(Y&#x3D;y \mid X&#x3D;x)$。计算公式：</p>
<center>$P(Y=y\mid X=x)=\frac{P(Y=y,X=x)}{P(X=x)}$</center></br>

<h3 id="条件概率的链式法则"><a href="#条件概率的链式法则" class="headerlink" title="条件概率的链式法则"></a>条件概率的链式法则</h3><p>&emsp;&emsp;任何多维随机变量的联合概率分布，都可以分解成为只有一个变量的条件概率相乘的形式：</p>
<center>$P(X^{(1)},...,X^{(n)})=P(X^{(1)})\prod ^{n}_{i=2}P(X^{(i)}\mid X^{(1)},...,X^{(i-1)})$</center></br>

<p>&emsp;&emsp;这个规则被称为概率的<strong>链式法则</strong> ，如：</p>
<center>$P(a,b,c)=P(a\mid b,c)P(b,c)$</center></br>
<center>$P(b,c)=P(b\mid c)P(c)$</center></br>
<center>$P(a,b,c)=P(a\mid b,c)P(b\mid c)P(c)$</center></br>

<h3 id="独立性和条件独立性"><a href="#独立性和条件独立性" class="headerlink" title="独立性和条件独立性"></a>独立性和条件独立性</h3><p>&emsp;&emsp;两个随机变量$x$和$y$，它们的概率分布可以表示成两个因子的乘积形式，并且一个因子只包含$x$，另一个因子只包含$y$，称这两个随机变量是<strong>相互独立的（Independent）</strong> ：</p>
<center>$\forall x\in X, \forall y \in Y, P(X=x,Y=y)=P(X=x)P(Y=y)$</center></br>

<p>&emsp;&emsp;如果关于$x$和$y$的条件概率分布对于$z$的每一个值都可以写成乘积形式，那么这两个随机变量$x$和$y$在给定随机变量$z$时是<strong>条件独立的（Conditionally Independent）</strong> ：</p>
<center>$\forall x\in X, \forall y \in Y, z\in X,P(X=x,Y=y \mid Z=z)=P(X=x\mid Z=z)P(Y=y\mid Z=z)$</center></br>

<h3 id="期望、方差和协方差"><a href="#期望、方差和协方差" class="headerlink" title="期望、方差和协方差"></a>期望、方差和协方差</h3><p>&emsp;&emsp;<strong>期望（Expectation）</strong> :当$x$由$P$产生，$f$作用于$x$时，$f(x)$的平均值。</p>
<p>&emsp;&emsp;<strong>离散型随机变量期望</strong> ：</p>
<center>$\mathbb{E}_{x\sim P[f(x)]}=\sum _{x}P(x)f(x)$</center></br>

<p>&emsp;&emsp;<strong>连续型随机变量期望</strong> ：</p>
<center>$\mathbb{E}_{x\sim p[f(x)]}=\int p(x)f(x)dx$</center></br

<p>&emsp;&emsp;<strong>方差（Variance）</strong> : 依据$x$进行采样时，用于衡量随机变量$x$的函数值呈现多大的差异：</p>
<center>$Var(f(x))=\mathbb{E}[(f(x)-\mathbb{E}[f(x)])^{2}]$</center></br>

<p>&emsp;&emsp;当方差很小时，$f(x)$的值形成的簇比较接近它们的期望值。方差的平方根称为<strong>标准差（Standard Deviation）</strong> 。</p>
<p>&emsp;&emsp;<strong>协方差（Covariance）</strong>  : 给出了两个变量线性相关性的强度以及这些变量的尺度：</p>
<center>$Cov(f(x),g(y))=\mathbb{E}[(f(x)-\mathbb{E}[f(x)])(g(y)-\mathbb{E}[g(y)])]$</center></br>

<h4 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>])</span><br><span class="line">y = np.array([<span class="number">9</span>,<span class="number">8</span>,<span class="number">7</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">Mean = np.mean(x) <span class="comment"># 平均值</span></span><br><span class="line">Var = np.var(x)   <span class="comment"># 默认总体方差</span></span><br><span class="line">Var_unbias = np.var(x, ddof=<span class="number">1</span>) <span class="comment"># 样本方差（无偏方差）</span></span><br><span class="line">Cov = np.cov(x,y) <span class="comment"># 协方差</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;平均值：&quot;</span>, Mean)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;默认方差：&quot;</span>, Var)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;样本方差：&quot;</span>, Var_unbias)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;协方差：\n&quot;</span>, Cov)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output </span></span><br><span class="line">平均值： <span class="number">5.0</span></span><br><span class="line">默认方差： <span class="number">6.666666666666667</span></span><br><span class="line">样本方差： <span class="number">7.5</span></span><br><span class="line">协方差：</span><br><span class="line"> [[ <span class="number">7.5</span> -<span class="number">7.5</span>]</span><br><span class="line"> [-<span class="number">7.5</span>  <span class="number">7.5</span>]]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_distribution</span>(<span class="params">X, axes=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 给定随机变量，绘制 PDF，PMF，CDF&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> axes <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line">    x_min, x_max = X.interval(<span class="number">0.99</span>) </span><br><span class="line">    x = np.linspace(x_min, x_max, <span class="number">1000</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">hasattr</span>(X.dist, <span class="string">&#x27;pdf&#x27;</span>): <span class="comment"># 判断有没有 pdf，即是不是连续分布</span></span><br><span class="line">        axes[<span class="number">0</span>].plot(x, X.pdf(x), label=<span class="string">&quot;PDF&quot;</span>)</span><br><span class="line">        axes[<span class="number">0</span>].fill_between(x, X.pdf(x), alpha=<span class="number">0.5</span>) <span class="comment"># alpha 是透明度，alpha=0 表示 100% 透明，alpha=100 表示完全不透明</span></span><br><span class="line">    <span class="keyword">else</span>: <span class="comment"># 离散分布</span></span><br><span class="line">        x_int = np.unique(x.astype(<span class="built_in">int</span>))</span><br><span class="line">        axes[<span class="number">0</span>].bar(x_int, X.pmf(x_int), label=<span class="string">&quot;PMF&quot;</span>) <span class="comment"># pmf 和 pdf 是类似的</span></span><br><span class="line">        axes[<span class="number">1</span>].plot(x, X.cdf(x), label=<span class="string">&quot;CDF&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> ax <span class="keyword">in</span> axes:</span><br><span class="line">        ax.legend()</span><br><span class="line">    <span class="keyword">return</span> axes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> bernoulli</span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">10</span>, <span class="number">3</span>)) <span class="comment"># 画布</span></span><br><span class="line">p = <span class="number">0.3</span></span><br><span class="line">X = bernoulli(p) <span class="comment"># 伯努利分布</span></span><br><span class="line">plot_distribution(X, axes=axes)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/pmf_cdf.png"></img></p>
<h4 id="手动推算"><a href="#手动推算" class="headerlink" title="手动推算"></a>手动推算</h4><h3 id="常用概率分布"><a href="#常用概率分布" class="headerlink" title="常用概率分布"></a>常用概率分布</h3><h4 id="Bernoulli分布"><a href="#Bernoulli分布" class="headerlink" title="Bernoulli分布"></a>Bernoulli分布</h4><p>&emsp;&emsp;伯努利分布（Bernoulli Distribution），是<strong>单个二值随机变量</strong>的分布，又叫两点分布。由单个参数$\phi \in\left [ 0,1 \right ]$控制，$phi$给出了随机变量等于1的概率。表示一次试验结果要么成功要么失败。具有如下性质：</p>
<ul>
<li>$P(x&#x3D;1)&#x3D;\phi$</li>
<li>$P(x&#x3D;1)&#x3D;1-\phi$</li>
<li>$P(X&#x3D;x)&#x3D;\phi ^{x}(1-\phi)^{1-x}$</li>
</ul>
<h4 id="代码实现-2"><a href="#代码实现-2" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 产生成功的概率</span></span><br><span class="line">possibility = <span class="number">0.3</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">trials</span>(<span class="params">n_samples</span>):</span><br><span class="line">    samples = np.random.binomial(n_samples, possibility) <span class="comment"># 成功的次数</span></span><br><span class="line">    proba_zero = (n_samples-samples)/n_samples</span><br><span class="line">    proba_one = samples/n_samples</span><br><span class="line">    <span class="keyword">return</span> [proba_zero, proba_one]</span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line"><span class="comment"># 一次试验， 伯努利分布</span></span><br><span class="line">n_samples = <span class="number">1</span></span><br><span class="line">axes[<span class="number">0</span>].bar([<span class="number">0</span>, <span class="number">1</span>], trials(n_samples), label=<span class="string">&quot;Bernoulli&quot;</span>)</span><br><span class="line"><span class="comment"># n 次试验， 二项分布</span></span><br><span class="line">n_samples = <span class="number">1000</span></span><br><span class="line">axes[<span class="number">1</span>].bar([<span class="number">0</span>, <span class="number">1</span>], trials(n_samples), label=<span class="string">&quot;Binomial&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> ax <span class="keyword">in</span> axes:</span><br><span class="line">    ax.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/bernoulli.png"></img></p>
<h4 id="手动推算-1"><a href="#手动推算-1" class="headerlink" title="手动推算"></a>手动推算</h4><h4 id="Multinoulli分布"><a href="#Multinoulli分布" class="headerlink" title="Multinoulli分布"></a>Multinoulli分布</h4><p>&emsp;&emsp;范畴分布（Multinoulli Distribution），是指在具有$k$个不同值的单个离散型随机变量上的分布，其中$k$是一个有限值。例如每次试验结果就可以记为一个$k$维的向量，只有此次试验的结果对应的维度记为1，其他记为0。公式：</p>
<center>$p(X=x)=\prod _{i} \phi _{i}^{x_{i}}$</center>

<h4 id="代码实现-3"><a href="#代码实现-3" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">k_possibilities</span>(<span class="params">k</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    随机产生一组 10 维概率向量</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    res = np.random.rand(k)</span><br><span class="line">    _<span class="built_in">sum</span> = <span class="built_in">sum</span>(res)</span><br><span class="line">    <span class="keyword">for</span> i, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(res):</span><br><span class="line">        res[i] = x / _<span class="built_in">sum</span></span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">10</span>, <span class="number">3</span>)) <span class="comment"># 一次试验， 范畴分布</span></span><br><span class="line">k, n_samples = <span class="number">10</span>, <span class="number">1</span></span><br><span class="line">samples = np.random.multinomial(n_samples, k_possibilities(k)) <span class="comment"># 各维度“成功”的次数</span></span><br><span class="line">axes[<span class="number">0</span>].bar(<span class="built_in">range</span>(<span class="built_in">len</span>(samples)), samples/n_samples, label=<span class="string">&quot;Multinoulli&quot;</span>)</span><br><span class="line">n_samples = <span class="number">1000</span> <span class="comment"># n 次试验， 多项分布</span></span><br><span class="line">samples = np.random.multinomial(n_samples, k_possibilities(k))</span><br><span class="line">axes[<span class="number">1</span>].bar(<span class="built_in">range</span>(<span class="built_in">len</span>(samples)), samples/n_samples, label=<span class="string">&quot;Multinomial&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> ax <span class="keyword">in</span> axes:</span><br><span class="line">    ax.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/random.png"></img></p>
<h4 id="手动推算-2"><a href="#手动推算-2" class="headerlink" title="手动推算"></a>手动推算</h4><h4 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a>高斯分布</h4><p>&emsp;&emsp;高斯分布（Gaussian Distribution），实数上常用最常用的分布，又称正态分布（Normal Distribution）:</p>
<center>$N(x;\mu ,\sigma ^{2})=\sqrt{\frac{1}{2\pi \sigma ^{2}}}exp \left (-\frac{1}{2}\beta (x-\mu)^{2} \right )$ </center>

<p>&emsp;&emsp;正态分布由两个参数控制，$\mu \in \mathbb{R}$和$\sigma \in (0,\propto )$。参数$\mu$给出了中心峰值的坐标，也是分布的均值。分布的标准差用$\sigma$表示，方差用$\sigma ^{2}$表示。当需要对概率密度函数求值时，需要对$\sigma$平方并且取倒数，$\beta &#x3D; \frac{1}{\sigma ^{2}}$。如下图所示：</p>
<p><img src="/images/normal_dis.png"></img></p>
<p>&emsp;&emsp;其中$\mu&#x3D;1,\sigma&#x3D;1$ 称为<strong>标准正态分布</strong>。</p>
<p>&emsp;&emsp;中心极限定理说明很多独立随机变量的和近似服从正态分布，因此可认为噪声是属于正态分布的。</p>
<h4 id="代码实现-4"><a href="#代码实现-4" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">10</span>, <span class="number">3</span>)) <span class="comment"># 画布</span></span><br><span class="line">mu, sigma = <span class="number">0</span>, <span class="number">1</span> </span><br><span class="line">X = norm(mu, sigma) <span class="comment"># 标准正态分布</span></span><br><span class="line">plot_distribution(X, axes=axes)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/pdf_cdf.png"></img></p>
<h4 id="手动推算-3"><a href="#手动推算-3" class="headerlink" title="手动推算"></a>手动推算</h4><h4 id="多元高斯分布（多元正态分布）"><a href="#多元高斯分布（多元正态分布）" class="headerlink" title="多元高斯分布（多元正态分布）"></a>多元高斯分布（多元正态分布）</h4><p>&emsp;&emsp;正态分布可以推广到$\mathbb{R}^{n}$空间，这种情况被称为<strong>多维正态分布</strong> ，形式如下：</p>
<center>$N(x;\mu,\Sigma )=\sqrt{\frac{1}{(2\pi)^{n}det(\Sigma)}}exp \left (-\frac{1}{2}(x-\mu)^{\top} \Sigma^{-1}(x-\mu)\right )$</center>

<p>&emsp;&emsp;对概率密度函数求值时，对$\Sigma$求逆，可使用一个精度矩阵$\beta$进行替代。$\beta&#x3D;\frac{1}{\Sigma}$ 。</p>
<h4 id="代码实现-5"><a href="#代码实现-5" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> multivariate_normal</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">x, y = np.mgrid[-<span class="number">1</span>:<span class="number">1</span>:<span class="number">.01</span>, -<span class="number">1</span>:<span class="number">1</span>:<span class="number">.01</span>]</span><br><span class="line">pos = np.dstack((x, y))</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">4</span>,<span class="number">4</span>))</span><br><span class="line">axes = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">mu = [<span class="number">0.5</span>, -<span class="number">0.2</span>] <span class="comment"># 均值</span></span><br><span class="line">sigma = [[<span class="number">2.0</span>, <span class="number">0.3</span>], [<span class="number">0.3</span>, <span class="number">0.5</span>]] <span class="comment"># 协方差矩阵</span></span><br><span class="line">X = multivariate_normal(mu, sigma)</span><br><span class="line">axes.contourf(x, y, X.pdf(pos))</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/mul_normal.png"></img></p>
<h4 id="手动推算-4"><a href="#手动推算-4" class="headerlink" title="手动推算"></a>手动推算</h4><h4 id="指数分布"><a href="#指数分布" class="headerlink" title="指数分布"></a>指数分布</h4><p>&emsp;&emsp;指数分布（Exponential Distribution），形式如下：</p>
<center>$p(x;\lambda )=\lambda 1_{x\geqslant 0}exp(-\lambda x)$</center>

<p>&emsp;&emsp;用于在$x&#x3D;0$处取得临界点的分布，其中$\lambda &gt; 0$是分布的一个参数，常被称为率参数。</p>
<h4 id="代码实现-6"><a href="#代码实现-6" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> expon</span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line"><span class="comment"># 定义 scale = 1 / lambda</span></span><br><span class="line">X = expon(scale=<span class="number">1</span>)</span><br><span class="line">plot_distribution(X, axes=axes)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/expon.png"></img></p>
<h4 id="拉普拉斯分布"><a href="#拉普拉斯分布" class="headerlink" title="拉普拉斯分布"></a>拉普拉斯分布</h4><p>&emsp;&emsp;拉普拉斯分布（Laplace Distribution），形式如下：</p>
<center>$Laplace(x;\mu , \gamma )=\frac{1}{2\gamma}exp\left ( -\frac{\left|x-\mu \right|}{\gamma } \right )$</center>

<p>&emsp;&emsp;允许在任意一个点$\mu$处设置概率质量峰值。</p>
<h4 id="代码实现-7"><a href="#代码实现-7" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> laplace</span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line">mu, gamma = <span class="number">0</span>, <span class="number">1</span> </span><br><span class="line">X = laplace(loc=mu, scale=gamma)</span><br><span class="line">plot_distribution(X, axes=axes)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/laplace.png"></img></p>
<h4 id="Dirac分布和经验分布"><a href="#Dirac分布和经验分布" class="headerlink" title="Dirac分布和经验分布"></a>Dirac分布和经验分布</h4><p>&emsp;&emsp;Dirac delta函数定义概率密度函数来实现：$p(x)&#x3D;\delta (x-\mu)$ ，被定义成除了0以外的所有点的值都为0，但积分为1，是一个泛函数。常用于组成<strong>经验分布（Empirical Distribution）</strong> ：</p>
<center>$\hat{p}(x)=\frac{1}{m}\sum_{m}^{i=1}\delta (x-x^{(i)})$</center>

<h4 id="混合分布"><a href="#混合分布" class="headerlink" title="混合分布"></a>混合分布</h4><p>&emsp;&emsp;混合分布（Mixture Distribution），通过组合一些简单的概率分布来定义新的概率分布。</p>
<h3 id="常用函数的有用性质"><a href="#常用函数的有用性质" class="headerlink" title="常用函数的有用性质"></a>常用函数的有用性质</h3><p>&emsp;&emsp;深度学习模型中常用到的概率分布。</p>
<h4 id="Logistic-sigmoid函数"><a href="#Logistic-sigmoid函数" class="headerlink" title="Logistic sigmoid函数"></a>Logistic sigmoid函数</h4><p>&emsp;&emsp;<strong>logistic sigmoid函数</strong>通常用来产生Bernoulli分布中的参数$\phi$ ，因为它的范围是$(0,1)$ ，在$\phi$的有效取值范围内。形式如下：</p>
<center>$\sigma(x)=\frac{1}{1+exp(-x)}$</center>

<p>&emsp;&emsp;下图给出了sigmoid函数的图示，sigmoid函数在变量取绝对值非常大的正值或负值时会出现<strong>饱和（saturate）</strong>现象，意味着函数会变得很平，并且对输入的微小改变会变得不敏感。</p>
<h4 id="softplus函数"><a href="#softplus函数" class="headerlink" title="softplus函数"></a>softplus函数</h4><p>&emsp;&emsp;<strong>softplus函数</strong> :</p>
<center>$\xi=log(1+exp(x))$</center>

<p>可以用来产生正态分布的$\beta$和$\alpha$参数，它的范围是$(0,\propto )$。当处理包含sigmoid函数的表达式时它也经常出现。softplus函数名来源于它是另外一个函数的平滑形式，函数如下：</p>
<center>$x^{+}=max(0,x)$</center>

<p>&emsp;&emsp;函数的一些性质如下：</p>
<ul>
<li><font color="#ff0000">$\sigma(x)&#x3D;\frac{exp(x)}{exp(x)+exp(0)}$</font></li>
<li><font color="#ff0000">$\frac{d}{dx}\sigma (x)&#x3D;\sigma(x)(1-\sigma(x))$</font></li>
<li><font color="#ff0000">$1-\sigma(x)&#x3D;\sigma(-x)$</font></li>
<li><font color="#ff0000">$log\sigma(x)&#x3D;-\xi (-x)$</font></li>
<li><font color="#ff0000">$\frac{d}{dx}\xi (x)&#x3D;\sigma (x)$</font></li>
<li><font color="#ff0000">$\sigma ^{-1}(x)&#x3D;log\left ( \frac{x}{1-x} \right ),\forall x\in (0,1)$</font></li>
<li><font color="#ff0000">$\xi ^{-1}(x)&#x3D;log(exp(x)-1),\forall x&gt;0$</font></li>
<li><font color="#ff0000">$\xi (x)&#x3D;\int_{-\propto }^{x}\sigma (y)dy$</font></li>
<li><font color="#ff0000">$\xi (x)-\xi (-x)&#x3D;x$</font></li>
</ul>
<p>&emsp;&emsp;softplus函数被设计成<strong>正部函数</strong> ，$x^{+}&#x3D;max{0,x}$ 和 <strong>负部函数</strong> ，$x^{-}&#x3D;max(0,-x)$ 。</p>
<p>&emsp;&emsp;函数的图示如下：</p>
<h4 id="代码实现-8"><a href="#代码实现-8" class="headerlink" title="代码实现"></a>代码实现</h4><h4 id="代码实现-9"><a href="#代码实现-9" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = np.linspace(-<span class="number">10</span>, <span class="number">10</span>, <span class="number">100</span>)</span><br><span class="line">sigmoid = <span class="number">1</span>/(<span class="number">1</span> + np.exp(-x))</span><br><span class="line">softplus = np.log(<span class="number">1</span> + np.exp(x))</span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line">axes[<span class="number">0</span>].plot(x, sigmoid, label=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">axes[<span class="number">1</span>].plot(x, softplus, label=<span class="string">&#x27;softplus&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> ax <span class="keyword">in</span> axes:</span><br><span class="line">    ax.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/sigmoid.png"></img></p>
<h3 id="贝叶斯规则"><a href="#贝叶斯规则" class="headerlink" title="贝叶斯规则"></a>贝叶斯规则</h3><p>&emsp;&emsp;贝叶斯规则（Bayes rule），在已知$P(y\mid x)$时计算$P(x\mid y)$，计算公式如下：</p>
<center>$P(x\mid y)=\frac{P(x)P(y\mid x)}{P(y)}$</center> 


<h3 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h3><p>&emsp;&emsp;<strong>信息论</strong>是应用数学的一个分支，主要研究的是对一个信号包含信息的多少进行量化。<strong>信息论背后的思想：</strong>一件不太可能的事件比一件比较可能的事件更有信息量。</p>
<p>&emsp;&emsp;<strong>信息（Information）</strong>需要满足三个条件：</p>
<ul>
<li>非常可能发生的事件信息量比较少。</li>
<li>较不可能发生的事件具有更高的信息量。</li>
<li>独立事件应具有增量的信息。</li>
</ul>
<p>&emsp;&emsp;<strong>自信息（Self-Information）</strong> ：对事件$X&#x3D;x$，定义：</p>
<center>$I(x)=-logP(x)$</center>

<p>&emsp;&emsp;$log$为底为$e$的自然对数；$I(x)$单位为<strong>奈特（nats）</strong> 。</p>
<p>&emsp;&emsp;<strong>香农熵（Shannon Entropy）</strong> ：自信息只包含一个事件的信息，而对于<strong>整个概率分布中的不确定性总量</strong>可用香农熵进行量化：</p>
<center>$H(x)=\mathbb{E}_{X\sim P}\left [ I(x) \right ]=-\mathbb{E}_{X\sim P}\left [ logP(x) \right ]$</center>

<p>&emsp;&emsp;一个分布的香农熵是指这个分布的事件所产生的期望信息总量。香农熵是编码原理中最优编码长度。</p>
<h3 id="结构化概率模型"><a href="#结构化概率模型" class="headerlink" title="结构化概率模型"></a>结构化概率模型</h3></div><script type="text/javascript" src="../../../../js/share.js?v=1.0.0" async></script><a class="article-share-link" data-url="https://deeplearner.top/2021/12/22/DeepLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-3-%E6%A6%82%E7%8E%87%E4%B8%8E%E4%BF%A1%E6%81%AF%E8%AE%BA/" data-id="clkor69p1003sc6s6hc9w675h" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASYAAAEmCAAAAADqr2IGAAAEiElEQVR42u3a0U7kMAwFUP7/p2elfUJaGO61yzIpp09V6TTJCZJjJ29v8fX4e72/f//k3+f/vvP8/eQLn/XnsyfPW3n7jgsTJkyYML0k0+Pp9dk7LWjSufzLz/ufvJ+PHRMmTJgw3YOpXQQkf33+vI25LfTzhUs+dkyYMGHC9HuY8rCdgCaJ8Wba2l9hwoQJEyZMm3LqJsC3iG1KjwkTJkyYfgNT/rk22CfQ+03QTSH44lo4JkyYMGF6MabZwZ173H/7+SZMmDBhwvSjTI/yakuueYeSttr0Nd9q/WLUmDBhwoTpWKY27dwXWFvEzZuz9VFRIcCECRMmTIcwteEzWRbkKPlSYMPUlp4xYcKECdM9mJIBJINJupKkynkquzms034HEyZMmDCdyzRDyVPiTQk4L7/O0vU21mPChAkTpnOZ8mG0iWieEucp66wYPWt3ONuYMGHChOkQposPvsTl3Vmw37dVl3oxYcKECdPLMyWDbwuj7RZm3vos5M8qAR/UwjFhwoQJ04FM+atterzZEP0/W5Xt1ikmTJgwYTqRqd0yzJPSJJzPpmc21FVxGRMmTJgw3Y6pbWBz4GYGujkG1H4ZEyZMmDDdiSkv2s4O97Tl3XZ4s0T9i+9jwoQJE6ZbMLWJ5SbhTAJ/MuA6iQ1S7i9SX0yYMGHCdCDTZhjXHpTJN0Hbidyk3JgwYcKE6VymvCzbDrtdNMwS5pz+gunEhAkTJkwHMuUd3Ww3tigtdL7VOhwRJkyYMGE6likJ55u0c38kKFkK7CcsSo8xYcKECdNNmfL7GWJb5J0VjttxFWsTTJgwYcL08kz7wJkPr922zFmvSpK/gMOECRMmTEcx7YuheRf3BeXZRG6K1JgwYcKE6U5MVx2aueqgT447WwoUxWVMmDBhwnQs06zT7YIgbyUv7LZPZhucq7nFhAkTJkwvwNSGxs1S4BFcs6XAsKodJ+qYMGHChOkeTNeWTfMJ2CwCZhNQb5FiwoQJE6ZjmYqgWDazP46TJ8P5ZmrST0yYMGHC9NuYZgF7Vm8edjcO8JslCyZMmDBhuhNT23AeyPcHg9rt0vab+cRgwoQJE6bXZ9oEwnbTMQ/GLesMpUiGMWHChAnTsUz7bchZM7P398uRy1JuTJgwYcJ0FFMbYhPK2cZh0t3ZQiE/3FNUAjBhwoQJ07FMs2Hk4X+24Jil0G1p+NPfYsKECROmA5na0N6G5zyxzJcOeYBPfhs9wYQJEyZMt2DKD9zMCr5XFWRnPZxNPyZMmDBhOp1plo62H41KqKMEtV2UtK28tbOECRMmTJhejOlRXpvEdb8tmk/b5l/hg79iwoQJE6ZjmWYh+dqjNvn9vlftPSZMmDBhugdTuwiYhfl9kM6T4WQxUS8yMGHChAnT4UxtwG63HjeF16SInMMlbRU1YEyYMGHCdCOmWUc35df2+M5VU/7BdzBhwoQJ069h2iST+1Q533Zty9bR8R1MmDBhwnQs0wZicwRnVg7eb4smxJfVwjFhwoQJ048yteHzqgFsUty2RJuj1DSYMGHChOl1mf4AZrLx8+tJ7soAAAAASUVORK5CYII=">分享</a><div class="tags"><a href="../../../../tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><i class="fa fa-tag"></i>深度学习笔记</a><a href="../../../../tags/%E8%8A%B1%E4%B9%A6/"><i class="fa fa-tag"></i>花书</a></div><div class="post-nav"><a class="pre" href="../../../../2022/01/04/DeepLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-4-%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/">DeepLearning-4.数值计算</a><a class="next" href="../../09/DeepLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-2-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">DeepLearning-2.线性代数</a></div><div class="nofancybox" id="waline"></div><script src="//unpkg.com/@waline/client@v2/dist/waline.js"></script><link rel="stylesheet" type="text/css" href="//unpkg.com/@waline/client@v2/dist/waline.css"><script>let metaInfo = ['nick', 'mail', 'link']
let requiredMeta = 'nick'.split(',').filter(item => {
  return metaInfo.indexOf(item) > -1
})
Waline.init({
  el: '#waline',
  comment: true,
  serverURL: 'https://waline-deeplearner.vercel.app',
  pageSize: '10',
  wordLimit: '500',
  requiredMeta,
})
</script></div></div></div><div class="pure-u-1 pure-u-md-1-4"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/images/blog/avatar_new.png"/></a><p>心外无物，知行合一</p><a class="info-icon" href="/resume/" title="个人简历" target="_blank" style="margin-inline:5px"> <i class="fa fa-share-square" style="margin-inline:5px"></i></a><a class="info-icon" href="mailto:conghaoyuan@gmail.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/conghaoyuan" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a><a class="info-icon" href="/atom.xml" title="RSS" target="_blank" style="margin-inline:5px"> <i class="fa fa-rss-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/AIGC/">AIGC</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Algorithm/">Algorithm</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/CV/">CV</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/GUI/">GUI</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/NLP/">NLP</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Python/">Python</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E5%AD%97%E4%BA%BA/">数字人</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E5%AD%A6/">数学</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/">深度学习框架</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B/">深度学习模型</a><span class="category-list-count">11</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="../../../../2025/03/06/AIGC-LLM-%E8%BE%9F%E9%82%AA%E5%89%91%E8%B0%B1%E4%B9%8BPrompt%20Engineering/">AIGC-LLM-辟邪剑谱之Prompt Engineering</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/11/18/AIGC-Agent-%E4%BD%9C%E6%96%87%E6%89%B9%E6%94%B9%E6%A0%87%E6%B3%A8/">AIGC-Agent-作文批改标注</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/09/27/LLama32%E8%B0%83%E7%A0%94/">LLama3.2调研报告</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/04/09/AIGC-LLM-Prompt%E6%8A%80%E8%83%BD/">AIGC-LLM-Prompt工程技能综述</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/03/05/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-BERT/">Deeeplearning模型-NLP-BERT</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/01/16/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E8%AF%AD%E6%96%99%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7/">Deeeplearning模型-NLP-大语言模型微调语料生成工具</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/12/05/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-Transformer%E6%A8%A1%E5%9E%8B/">Deeeplearning模型-NLP-Transformer模型</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/12/01/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-NLP%E5%9F%BA%E7%A1%80/">Deeeplearning模型-NLP-NLP基础</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/10/26/%E6%95%B0%E5%AD%97%E4%BA%BA-%E6%95%B0%E5%AD%97%E4%BA%BA%E6%8A%80%E6%9C%AF%E6%95%88%E6%9E%9C%E5%AF%B9%E6%AF%94/">数字人-数字人技术效果对比</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/09/15/AIGC-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83-LLama2-Lora%E5%8C%BB%E5%AD%A6%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%832/">AIGC-大模型微调-LLama2-Lora医学大模型微调【风格学习】</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://conghaoyuan.github.io" title="Fern[个人早期博客]" target="_blank">Fern[个人早期博客]</a></div><div class="widget"><div class="widget-title"><i class="fa fa-star"> 天文学</i></div><ul></ul><a href="/tools/tianwenli.html" title="天文历" target="_self">天文历</a></div><div class="widget"><div class="widget-title"><i class="fa fa-plus"> 数学小工具</i></div><ul></ul><a href="/tools/buy_house.html" title="丐版买房计算器" target="_self">丐版买房计算器</a><ul></ul><a href="/tools/equation_12.html" title="一元二次方程" target="_self">一元二次方程</a><ul></ul><a href="/tools/equation_line.html" title="直线方程" target="_self">直线方程</a><ul></ul><a href="/tools/equation_polynomial.html" title="多项式方程" target="_self">多项式方程</a><ul></ul><a href="/tools/regression_ridge.html" title="岭回归" target="_self">岭回归</a><ul></ul><a href="/tools/fourier_transform.html" title="傅里叶变换" target="_self">傅里叶变换</a><ul></ul><a href="/tools/gradient_descent.html" title="梯度下降" target="_self">梯度下降</a><ul></ul><a href="/tools/function_e.html" title="指数函数" target="_self">指数函数</a><ul></ul><a href="/tools/function_inverse_scale.html" title="反比例函数" target="_self">反比例函数</a><ul></ul><a href="/tools/function_log.html" title="对数函数" target="_self">对数函数</a><ul></ul><a href="/tools/function_sin.html" title="正弦函数" target="_self">正弦函数</a><ul></ul><a href="/tools/coord_grid.html" title="网格化坐标" target="_self">网格化坐标</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="../../../../." rel="nofollow">DeepLearner.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="../../../../js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="../../../../js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="../../../../css/search.css?v=1.0.0"><script type="text/javascript" src="../../../../js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="/static/js/MathJax.js?config=TeX-MML-AM_CHTML" async></script><div id="script" type="text/javascript" src="../../../../js/mathjaxs.js" async></div><script type="text/javascript" src="../../../../js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="../../../../js/smartresize.js?v=1.0.0"></script></div><!-- hexo injector body_end start -->
<script src="assets/prism-bundle.js"></script>
<script src="assets/prism-plus.js" data-pjax=""></script>
<!-- hexo injector body_end end --></body></html>