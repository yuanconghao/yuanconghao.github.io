<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Just Do It"><title>MachineLearning-11.聚类 | DeepLearner</title><link rel="stylesheet" type="text/css" href="../../../../css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="/static/css/normalize.css"><link rel="stylesheet" type="text/css" href="/static/css/pure-min.css"><link rel="stylesheet" type="text/css" href="/static/css/grids-responsive-min.css"><link rel="stylesheet" href="/static/css/font-awesome.min.css"><script type="text/javascript" src="/static/js/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="../../../../favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="../../../../favicon.ico"><link rel="apple-touch-icon" href="../../../../apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="../../../../apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="../../../../atom.xml"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-83251621-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + 'b207d9febf3295d375e6e9b42006f9eb';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/static/js/clipboard.min.js"></script><script type="text/javascript" src="/static/js/toastr.min.js"></script><link rel="stylesheet" href="/static/css/toastr.min.css"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">MachineLearning-11.聚类</h1><a id="logo" href="../../../../.">DeepLearner</a><p class="description">Deep Learning Notes</p></div><div id="nav-menu"><a class="current" href="../../../../."><i class="fa fa-home"> 首页</i></a><a href="../../../../archives/"><i class="fa fa-archive"> 归档</i></a><a href="../../../../tagcloud/"><i class="fa fa-tags"> 标签</i></a><a href="../../../../resource/"><i class="fa fa-cloud"> 资源</i></a><a href="../../../../guestbook/"><i class="fa fa-wechat"> 留言</i></a><a href="../../../../codeline/"><i class="fa fa-circle"> 码迹</i></a><a href="../../../../resume/"><i class="fa fa-user"> 个人简历</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">MachineLearning-11.聚类</h1><div class="post-meta">created:2022-11-03</div><div class="post-meta">updated:2023-07-30<span> | </span><span class="category"><a href="../../../../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><a class="disqus-comment-count" href="#waline"><span class="waline-comment-count" id=""></span><span> 条评论</span></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E6%A6%82%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text">相关概述</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%B8%E4%BC%BC%E5%BA%A6%E5%BA%A6%E9%87%8F%E6%96%B9%E5%BC%8F"><span class="toc-number">1.1.</span> <span class="toc-text">相似度度量方式</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%AC%A7%E6%B0%8F%E8%B7%9D%E7%A6%BB"><span class="toc-number">1.1.1.</span> <span class="toc-text">欧氏距离</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9B%BC%E5%93%88%E9%A1%BF%E8%B7%9D%E7%A6%BB"><span class="toc-number">1.1.2.</span> <span class="toc-text">曼哈顿距离</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%97%B5%E5%8F%AF%E5%A4%AB%E6%96%AF%E5%9F%BA%E8%B7%9D%E7%A6%BB"><span class="toc-number">1.1.3.</span> <span class="toc-text">闵可夫斯基距离</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B7%9D%E7%A6%BB%E7%9A%84%E6%80%A7%E8%B4%A8"><span class="toc-number">1.1.4.</span> <span class="toc-text">距离的性质</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E7%9A%84%E5%88%92%E5%88%86"><span class="toc-number">1.2.</span> <span class="toc-text">聚类算法的划分</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8E%9F%E5%9E%8B%E8%81%9A%E7%B1%BB"><span class="toc-number">1.2.1.</span> <span class="toc-text">原型聚类</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AF%86%E5%BA%A6%E8%81%9A%E7%B1%BB"><span class="toc-number">1.2.2.</span> <span class="toc-text">密度聚类</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BB"><span class="toc-number">1.2.3.</span> <span class="toc-text">层次聚类</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">常用聚类算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#K%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB"><span class="toc-number">2.1.</span> <span class="toc-text">K均值聚类</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89"><span class="toc-number">2.1.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.1.2.</span> <span class="toc-text">实现</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%89%B9%E7%82%B9%E5%8F%8A%E4%BD%BF%E7%94%A8"><span class="toc-number">2.1.3.</span> <span class="toc-text">特点及使用</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%99%AA%E5%A3%B0%E5%AF%86%E5%BA%A6"><span class="toc-number">2.2.</span> <span class="toc-text">噪声密度</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-1"><span class="toc-number">2.2.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%91%A1-%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.2.2.</span> <span class="toc-text">② 实现</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%89%B9%E7%82%B9%E5%8F%8A%E4%BD%BF%E7%94%A8-1"><span class="toc-number">2.2.3.</span> <span class="toc-text">特点及使用</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%87%9D%E8%81%9A%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BB"><span class="toc-number">2.3.</span> <span class="toc-text">凝聚层次聚类</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-2"><span class="toc-number">2.3.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0-1"><span class="toc-number">2.3.2.</span> <span class="toc-text">实现</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%89%B9%E7%82%B9%E5%8F%8A%E4%BD%BF%E7%94%A8-2"><span class="toc-number">2.3.3.</span> <span class="toc-text">特点及使用</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB%E7%9A%84%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="toc-number">3.</span> <span class="toc-text">聚类的评价指标</span></a></li></ol></div></div><div class="post-content"><p>聚类（cluster）属于无监督学习；聚类是根据数据的特征，将相似度最高的样本划分到一个聚簇中；相似度的度量方式有，曼哈顿距离、欧式距离、切比雪夫距离，都可以用闵式距离公式表示；聚类算法包括：基于原型聚类，如k-means算法；基于密度聚类，如DBSCAN算法；基金层次聚类，如凝聚算法。评价指标采用轮廓系数。</p>
<span id="more"></span>

<h3 id="相关概述"><a href="#相关概述" class="headerlink" title="相关概述"></a>相关概述</h3><p>聚类（cluster）与分类（class）问题不同，聚类是属于无监督学习模型，而分类属于有监督学习。聚类使用一些算法把样本分为N个群落，群落内部相似度较高，群落之间相似度较低。在机器学习中，通常采用“距离”来度量样本间的相似度，距离越小，相似度越高；距离越大，相似度越低.</p>
<h4 id="相似度度量方式"><a href="#相似度度量方式" class="headerlink" title="相似度度量方式"></a>相似度度量方式</h4><h5 id="欧氏距离"><a href="#欧氏距离" class="headerlink" title="欧氏距离"></a>欧氏距离</h5><p>相似度使用欧氏距离来进行度量. 坐标轴上两点$x_1, x_2$之间的欧式距离可以表示为：<br>$$<br>|x_1-x_2| &#x3D; \sqrt{(x_1-x_2)^2}<br>$$<br>平面坐标中两点$(x_1, y_1), (x_2, y_2)$欧式距离可表示为：<br>$$<br>|(x_1,y_1)-(x_2, y_2)| &#x3D; \sqrt{(x_1-x_2)^2+(y_1-y_2)^2}<br>$$<br>三维坐标系中$(x_1, y_1, z_1), (x_2, y_2, z_2)$欧式距离可表示为：<br>$$<br>|(x_1, y_1, z_1),(x_2, y_2, z_2)| &#x3D; \sqrt{(x_1-x_2)^2+(y_1-y_2)^2+(z_1-z_2)^2}<br>$$<br>以此类推，可以推广到N维空间.<br>$$<br>|(x_1, y_1, z_1…,n_1),(x_2, y_2, z_2,…n_2)| &#x3D; \sqrt{(x_1-x_2)^2+(y_1-y_2)^2+(z_1-z_2)^2+…(n_1-n_2)^2}<br>$$</p>
<h5 id="曼哈顿距离"><a href="#曼哈顿距离" class="headerlink" title="曼哈顿距离"></a>曼哈顿距离</h5><p>二维平面两点$a(x_1, y_1)$与$b(x_2, y_2)$两点间的曼哈顿距离为：<br>$$<br>d(a, b) &#x3D; |x_1 - x_2| + |y_1 - y_2|<br>$$<br>推广到N维空间，$x(x_1, x_2, …, x_n)$与$y(y_1, y_2, …, y_n)$之间的曼哈顿距离为：<br>$$<br>d(x,y) &#x3D; |x_1 - y_1| + |x_2 - y_2| + … + |x_n - y_n| &#x3D; \sum_{i&#x3D;1}^n|x_i - y_i|<br>$$</p>
<img src="/images/ml/cluster/manhaton_dist.png" alt="" width="200px"/>

<p>在上图中，绿色线条表示的为欧式距离，红色线条表示的为曼哈顿距离，黄色线条和蓝色线条表示的为曼哈顿距离的等价长度。</p>
<h5 id="闵可夫斯基距离"><a href="#闵可夫斯基距离" class="headerlink" title="闵可夫斯基距离"></a>闵可夫斯基距离</h5><p>闵可夫斯基距离（Minkowski distance）又称闵氏距离，其定义为：<br>$$<br>D(x, y) &#x3D; (\sum_{i&#x3D;1}^n |x_i - y_i|^p)^{\frac{1}{p}}<br>$$</p>
<ul>
<li><p>当$p&#x3D;1$时，即为曼哈顿距离</p>
</li>
<li><p>当$p&#x3D;2$时，即为欧式距离</p>
</li>
<li><p>当$p \rightarrow \infty$时，即为切比雪夫距离</p>
</li>
</ul>
<p>可见，曼哈顿距离、欧氏距离、切比雪夫距离都是闵可夫斯基的特殊形式.</p>
<h5 id="距离的性质"><a href="#距离的性质" class="headerlink" title="距离的性质"></a>距离的性质</h5><p>如果$dist(x,y)$度量标准为一个距离，它应该满足以下几个条件：</p>
<ul>
<li>非负性：距离一般不能为负，即 $dist(x, y) &gt;&#x3D; 0$</li>
<li>同一性：$dist(x_i, y_i) &#x3D; 0$，当且仅当$x_i &#x3D; y_i$</li>
<li>对称性：$dist(x_i, y_i) &#x3D; dist(y_i, x_i)$</li>
<li>直递性：$dist(x_i, x_j) &lt;&#x3D; dist(x_i, x_k) + dist(x_k, x_j)$</li>
</ul>
<h4 id="聚类算法的划分"><a href="#聚类算法的划分" class="headerlink" title="聚类算法的划分"></a>聚类算法的划分</h4><h5 id="原型聚类"><a href="#原型聚类" class="headerlink" title="原型聚类"></a>原型聚类</h5><p>原型聚类也称“基于原型的聚类”（prototype-based clustering），此类算法假设聚类结构能通过一组原型刻画，在现实聚类任务中极为常用. 通常情况下，算法先对原型进行初始化，然后对原型进行迭代更新求解. 采用不同的原型表示、不同的求解方式，将产生不同的算法. 最著名的原型聚类算法有K-Means.</p>
<h5 id="密度聚类"><a href="#密度聚类" class="headerlink" title="密度聚类"></a>密度聚类</h5><p>密度聚类也称“基于密度的聚类”（density-based clustering），此类算法假定聚类结构能通过样本分布的紧密程度确定. 通常情况下，密度聚类算法从样本密度的角度来考察样本之间的可连接性，并基于可连接样本不断扩展聚类簇以获得最终的聚类结果. 著名的密度聚类算法有DBSCAN.</p>
<h5 id="层次聚类"><a href="#层次聚类" class="headerlink" title="层次聚类"></a>层次聚类</h5><p>层次聚类（hierarchical clustering）试图在不同层次对数据集进行划分，从而形成树形的聚类结构. 数据集的划分可以采用“自底向上”或“自顶向下”的策略. 常用的层次聚类有凝聚层次算法等.</p>
<h3 id="常用聚类算法"><a href="#常用聚类算法" class="headerlink" title="常用聚类算法"></a>常用聚类算法</h3><h4 id="K均值聚类"><a href="#K均值聚类" class="headerlink" title="K均值聚类"></a>K均值聚类</h4><h5 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h5><p>K均值聚类（k-means clustering）算法是一种常用的、基于原型的聚类算法，简单、直观、高效。其步骤为：</p>
<p>第一步：根据事先已知的聚类数，随机选择若干样本作为聚类中心，计算每个样本与每个聚类中心的欧式距离，离哪个聚类中心近，就算哪个聚类中心的聚类，完成一次聚类划分.</p>
<p>第二步：计算每个聚类的几何中心，如果几何中心与聚类中心不重合，再以几何中心作为新的聚类中心，重新划分聚类. 重复以上过程，直到某一次聚类划分后，所得到的各个几何中心与其所依据的聚类中心重合或足够接近为止.  聚类过程如下图所示：</p>
<img src="/images/ml/cluster/k-means.png" alt="" width="400px"/>

<p>注意事项：</p>
<p>（1）聚类数（K）必须事先已知，来自业务逻辑的需求或性能指标. </p>
<p>（2）最终的聚类结果会因初始中心的选择不同而异，初始中心尽量选择离中心最远的样本.</p>
<h5 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h5><p>sklearn关于k-means算法API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.cluster <span class="keyword">as</span> sc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型</span></span><br><span class="line">model = sc.KMeans(n_clusters)  <span class="comment"># n_cluster为聚类数量</span></span><br><span class="line"></span><br><span class="line"> <span class="comment"># 获取聚类(几何)中心</span></span><br><span class="line">centers = model.cluster_centers_  </span><br><span class="line"></span><br><span class="line"> <span class="comment"># 获取聚类标签（聚类结果）</span></span><br><span class="line">pred_y = model.labels_  </span><br></pre></td></tr></table></figure>

<p>示例代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># k-means示例</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.cluster <span class="keyword">as</span> sc</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">import</span> sklearn.metrics <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line">x = []  <span class="comment"># 没有输出（无监督学习）</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;../data/multiple3.txt&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">        line = line.replace(<span class="string">&quot;\n&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">        data = [<span class="built_in">float</span>(substr) <span class="keyword">for</span> substr <span class="keyword">in</span> line.split(<span class="string">&quot;,&quot;</span>)]</span><br><span class="line">        x.append(data)</span><br><span class="line"></span><br><span class="line">x = np.array(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># K均值聚类器</span></span><br><span class="line">model = sc.KMeans(n_clusters=<span class="number">4</span>)  <span class="comment"># n_cluster为聚类数量</span></span><br><span class="line">model.fit(x)  <span class="comment"># 训练</span></span><br><span class="line"></span><br><span class="line">pred_y = model.labels_  <span class="comment"># 聚类标签（聚类结果）</span></span><br><span class="line">centers = model.cluster_centers_  <span class="comment"># 获取聚类(几何)中心</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;centers:&quot;</span>, centers)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;labels.shape:&quot;</span>, pred_y.shape)</span><br><span class="line"><span class="comment">#print(&quot;labels:&quot;, pred_y)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算并打印轮廓系数</span></span><br><span class="line">score = sm.silhouette_score(x, pred_y,</span><br><span class="line">                            sample_size=<span class="built_in">len</span>(x),</span><br><span class="line">                            metric=<span class="string">&quot;euclidean&quot;</span>)  <span class="comment"># 欧式距离度量</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;silhouette_score:&quot;</span>, score)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">mp.figure(<span class="string">&quot;K-Means Cluster&quot;</span>, facecolor=<span class="string">&quot;lightgray&quot;</span>)</span><br><span class="line">mp.title(<span class="string">&quot;K-Means Cluster&quot;</span>)</span><br><span class="line">mp.xlabel(<span class="string">&quot;x&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.ylabel(<span class="string">&quot;y&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.scatter(x[:, <span class="number">0</span>], x[:, <span class="number">1</span>], s=<span class="number">80</span>, c=pred_y, cmap=<span class="string">&quot;brg&quot;</span>)</span><br><span class="line">mp.scatter(centers[:, <span class="number">0</span>], centers[:, <span class="number">1</span>], marker=<span class="string">&quot;+&quot;</span>,</span><br><span class="line">           c=<span class="string">&quot;black&quot;</span>, s=<span class="number">200</span>, linewidths=<span class="number">1</span>)</span><br><span class="line">mp.show()</span><br></pre></td></tr></table></figure>

<p>打印输出：</p>
<figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">centers: <span class="comment">[<span class="comment">[7.07326531 5.61061224]</span></span></span><br><span class="line"><span class="comment"> <span class="comment">[1.831      1.9998    ]</span></span></span><br><span class="line"><span class="comment"> <span class="comment">[5.91196078 2.04980392]</span></span></span><br><span class="line"><span class="comment"> <span class="comment">[3.1428     5.2616    ]</span>]</span></span><br><span class="line">labels.shape: (200,)</span><br><span class="line">silhouette_score: 0.5773232071896658</span><br></pre></td></tr></table></figure>

<p>生成图像：</p>
<img src="/images/ml/cluster/k-means.png.png" alt="" width="400px"/>

<h5 id="特点及使用"><a href="#特点及使用" class="headerlink" title="特点及使用"></a>特点及使用</h5><ul>
<li>优点</li>
</ul>
<p>（1）原理简单，实现方便，收敛速度快；</p>
<p>（2）聚类效果较优，模型的可解释性较强；</p>
<ul>
<li>缺点</li>
</ul>
<p>（1）需要事先知道聚类数量；</p>
<p>（2）聚类初始中心的选择对聚类结果有影响；</p>
<p>（3）采用的是迭代的方法，只能得到局部最优解；</p>
<p>（4）对于噪音和异常点比较敏感. </p>
<ul>
<li>什么时候选择k-means</li>
</ul>
<p>（1）事先知道聚类数量</p>
<p>（2）数据分布有明显的中心</p>
<h4 id="噪声密度"><a href="#噪声密度" class="headerlink" title="噪声密度"></a>噪声密度</h4><h5 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h5><p>噪声密度（Density-Based Spatial Clustering of Applications with Noise， 简写DBSCAN）随机选择一个样本做圆心，以事先给定的半径做圆，凡被该圆圈中的样本都被划为与圆心样本同处一个聚类，再以这些被圈中的样本做圆心，以事先给定的半径继续做圆，不断加入新的样本，扩大聚类的规模，知道再无新的样本加入为止，即完成一个聚类的划分. 以同样的方法，在其余样本中继续划分新的聚类，直到样本空间被耗尽为止，即完成整个聚类划分过程. 示意图如下：</p>
<img src="/images/ml/cluster/DBSCAN.png" alt="" width="400px" />

<p>DBSCAN算法中，样本点被分为三类：</p>
<ul>
<li>边界点（Border point）：可以划分到某个聚类，但无法发展出新的样本；</li>
<li>噪声点（Noise）：无法划分到某个聚类中的点；</li>
<li>核心点（Core point）：除了孤立样本和外周样本以外的样本都是核心点；</li>
</ul>
<img src="/images/ml/cluster/DBSCAN_3.png" alt="" width="400px" />

<p>上图中，A和B为核心点，C为边界点，D为噪声点.  此外，DBSCAN还有两个重要参数：</p>
<ul>
<li>邻域半径：设置邻域半径大小；</li>
<li>最少样本数目：邻域内最小样本数量，某个样本邻域内的样本超过该数，才认为是核心点.</li>
</ul>
<h5 id="②-实现"><a href="#②-实现" class="headerlink" title="② 实现"></a>② 实现</h5><p>sklearn提供了DBSCAN模型来实现噪声密度聚类，原型如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = sc.DBSCAN(eps,   <span class="comment"># 半径</span></span><br><span class="line">                  min_samples) <span class="comment"># 最小样本数</span></span><br></pre></td></tr></table></figure>

<p>示例代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 噪声密度聚类示例</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.cluster <span class="keyword">as</span> sc</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">import</span> sklearn.metrics <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取样本</span></span><br><span class="line">x = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;../data/perf.txt&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">        line = line.replace(<span class="string">&quot;\n&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">        data = [<span class="built_in">float</span>(substr) <span class="keyword">for</span> substr <span class="keyword">in</span> line.split(<span class="string">&quot;,&quot;</span>)]</span><br><span class="line">        x.append(data)</span><br><span class="line"></span><br><span class="line">x = np.array(x)</span><br><span class="line"></span><br><span class="line">epsilon = <span class="number">0.8</span>  <span class="comment"># 邻域半径</span></span><br><span class="line">min_samples = <span class="number">5</span>  <span class="comment"># 最小样本数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建噪声密度聚类器</span></span><br><span class="line">model = sc.DBSCAN(eps=epsilon,  <span class="comment"># 半径</span></span><br><span class="line">                  min_samples=min_samples)  <span class="comment"># 最小样本数</span></span><br><span class="line">model.fit(x)</span><br><span class="line">score = sm.silhouette_score(x,</span><br><span class="line">                            model.labels_,</span><br><span class="line">                            sample_size=<span class="built_in">len</span>(x),</span><br><span class="line">                            metric=<span class="string">&#x27;euclidean&#x27;</span>)  <span class="comment"># 计算轮廓系数</span></span><br><span class="line">pred_y = model.labels_</span><br><span class="line"><span class="built_in">print</span>(pred_y) <span class="comment"># 打印所有样本类别</span></span><br><span class="line"><span class="comment"># print(model.core_sample_indices_) # 打印所有核心样本索引</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 区分样本</span></span><br><span class="line">core_mask = np.zeros(<span class="built_in">len</span>(x), dtype=<span class="built_in">bool</span>)</span><br><span class="line">core_mask[model.core_sample_indices_] = <span class="literal">True</span>  <span class="comment"># 核心样本下标</span></span><br><span class="line"></span><br><span class="line">offset_mask = (pred_y == -<span class="number">1</span>)  <span class="comment"># 孤立样本</span></span><br><span class="line">periphery_mask = ~(core_mask | offset_mask)  <span class="comment"># 核心样本、孤立样本之外的样本</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">mp.figure(<span class="string">&#x27;DBSCAN Cluster&#x27;</span>, facecolor=<span class="string">&#x27;lightgray&#x27;</span>)</span><br><span class="line">mp.title(<span class="string">&#x27;DBSCAN Cluster&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">mp.xlabel(<span class="string">&#x27;x&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.ylabel(<span class="string">&#x27;y&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">14</span>)</span><br><span class="line">mp.grid(linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">labels = <span class="built_in">set</span>(pred_y)</span><br><span class="line"><span class="built_in">print</span>(labels)</span><br><span class="line">cs = mp.get_cmap(<span class="string">&#x27;brg&#x27;</span>, <span class="built_in">len</span>(labels))(<span class="built_in">range</span>(<span class="built_in">len</span>(labels)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;cs:&quot;</span>, cs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 核心点</span></span><br><span class="line">mp.scatter(x[core_mask][:, <span class="number">0</span>],  <span class="comment"># x坐标值数组</span></span><br><span class="line">           x[core_mask][:, <span class="number">1</span>],  <span class="comment"># y坐标值数组</span></span><br><span class="line">           c=cs[pred_y[core_mask]],</span><br><span class="line">           s=<span class="number">80</span>, label=<span class="string">&#x27;Core&#x27;</span>)</span><br><span class="line"><span class="comment"># 边界点</span></span><br><span class="line">mp.scatter(x[periphery_mask][:, <span class="number">0</span>],</span><br><span class="line">           x[periphery_mask][:, <span class="number">1</span>],</span><br><span class="line">           edgecolor=cs[pred_y[periphery_mask]],</span><br><span class="line">           facecolor=<span class="string">&#x27;none&#x27;</span>, s=<span class="number">80</span>, label=<span class="string">&#x27;Periphery&#x27;</span>)</span><br><span class="line"><span class="comment"># 噪声点</span></span><br><span class="line">mp.scatter(x[offset_mask][:, <span class="number">0</span>],</span><br><span class="line">           x[offset_mask][:, <span class="number">1</span>],</span><br><span class="line">           marker=<span class="string">&#x27;D&#x27;</span>, c=cs[pred_y[offset_mask]],</span><br><span class="line">           s=<span class="number">80</span>, label=<span class="string">&#x27;Offset&#x27;</span>)</span><br><span class="line">mp.legend()</span><br><span class="line">mp.show()</span><br></pre></td></tr></table></figure>

<p>执行图像：</p>
<img src="/images/ml/cluster/DBSCAN_2.png" alt="" width="400px" />

<h5 id="特点及使用-1"><a href="#特点及使用-1" class="headerlink" title="特点及使用"></a>特点及使用</h5><ul>
<li>算法优点</li>
</ul>
<p>（1）不用人为提前确定聚类类别数K；<br>（2）聚类速度快；<br>（3）能够有效处理噪声点（因为异常点不会被包含于任意一个簇，则认为是噪声）；<br>（4）能够应对任意形状的空间聚类.</p>
<ul>
<li>算法缺点</li>
</ul>
<p>（1）当数据量过大时，要求较大的内存支持I&#x2F;O消耗很大；<br>（2）当空间聚类的密度不均匀、聚类间距差别很大时、聚类效果有偏差；<br>（3）邻域半径和最少样本数量两个参数对聚类结果影响较大.</p>
<ul>
<li>何时选择噪声密度</li>
</ul>
<p>（1）数据稠密、没有明显中心；</p>
<p>（2）噪声数据较多；</p>
<p>（3）未知聚簇的数量. </p>
<h4 id="凝聚层次聚类"><a href="#凝聚层次聚类" class="headerlink" title="凝聚层次聚类"></a>凝聚层次聚类</h4><h5 id="定义-2"><a href="#定义-2" class="headerlink" title="定义"></a>定义</h5><p>凝聚层次（Agglomerative）算法，首先将每个样本看做独立的聚类，如果聚类数大于预期，则合并两个距离最近的样本作为一个新的聚类，如此反复迭代，不断扩大聚类规模的同时，减少聚类的总数，直到聚类数减少到预期值为止.  这里的关键问题是如何计算聚类之间的距离.</p>
<p>依据对距离的不同定义，将Agglomerative Clustering的聚类方法分为三种：</p>
<ul>
<li>ward：默认选项，挑选两个簇来合并，是的所有簇中的方差增加最小。这通常会得到大小差不多相等的簇。</li>
<li>average链接：将簇中所有点之间平均距离最小的两个簇合并。</li>
<li>complete链接：也称为最大链接，将簇中点之间最大距离最小的两个簇合并。</li>
</ul>
<p>ward适用于大多数数据集。如果簇中的成员个数非常不同（比如其中一个比其他所有都大得多），那么average或complete可能效果更好。</p>
<h5 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h5><p>sklearn提供了AgglomerativeClustering聚类器来实现凝聚层次聚类，示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 凝聚层次聚类示例</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.cluster <span class="keyword">as</span> sc</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> mp</span><br><span class="line"></span><br><span class="line">x = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;../data/multiple3.txt&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">        line = line.replace(<span class="string">&quot;\n&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">        data = [<span class="built_in">float</span>(substr) <span class="keyword">for</span> substr <span class="keyword">in</span> line.split(<span class="string">&quot;,&quot;</span>)]</span><br><span class="line">        x.append(data)</span><br><span class="line"></span><br><span class="line">x = np.array(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 凝聚聚类</span></span><br><span class="line">model = sc.AgglomerativeClustering(n_clusters=<span class="number">4</span>)  <span class="comment"># n_cluster为聚类数量</span></span><br><span class="line">model.fit(x)  <span class="comment"># 训练</span></span><br><span class="line">pred_y = model.labels_  <span class="comment"># 聚类标签（聚类结果）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">mp.figure(<span class="string">&quot;Agglomerative&quot;</span>, facecolor=<span class="string">&quot;lightgray&quot;</span>)</span><br><span class="line">mp.title(<span class="string">&quot;Agglomerative&quot;</span>)</span><br><span class="line">mp.xlabel(<span class="string">&quot;x&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.ylabel(<span class="string">&quot;y&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.scatter(x[:, <span class="number">0</span>], x[:, <span class="number">1</span>], s=<span class="number">80</span>, c=pred_y, cmap=<span class="string">&quot;brg&quot;</span>)</span><br><span class="line">mp.show()</span><br></pre></td></tr></table></figure>

<p>执行结果：</p>
<img src="/images/ml/cluster/agglom.png" alt="" width="400px" />

<h5 id="特点及使用-2"><a href="#特点及使用-2" class="headerlink" title="特点及使用"></a>特点及使用</h5><p>（1）需要事先给定期望划分的聚类数（k），来自业务或指标优化；</p>
<p>（2）没有聚类中心，无法进行聚类预测，因为不依赖于中心的划分，所以对于中心特征不明显的样本，划分效果更佳稳定.</p>
<p>（3）适合于中心不明显的聚类.</p>
<h3 id="聚类的评价指标"><a href="#聚类的评价指标" class="headerlink" title="聚类的评价指标"></a>聚类的评价指标</h3><p>理想的聚类可以用四个字概况：内密外疏，即同一聚类内部足够紧密，聚类之间足够疏远. 学科中使用“轮廓系数”来进行度量，见下图：</p>
<img src="/images/ml/cluster/cluster_measure.jpg" alt="" width="400px"/>

<p>假设我们已经通过一定算法，将待分类数据进行了聚类，对于簇中的每个样本，分别计算它们的轮廓系数。对于其中的一个点 i 来说：<br>    a(i) &#x3D; average(i向量到所有它属于的簇中其它点的距离)<br>    b(i) &#x3D; min (i向量到各个非本身所在簇的所有点的平均距离)<br>那么 i 向量轮廓系数就为：<br>$$<br>S(i)&#x3D;\frac{b(i)-a(i)}{max(b(i), a(i))}<br>$$<br>由公式可以得出:</p>
<p>（1）当$b(i)&gt;&gt;a(i)$时，$S(i)$越接近于1，这种情况聚类效果最好；</p>
<p>（2）当$b(i)&lt;&lt;a(i)$时，$S(i)$越接近于-1，这种情况聚类效果最差；</p>
<p>（3）当$b(i)&#x3D;a(i)$时，$S(i)$的值为0，这种情况分类出现了重叠. </p>
<p>sklearn提供的计算轮廓系数API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">score = sm.silhouette_score(x, <span class="comment"># 样本</span></span><br><span class="line">                            pred_y, <span class="comment"># 标签</span></span><br><span class="line">                            sample_size=<span class="built_in">len</span>(x), <span class="comment"># 样本数量</span></span><br><span class="line">                            metric=<span class="string">&quot;euclidean&quot;</span>)  <span class="comment"># 欧式距离度量</span></span><br></pre></td></tr></table></figure></div><script type="text/javascript" src="../../../../js/share.js?v=1.0.0" async></script><a class="article-share-link" data-url="https://deeplearner.top/2022/11/03/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-11-%E8%81%9A%E7%B1%BB/" data-id="clkor69p3004bc6s65ippa5xt" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAQ4AAAEOCAAAAABd2qZ5AAAD7klEQVR42u3awVLjQAwE0Pz/T7NXqCVxtzQOObycKEjsmWeqFPXo8YhfX09e///1+2/yzyaferaqZA2HXzhw4MCBY7TVZHHJz6+Xm/x+tqr8mjhw4MCB4w6OpIzNtpfUsqQ0zkp7vkccOHDgwPFXHMWlY9Zn2zh7ZRw4cODA8ZkcbSHMC3BO/JoPBw4cOHB8Akd7OLRpvWbhYIt+e1aKAwcOHDgmla5o5z7551vmO3DgwIEDR3D8kxektjznhbZt2GYr/OXuOHDgwIFjzdEGf/loWhLe5YFgPk7R3hcHDhw4cNzBMYvzNq3gbIghL6VJIS92gQMHDhw4Yo5ZgdyMuyUFchZNHog4ceDAgQPHzRx5ecsLatIctmMNx7464MCBAweOQxxtWLZplt4zVJePO1ykpDhw4MCBY8Gx2cxsuGFGsCn5FxEhDhw4cOA4ypFHeO1xURIjvn4ws6OpeuQCBw4cOHCsOZIl5sUs52jbsLYkrx4qDhw4cOBYcLRHSm3o1rZ8m9ax5V61cDhw4MCBI+BoC97mEGgfSrZFdJWV4sCBAweOmKMtaadavmSsLVlJEkEeCAdx4MCBA0fJkRwLtUdKpwrk7Egp3zwOHDhw4LiPIy+Nedw2K7R5CW8fWNGp4cCBAweOEccmBGwPmTajcvmWNmvDgQMHDhx7jlkg2BbIpHlr262ErB2/wIEDBw4c7+GYjSDMBiBmh0+z60dTHjhw4MCBY8SxHxdoQ8NNLDgruvlDwoEDBw4cpzjypisP3YYDaut75Wu++L/AgQMHDhwlx6ZQbQK7dkAheWcbMv7yKRw4cODAsebI47Z83GEzEtEOK+Qrx4EDBw4c7+HIO7y81OUQCUeOMrvvo63JOHDgwIGjO1Gq47a8EOatV/ueWSt4rE/FgQMHDhxBlFaXohJlNjyRh4/tsdmPFg4HDhw4cBziSNqh/EhpuKASN79vVMJx4MCBA8eaI9lS3uOcukLSsM0auforBQ4cOHDgKDnagYP8qGlzgDQbp9iwDucvcODAgQNHwDEbF2jH15L356U0fxgXn8KBAwcOHIc4ZsdI+0DwMXptIr8iK8WBAwcOHIt3nr1cXlDboYRNFFhkpThw4MCBY8Exu83+nVFUt3gA+fWjcBAHDhw4cGy7pBXcqXBwFvPlYWUyfoEDBw4cOGb3arc3iw7PFsLZ0EMUOOLAgQMHjkMceZq4if82205QNqA4cODAgeOvOGajDPkm2wOq9iDq4uHhwIEDB463c+SRXD1bMSr2+y8EB7534MCBAweOUTjYbn5WLFuI9pjq2LETDhw4cOBYDzRs4rkNdEuTr3kWWeLAgQMHjifv/Aef9FSGNR/HhwAAAABJRU5ErkJggg==">分享</a><div class="tags"><a href="../../../../tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><i class="fa fa-tag"></i>机器学习笔记</a><a href="../../../../tags/%E5%91%A8%E5%BF%97%E5%8D%8E/"><i class="fa fa-tag"></i>周志华</a><a href="../../../../tags/%E5%90%B4%E6%81%A9%E8%BE%BE/"><i class="fa fa-tag"></i>吴恩达</a><a href="../../../../tags/%E6%9D%8E%E8%88%AA/"><i class="fa fa-tag"></i>李航</a></div><div class="post-nav"><a class="pre" href="../../04/CV%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E6%9C%AC%E7%90%86%E8%AE%BA/">OpenCV-1.计算机视觉基本理论</a><a class="next" href="../../02/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-10-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E4%BC%98%E5%8C%96/">MachineLearning-10.模型评估与优化</a></div><div class="nofancybox" id="waline"></div><script src="//unpkg.com/@waline/client@v2/dist/waline.js"></script><link rel="stylesheet" type="text/css" href="//unpkg.com/@waline/client@v2/dist/waline.css"><script>let metaInfo = ['nick', 'mail', 'link']
let requiredMeta = 'nick'.split(',').filter(item => {
  return metaInfo.indexOf(item) > -1
})
Waline.init({
  el: '#waline',
  comment: true,
  serverURL: 'https://waline-deeplearner.vercel.app',
  pageSize: '10',
  wordLimit: '500',
  requiredMeta,
})
</script></div></div></div><div class="pure-u-1 pure-u-md-1-4"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/images/blog/avatar_new.png"/></a><p>心外无物，知行合一</p><a class="info-icon" href="/resume/" title="个人简历" target="_blank" style="margin-inline:5px"> <i class="fa fa-share-square" style="margin-inline:5px"></i></a><a class="info-icon" href="mailto:conghaoyuan@gmail.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/conghaoyuan" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a><a class="info-icon" href="/atom.xml" title="RSS" target="_blank" style="margin-inline:5px"> <i class="fa fa-rss-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/AIGC/">AIGC</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Algorithm/">Algorithm</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/CV/">CV</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/GUI/">GUI</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/NLP/">NLP</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Python/">Python</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E5%AD%97%E4%BA%BA/">数字人</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E5%AD%A6/">数学</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/">深度学习框架</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B/">深度学习模型</a><span class="category-list-count">11</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="../../../../2025/03/10/AIGC-LLM-%E8%BE%9F%E9%82%AA%E5%89%91%E8%B0%B1%E4%B9%8B%E9%80%9A%E4%B9%89Prompt%E5%9B%9B%E5%8D%81%E5%BC%8F/">AIGC-LLM-辟邪剑谱之通义Prompt四十式</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2025/03/06/AIGC-LLM-%E8%BE%9F%E9%82%AA%E5%89%91%E8%B0%B1%E4%B9%8BPrompt%20Engineering/">AIGC-LLM-辟邪剑谱之Prompt Engineering</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/11/18/AIGC-Agent-%E4%BD%9C%E6%96%87%E6%89%B9%E6%94%B9%E6%A0%87%E6%B3%A8/">AIGC-Agent-作文批改标注</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/09/27/LLama32%E8%B0%83%E7%A0%94/">LLama3.2调研报告</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/04/09/AIGC-LLM-Prompt%E6%8A%80%E8%83%BD/">AIGC-LLM-Prompt工程技能综述</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/03/05/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-BERT/">Deeeplearning模型-NLP-BERT</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/01/16/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E8%AF%AD%E6%96%99%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7/">Deeeplearning模型-NLP-大语言模型微调语料生成工具</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/12/05/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-Transformer%E6%A8%A1%E5%9E%8B/">Deeeplearning模型-NLP-Transformer模型</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/12/01/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-NLP%E5%9F%BA%E7%A1%80/">Deeeplearning模型-NLP-NLP基础</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/10/26/%E6%95%B0%E5%AD%97%E4%BA%BA-%E6%95%B0%E5%AD%97%E4%BA%BA%E6%8A%80%E6%9C%AF%E6%95%88%E6%9E%9C%E5%AF%B9%E6%AF%94/">数字人-数字人技术效果对比</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://conghaoyuan.github.io" title="Fern[个人早期博客]" target="_blank">Fern[个人早期博客]</a></div><div class="widget"><div class="widget-title"><i class="fa fa-star"> 天文学</i></div><ul></ul><a href="/tools/tianwenli.html" title="天文历" target="_self">天文历</a></div><div class="widget"><div class="widget-title"><i class="fa fa-plus"> 数学小工具</i></div><ul></ul><a href="/tools/buy_house.html" title="丐版买房计算器" target="_self">丐版买房计算器</a><ul></ul><a href="/tools/equation_12.html" title="一元二次方程" target="_self">一元二次方程</a><ul></ul><a href="/tools/equation_line.html" title="直线方程" target="_self">直线方程</a><ul></ul><a href="/tools/equation_polynomial.html" title="多项式方程" target="_self">多项式方程</a><ul></ul><a href="/tools/regression_ridge.html" title="岭回归" target="_self">岭回归</a><ul></ul><a href="/tools/fourier_transform.html" title="傅里叶变换" target="_self">傅里叶变换</a><ul></ul><a href="/tools/gradient_descent.html" title="梯度下降" target="_self">梯度下降</a><ul></ul><a href="/tools/function_e.html" title="指数函数" target="_self">指数函数</a><ul></ul><a href="/tools/function_inverse_scale.html" title="反比例函数" target="_self">反比例函数</a><ul></ul><a href="/tools/function_log.html" title="对数函数" target="_self">对数函数</a><ul></ul><a href="/tools/function_sin.html" title="正弦函数" target="_self">正弦函数</a><ul></ul><a href="/tools/coord_grid.html" title="网格化坐标" target="_self">网格化坐标</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="../../../../." rel="nofollow">DeepLearner.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="../../../../js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="../../../../js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="../../../../css/search.css?v=1.0.0"><script type="text/javascript" src="../../../../js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="/static/js/MathJax.js?config=TeX-MML-AM_CHTML" async></script><div id="script" type="text/javascript" src="../../../../js/mathjaxs.js" async></div><script type="text/javascript" src="../../../../js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="../../../../js/smartresize.js?v=1.0.0"></script></div><!-- hexo injector body_end start -->
<script src="assets/prism-bundle.js"></script>
<script src="assets/prism-plus.js" data-pjax=""></script>
<!-- hexo injector body_end end --></body></html>