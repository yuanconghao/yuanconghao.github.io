<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Just Do It"><title>MachineLearning-10.模型评估与优化 | DeepLearner</title><link rel="stylesheet" type="text/css" href="../../../../css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="/static/css/normalize.css"><link rel="stylesheet" type="text/css" href="/static/css/pure-min.css"><link rel="stylesheet" type="text/css" href="/static/css/grids-responsive-min.css"><link rel="stylesheet" href="/static/css/font-awesome.min.css"><script type="text/javascript" src="/static/js/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="../../../../favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="../../../../favicon.ico"><link rel="apple-touch-icon" href="../../../../apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="../../../../apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="../../../../atom.xml"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-83251621-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + 'b207d9febf3295d375e6e9b42006f9eb';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/static/js/clipboard.min.js"></script><script type="text/javascript" src="/static/js/toastr.min.js"></script><link rel="stylesheet" href="/static/css/toastr.min.css"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">MachineLearning-10.模型评估与优化</h1><a id="logo" href="../../../../.">DeepLearner</a><p class="description">Deep Learning Notes</p></div><div id="nav-menu"><a class="current" href="../../../../."><i class="fa fa-home"> 首页</i></a><a href="../../../../archives/"><i class="fa fa-archive"> 归档</i></a><a href="../../../../tagcloud/"><i class="fa fa-tags"> 标签</i></a><a href="../../../../resource/"><i class="fa fa-cloud"> 资源</i></a><a href="../../../../guestbook/"><i class="fa fa-wechat"> 留言</i></a><a href="../../../../codeline/"><i class="fa fa-circle"> 码迹</i></a><a href="../../../../resume/"><i class="fa fa-user"> 个人简历</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">MachineLearning-10.模型评估与优化</h1><div class="post-meta">created:2022-11-02</div><div class="post-meta">updated:2023-07-30<span> | </span><span class="category"><a href="../../../../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><a class="disqus-comment-count" href="#waline"><span class="waline-comment-count" id=""></span><span> 条评论</span></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="toc-number">1.</span> <span class="toc-text">模型评估</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E5%BA%A6%E9%87%8F"><span class="toc-number">1.1.</span> <span class="toc-text">性能度量</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%94%99%E8%AF%AF%E7%8E%87%E4%B8%8E%E7%B2%BE%E5%BA%A6"><span class="toc-number">1.1.1.</span> <span class="toc-text">错误率与精度</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9F%A5%E5%87%86%E7%8E%87%E3%80%81%E5%8F%AC%E5%9B%9E%E7%8E%87%E4%B8%8EF1%E5%BE%97%E5%88%86"><span class="toc-number">1.1.2.</span> <span class="toc-text">查准率、召回率与F1得分</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5"><span class="toc-number">1.1.3.</span> <span class="toc-text">混淆矩阵</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.1.4.</span> <span class="toc-text">实验</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E9%9B%86%E4%B8%8E%E6%B5%8B%E8%AF%95%E9%9B%86"><span class="toc-number">1.2.</span> <span class="toc-text">训练集与测试集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E6%B3%95"><span class="toc-number">1.3.</span> <span class="toc-text">交叉验证法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E5%AE%9A%E4%B9%89"><span class="toc-number">1.3.1.</span> <span class="toc-text">交叉验证定义</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.3.2.</span> <span class="toc-text">交叉验证实现</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96"><span class="toc-number">2.</span> <span class="toc-text">模型优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%AA%8C%E8%AF%81%E6%9B%B2%E7%BA%BF%E4%B8%8E%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF"><span class="toc-number">2.1.</span> <span class="toc-text">验证曲线与学习曲线</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%AA%8C%E8%AF%81%E6%9B%B2%E7%BA%BF"><span class="toc-number">2.1.1.</span> <span class="toc-text">验证曲线</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF"><span class="toc-number">2.1.2.</span> <span class="toc-text">学习曲线</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96"><span class="toc-number">2.2.</span> <span class="toc-text">超参数优化</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E5%AE%9A%E4%B9%89"><span class="toc-number">2.2.1.</span> <span class="toc-text">超参数定义</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2"><span class="toc-number">2.2.2.</span> <span class="toc-text">网格搜索</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%90%9C%E7%B4%A2"><span class="toc-number">2.2.3.</span> <span class="toc-text">随机搜索</span></a></li></ol></li></ol></li></ol></div></div><div class="post-content"><p>模型评估和优化是机器学习中非常重要一环，不同的机器学习任务有着不同的评价指标，同时同一种机器学习任务也有着不同的评价指标，每个指标的着重点不一样。在实际情况中，会用不同的度量去评估模型，度量的选择，完全取决于模型的类型和模型的用处。<font color="#ff0000"><sup>[<a target="_blank" rel="noopener" href="http://www.feiguyunai.com/index.php/2017/10/17/pythonai-model-evaluation01/">1</a>]</sup></font></p>
<span id="more"></span>

<h3 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h3><h4 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h4><h5 id="错误率与精度"><a href="#错误率与精度" class="headerlink" title="错误率与精度"></a>错误率与精度</h5><p>错误率和精度是分类问题中常用的性能度量指标，既适用于二分类任务，也适用于多分类任务. </p>
<ul>
<li>错误率（error rate）：指分类错误的样本占样本总数的比例，即 （ 分类错误的数量 &#x2F; 样本总数数量）</li>
<li>精度（accuracy）：指分类正确的样本占样本总数的比例，即 （分类正确的数量 &#x2F; 样本总数数量）</li>
</ul>
<p><font color="#ff0000">$$精度 &#x3D; 1 - 错误率$$</font></p>
<h5 id="查准率、召回率与F1得分"><a href="#查准率、召回率与F1得分" class="headerlink" title="查准率、召回率与F1得分"></a>查准率、召回率与F1得分</h5><p>错误率和精度虽然常用，但并不能满足所有的任务需求。例如，在一次疾病检测中，我们更关注以下两个问题：</p>
<ul>
<li>检测出感染的个体中有多少是真正病毒携带者？</li>
<li>所有真正病毒携带者中，有多大比例被检测了出来？</li>
</ul>
<p>类似的问题在很多分类场景下都会出现，“查准率”（precision）与“召回率”（recall）是更为适合的度量标准。对于二分类问题，可以将真实类别、预测类别组合为“真正例”（true positive）、“假正例”（false positive）、“真反例”（true negative）、“假反例”（false negative）四种情形，见下表：</p>
<img src="/images/ml/confusion_matrix.png" alt="" width="400px" style="border:1px solid black;" />

<ul>
<li><p>样例总数：TP + FP + TN + FN</p>
</li>
<li><p>查准率： TP &#x2F; (TP + FP)，表示分的准不准</p>
</li>
<li><p>召回率：TP &#x2F; (TP + FN)，表示分的全不全，又称为“查全率”</p>
</li>
<li><p>F1得分：<br>$$<br>f1 &#x3D; \frac{2 * 查准率 * 召回率}{查准率 + 召回率}<br>$$</p>
</li>
</ul>
<p>查准率和召回率是一对矛盾的度量。一般来说，查准率高时，召回率往往偏低；召回率高时，查准率往往偏低。例如，在病毒感染者检测中，若要提高查准率，只需要采取更严格的标准即可，这样会导致漏掉部分感染者，召回率就变低了；反之，放松检测标准，更多的人被检测为感染，召回率升高了，查准率又降低了. 通常只有在一些简单任务中，才能同时获得较高查准率和召回率。</p>
<p>查准率和召回率在不同应用中重要性也不同。例如，在商品推荐中，为了尽可能少打扰客户，更希望推荐的内容是用户感兴趣的，此时查准率更重要；而在逃犯信息检索系统中，希望让更少的逃犯漏网，此时召回率更重要。</p>
<h5 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h5><p>混淆矩阵也称误差矩阵，是表示精度评价的一种标准格式，用n行n列的矩阵形式来表示。每一行（数量之和）表示一个真实类别的样本，每一列（数量之和）表示一个预测类别的样本。</p>
<p>根据混淆矩阵，查准率、召回率也可表示为：</p>
<p>查准率 &#x3D; 主对角线上的值 &#x2F; 该值所在列的和</p>
<p>召回率 &#x3D; 主对角线上的值 &#x2F; 该值所在行的和</p>
<h5 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h5><p>利用sklearn提供的朴素贝叶斯分类器分类，并打印查准率、召回率、R2得分和混淆矩阵：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 混淆矩阵示例</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.model_selection <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">import</span> sklearn.metrics <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> sklearn.naive_bayes <span class="keyword">as</span> nb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入，输出</span></span><br><span class="line">x, y = [], []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据文件</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;../data/multiple1.txt&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">        data = [<span class="built_in">float</span>(substr) <span class="keyword">for</span> substr <span class="keyword">in</span> line.split(<span class="string">&quot;,&quot;</span>)]</span><br><span class="line">        x.append(data[:-<span class="number">1</span>])  <span class="comment"># 输入样本：取从第一列到导数第二列</span></span><br><span class="line">        y.append(data[-<span class="number">1</span>])  <span class="comment"># 输出样本：取最后一列</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 样本转数组</span></span><br><span class="line">x = np.array(x)</span><br><span class="line">y = np.array(y, dtype=<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">train_x, test_x, train_y, test_y = ms.train_test_split(</span><br><span class="line">    x, y, test_size=<span class="number">0.25</span>, random_state=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建高斯朴素贝叶斯分类器对象</span></span><br><span class="line">model = nb.GaussianNB()</span><br><span class="line">model.fit(train_x, train_y)  <span class="comment"># 使用划分的训练集来训练模型</span></span><br><span class="line">pred_test_y = model.predict(test_x)  <span class="comment"># 预测</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;recall:&quot;</span>, sm.recall_score(test_y,  <span class="comment"># 真实值</span></span><br><span class="line">                                 pred_test_y,  <span class="comment"># 预测值</span></span><br><span class="line">                                 average=<span class="string">&quot;macro&quot;</span>))  <span class="comment"># 计算平均值，不考虑样本权重</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;precision:&quot;</span>, sm.precision_score(test_y,  <span class="comment"># 真实值</span></span><br><span class="line">                                       pred_test_y,  <span class="comment"># 预测值</span></span><br><span class="line">                                       average=<span class="string">&quot;macro&quot;</span>))  <span class="comment"># 计算平均值，不考虑样本权重</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;F1:&quot;</span>, sm.f1_score(test_y, pred_test_y,average=<span class="string">&quot;macro&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算并打印模型预测的混淆矩阵</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n Confusion Matrix:&quot;</span>)</span><br><span class="line">cm = sm.confusion_matrix(test_y, pred_test_y)</span><br><span class="line"><span class="built_in">print</span>(cm)</span><br></pre></td></tr></table></figure>

<p>打印输出：</p>
<figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">recall: 0.9910714285714286</span><br><span class="line">precision: 0.9903846153846154</span><br><span class="line">F1: 0.9905525846702318</span><br><span class="line"></span><br><span class="line"> Confusion Matrix:</span><br><span class="line">[[22 <span class="number"> 0 </span><span class="number"> 0 </span> 0]</span><br><span class="line"> [<span class="number"> 0 </span>27 <span class="number"> 1 </span> 0]</span><br><span class="line"> [<span class="number"> 0 </span><span class="number"> 0 </span>25  0]</span><br><span class="line"> [<span class="number"> 0 </span><span class="number"> 0 </span><span class="number"> 0 </span>25]]</span><br></pre></td></tr></table></figure>

<h4 id="训练集与测试集"><a href="#训练集与测试集" class="headerlink" title="训练集与测试集"></a>训练集与测试集</h4><p>通常情况下，评估一个模型性能的好坏，将样本数据划分为两部分，一部分专门用于模型训练，这部分称为“训练集”，一部分用于对模型进行测试，这部分被称为“测试集”，训练集和测试集一般不存在重叠部分. 常用的训练集、测试集比例有：9:1, 8:2, 7:3等. 训练集和测试的划分，尽量保持均衡、随机，不能集中于某个或少量类别. </p>
<p>有些公共数据集在创建时，已经进行了划分. 有时候，我们需要自己对数据集进行划分，划分的方式是先打乱数据集，然后使用一种计算方法，将一部分数据划入训练集，一部分数据划入测试集. </p>
<h4 id="交叉验证法"><a href="#交叉验证法" class="headerlink" title="交叉验证法"></a>交叉验证法</h4><h5 id="交叉验证定义"><a href="#交叉验证定义" class="headerlink" title="交叉验证定义"></a>交叉验证定义</h5><p>在样本数量较少的情况下，如果将样本划分为训练集、测试集，可能导致单个集合样本数量更少，可以采取交叉验证法来训练和测试模型. </p>
<p>将所有数据，划分成N等分，用每份都去训练，用每份都去测试</p>
<p>所有的数据，都去训练，所有的数据都去测试</p>
<p>“交叉验证法”（cross validation）先将数据集D划分为k个大小相同（或相似）的、互不相交的子集，每个子集称为一个”折叠”（fold），每次训练，轮流使用其中的一个作为测试集、其它作为训练集. 这样，就相当于获得了k组训练集、测试集，最终的预测结果为k个测试结果的平均值.</p>
<img src="/images/ml/cross_validation.png" alt="" width="600px" />

<h5 id="交叉验证实现"><a href="#交叉验证实现" class="headerlink" title="交叉验证实现"></a>交叉验证实现</h5><p>sklearn中，提供了cross_val_score函数来实现交叉验证并返回评估指标值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.model_selection <span class="keyword">as</span> ms</span><br><span class="line"></span><br><span class="line">n = ms.cross_val_score(model, <span class="comment">#模型</span></span><br><span class="line">                       train_x, train_y,<span class="comment"># 样本输入、输出</span></span><br><span class="line">                       cv,  <span class="comment"># 折叠数量</span></span><br><span class="line">                       scoring) <span class="comment"># 指定返回的指标</span></span><br></pre></td></tr></table></figure>

<p>拿到鸢尾花数据集，想要去做分类预测，用逻辑回归先用交叉验证，验证一下当前模型是否可用，再去进行训练。朴素贝叶斯模型的交叉验证实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 交叉验证示例</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.model_selection <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">import</span> sklearn.naive_bayes <span class="keyword">as</span> nb</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> mp</span><br><span class="line"></span><br><span class="line">x, y = [], []  <span class="comment"># 输入，输出</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据文件</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;../data/multiple1.txt&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">        data = [<span class="built_in">float</span>(substr) <span class="keyword">for</span> substr <span class="keyword">in</span> line.split(<span class="string">&quot;,&quot;</span>)]</span><br><span class="line">        x.append(data[:-<span class="number">1</span>])  <span class="comment"># 输入样本：取从第一列到导数第二列</span></span><br><span class="line">        y.append(data[-<span class="number">1</span>])  <span class="comment"># 输出样本：取最后一列</span></span><br><span class="line"></span><br><span class="line">train_x = np.array(x)</span><br><span class="line">train_y = np.array(y, dtype=<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line"><span class="comment">#train_x, test_x, train_y, test_y = ms.train_test_split(</span></span><br><span class="line"><span class="comment">#    x, y, test_size=0.25, random_state=7)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建高斯朴素贝叶斯分类器对象</span></span><br><span class="line">model = nb.GaussianNB()</span><br><span class="line"><span class="comment"># 先做交叉验证，如果得分结果可以接受，再执行训练和预测</span></span><br><span class="line">pws = ms.cross_val_score(model, x, y,</span><br><span class="line">                         cv=<span class="number">5</span>,  <span class="comment"># 折叠数量</span></span><br><span class="line">                         scoring=<span class="string">&#x27;precision_weighted&#x27;</span>)  <span class="comment"># 查准率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;precision:&quot;</span>, pws.mean())</span><br><span class="line"></span><br><span class="line">rws = ms.cross_val_score(model, x, y, cv=<span class="number">5</span>,</span><br><span class="line">                         scoring=<span class="string">&#x27;recall_weighted&#x27;</span>)  <span class="comment"># 召回率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;recall:&quot;</span>, rws.mean())</span><br><span class="line"></span><br><span class="line">f1s = ms.cross_val_score(model, x, y, cv=<span class="number">5</span>,</span><br><span class="line">                         scoring=<span class="string">&#x27;f1_weighted&#x27;</span>)  <span class="comment"># F1得分</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;f1:&quot;</span>, f1s.mean())</span><br><span class="line"></span><br><span class="line">acc = ms.cross_val_score(model, x, y,</span><br><span class="line">                         cv=<span class="number">5</span>, scoring=<span class="string">&#x27;accuracy&#x27;</span>)  <span class="comment"># 准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;acc:&quot;</span>, acc.mean())</span><br></pre></td></tr></table></figure>

<p>执行结果：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">precision</span>: <span class="number">0</span>.<span class="number">996822033898305</span></span><br><span class="line"><span class="attribute">recall</span>: <span class="number">0</span>.<span class="number">9966101694915255</span></span><br><span class="line"><span class="attribute">f1</span>: <span class="number">0</span>.<span class="number">9966063988235516</span></span><br><span class="line"><span class="attribute">acc</span>: <span class="number">0</span>.<span class="number">9966101694915255</span></span><br></pre></td></tr></table></figure>

<h3 id="模型优化"><a href="#模型优化" class="headerlink" title="模型优化"></a>模型优化</h3><h4 id="验证曲线与学习曲线"><a href="#验证曲线与学习曲线" class="headerlink" title="验证曲线与学习曲线"></a>验证曲线与学习曲线</h4><h5 id="验证曲线"><a href="#验证曲线" class="headerlink" title="验证曲线"></a>验证曲线</h5><p>验证曲线是指根据不同的评估系数，来评估模型的优劣。 构建随机森林，树的数量不同，模型预测准确度不同。验证曲线示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.preprocessing <span class="keyword">as</span> sp</span><br><span class="line"><span class="keyword">import</span> sklearn.ensemble <span class="keyword">as</span> se</span><br><span class="line"><span class="keyword">import</span> sklearn.model_selection <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> mp</span><br><span class="line"></span><br><span class="line">data = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;../data/car.txt&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">        data.append(line.replace(<span class="string">&quot;\n&quot;</span>, <span class="string">&quot;&quot;</span>).split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">data = np.array(data).T  <span class="comment"># 转置</span></span><br><span class="line">encoders, train_x = [], []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对样本数据进行标签编码</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)):</span><br><span class="line">    encoder = sp.LabelEncoder()  <span class="comment"># 创建标签编码器</span></span><br><span class="line">    encoders.append(encoder)</span><br><span class="line">    <span class="keyword">if</span> row &lt; <span class="built_in">len</span>(data) - <span class="number">1</span>:  <span class="comment"># 不是最后一行，为样本特征</span></span><br><span class="line">        lbl_code = encoder.fit_transform(data[row])  <span class="comment"># 编码</span></span><br><span class="line">        train_x.append(lbl_code)</span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># 最后一行，为样本输出</span></span><br><span class="line">        train_y = encoder.fit_transform(data[row])</span><br><span class="line"></span><br><span class="line">train_x = np.array(train_x).T  <span class="comment"># 转置回来，变为编码后的矩阵</span></span><br><span class="line"><span class="comment"># print(train_x)</span></span><br><span class="line"></span><br><span class="line">model = se.RandomForestClassifier(max_depth=<span class="number">8</span>,  <span class="comment"># 最大树高</span></span><br><span class="line">                                  random_state=<span class="number">7</span>)  <span class="comment"># 随机种子</span></span><br><span class="line"><span class="comment"># 调用validation_curve，返回训练集、测试集得分矩阵</span></span><br><span class="line">n_estimators = np.arange(<span class="number">50</span>, <span class="number">550</span>, <span class="number">50</span>)  <span class="comment"># 超参数值表</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;n_estimators.shape:&quot;</span>, n_estimators.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;n_estimators:&quot;</span>, n_estimators)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过不同参数，构建多棵决策树，验证其准确性</span></span><br><span class="line">train_scores1, test_scores1 = ms.validation_curve(model,  <span class="comment"># 模型</span></span><br><span class="line">                                                  train_x, train_y,</span><br><span class="line">                                                  <span class="string">&#x27;n_estimators&#x27;</span>,  <span class="comment"># 模型参数名称</span></span><br><span class="line">                                                  n_estimators,  <span class="comment"># 模型参数值</span></span><br><span class="line">                                                  cv=<span class="number">5</span>)</span><br><span class="line">train_mean = train_scores1.mean(axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;train_mean:&quot;</span>, train_mean)</span><br><span class="line">test_mean = test_scores1.mean(axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test_mean:&quot;</span>, test_mean)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">mp.figure(<span class="string">&#x27;n_estimators&#x27;</span>, facecolor=<span class="string">&#x27;lightgray&#x27;</span>)</span><br><span class="line">mp.title(<span class="string">&#x27;n_estimators&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">mp.xlabel(<span class="string">&#x27;n_estimators&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.ylabel(<span class="string">&#x27;F1 Score&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.grid(linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">mp.plot(n_estimators, test_mean, <span class="string">&#x27;o-&#x27;</span>, c=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;Testing&#x27;</span>)</span><br><span class="line">mp.legend()</span><br><span class="line">mp.show()</span><br></pre></td></tr></table></figure>

<p>执行结果：</p>
<img src="/images/ml/validation_curve.png" alt="" width="400px" style="border:1px solid black;" />

<h5 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h5><p>学习曲线是用来评估不同大小的训练集下模型的优劣程度，如果预测结果随着训练集样本的增加而变化不大，那么增加样本数量不会对模型产生明显优化作用. 以下是一个学习曲线的示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 学习曲线示例</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.preprocessing <span class="keyword">as</span> sp</span><br><span class="line"><span class="keyword">import</span> sklearn.ensemble <span class="keyword">as</span> se</span><br><span class="line"><span class="keyword">import</span> sklearn.model_selection <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> mp</span><br><span class="line"></span><br><span class="line">data = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;../data/car.txt&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">        data.append(line.replace(<span class="string">&quot;\n&quot;</span>, <span class="string">&quot;&quot;</span>).split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">data = np.array(data).T  <span class="comment"># 转置</span></span><br><span class="line">encoders, train_x = [], []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对样本数据进行标签编码</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)):</span><br><span class="line">    encoder = sp.LabelEncoder()  <span class="comment"># 创建标签编码器</span></span><br><span class="line">    encoders.append(encoder)</span><br><span class="line">    <span class="keyword">if</span> row &lt; <span class="built_in">len</span>(data) - <span class="number">1</span>:  <span class="comment"># 不是最后一行，为样本特征</span></span><br><span class="line">        lbl_code = encoder.fit_transform(data[row])  <span class="comment"># 编码</span></span><br><span class="line">        train_x.append(lbl_code)</span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># 最后一行，为样本输出</span></span><br><span class="line">        train_y = encoder.fit_transform(data[row])</span><br><span class="line"></span><br><span class="line">train_x = np.array(train_x).T  <span class="comment"># 转置回来，变为编码后的矩阵</span></span><br><span class="line"><span class="built_in">print</span>(train_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获得学习曲线</span></span><br><span class="line">model = se.RandomForestClassifier(max_depth=<span class="number">9</span>,  <span class="comment"># 最大树高</span></span><br><span class="line">                                  n_estimators=<span class="number">200</span>, <span class="comment"># 评估系数</span></span><br><span class="line">                                  random_state=<span class="number">7</span>)  <span class="comment"># 随机种子</span></span><br><span class="line"></span><br><span class="line">train_sizes = np.linspace(<span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line">train_sizes, train_scores, test_scores = ms.learning_curve(</span><br><span class="line">                                                        model,</span><br><span class="line">                                                        train_x, train_y,</span><br><span class="line">                                                        train_sizes=train_sizes,</span><br><span class="line">                                                        cv=<span class="number">5</span>)<span class="comment">#交叉验证折叠数量</span></span><br><span class="line">train_means = train_scores.mean(axis=<span class="number">1</span>)</span><br><span class="line">test_means = test_scores.mean(axis=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> size, score <span class="keyword">in</span> <span class="built_in">zip</span>(train_sizes, train_means):</span><br><span class="line">    <span class="built_in">print</span>(size, <span class="string">&#x27;-&gt;&#x27;</span>, score)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">mp.figure(<span class="string">&#x27;Learning Curve&#x27;</span>, facecolor=<span class="string">&#x27;lightgray&#x27;</span>)</span><br><span class="line">mp.title(<span class="string">&#x27;Learning Curve&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">mp.xlabel(<span class="string">&#x27;Train Size&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.ylabel(<span class="string">&#x27;F1 Score&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.grid(linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">mp.plot(train_sizes, train_means, <span class="string">&#x27;o-&#x27;</span>, c=<span class="string">&#x27;dodgerblue&#x27;</span>, label=<span class="string">&#x27;Training&#x27;</span>)</span><br><span class="line">mp.plot(train_sizes, test_means, <span class="string">&#x27;o-&#x27;</span>, c=<span class="string">&#x27;orangered&#x27;</span>, label=<span class="string">&#x27;Testing&#x27;</span>)</span><br><span class="line">mp.legend()</span><br><span class="line">mp.show()</span><br></pre></td></tr></table></figure>

<p>执行结果：</p>
<img src="/images/ml/learn_curve.png" alt="" width="400px" style="border:1px solid black;" />

<h4 id="超参数优化"><a href="#超参数优化" class="headerlink" title="超参数优化"></a>超参数优化</h4><h5 id="超参数定义"><a href="#超参数定义" class="headerlink" title="超参数定义"></a>超参数定义</h5><p>超参数是在开始学习过程之前设置值的参数，而不是通过训练得到的参数数据。超参数的设置主要依赖于经验、实验或经过比较的优选值。以下是一些模型中常见的超参数：</p>
<ul>
<li>决策树模型树的最大深度；</li>
<li>随机森林模型树的数量；</li>
<li>交叉验证中折叠的额数量；</li>
<li>训练集&#x2F;测试集的比例等等.</li>
</ul>
<p>超参数选择主要有随机搜索、网格搜索等方法。</p>
<h5 id="网格搜索"><a href="#网格搜索" class="headerlink" title="网格搜索"></a>网格搜索</h5><p>网格搜索指将主要参数以及这些参数的主要取值，通过穷举法产生不同组合，计算并比较预测结果，来寻找这些参数的最优组合。</p>
<p>以下是利用网格搜索法，寻找SVM的最优超参数的示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 网格搜索示例</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.model_selection <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">import</span> sklearn.svm <span class="keyword">as</span> svm</span><br><span class="line"><span class="keyword">import</span> sklearn.metrics <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> mp</span><br><span class="line"></span><br><span class="line">x, y = [], []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;../data/multiple2.txt&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">        data = [<span class="built_in">float</span>(substr) <span class="keyword">for</span> substr <span class="keyword">in</span> line.split(<span class="string">&quot;,&quot;</span>)]</span><br><span class="line">        x.append(data[:-<span class="number">1</span>])  <span class="comment"># 输入</span></span><br><span class="line">        y.append(data[-<span class="number">1</span>])  <span class="comment"># 输出</span></span><br><span class="line"></span><br><span class="line">x = np.array(x)</span><br><span class="line">y = np.array(y, dtype=<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过网格搜索确定最优参数组合</span></span><br><span class="line"><span class="comment"># 定义参数字典</span></span><br><span class="line">params = [</span><br><span class="line">    &#123;<span class="string">&quot;kernel&quot;</span>: [<span class="string">&quot;linear&quot;</span>],</span><br><span class="line">     <span class="string">&quot;C&quot;</span>: [<span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>, <span class="number">1000</span>]</span><br><span class="line">     &#125;,</span><br><span class="line">    &#123;<span class="string">&quot;kernel&quot;</span>: [<span class="string">&quot;poly&quot;</span>],</span><br><span class="line">     <span class="string">&quot;C&quot;</span>: [<span class="number">1</span>],</span><br><span class="line">     <span class="string">&quot;degree&quot;</span>: [<span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">     &#125;,</span><br><span class="line">    &#123;<span class="string">&quot;kernel&quot;</span>: [<span class="string">&quot;rbf&quot;</span>],</span><br><span class="line">     <span class="string">&quot;C&quot;</span>: [<span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>, <span class="number">1000</span>],</span><br><span class="line">     <span class="string">&quot;gamma&quot;</span>: [<span class="number">1</span>, <span class="number">0.1</span>, <span class="number">0.01</span>, <span class="number">0.001</span>]</span><br><span class="line">     &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">model = ms.GridSearchCV(svm.SVC(), params, cv=<span class="number">5</span>)  <span class="comment"># 创建网格搜索对象</span></span><br><span class="line">model.fit(x, y)  <span class="comment"># 训练</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;best_score_:&quot;</span>, model.best_score_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;best_params_:\n&quot;</span>, model.best_params_)</span><br><span class="line"><span class="comment">#print(&quot;best_estimator_:\n&quot;, model.best_estimator_)</span></span><br><span class="line"></span><br><span class="line">l, r, h = x[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span>, x[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">1</span>, <span class="number">0.005</span></span><br><span class="line">b, t, v = x[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span>, x[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">1</span>, <span class="number">0.005</span></span><br><span class="line">grid_x = np.meshgrid(np.arange(l, r, h), np.arange(b, t, v))</span><br><span class="line">flat_x = np.c_[grid_x[<span class="number">0</span>].ravel(), grid_x[<span class="number">1</span>].ravel()]</span><br><span class="line">flat_y = model.predict(flat_x)</span><br><span class="line">grid_y = flat_y.reshape(grid_x[<span class="number">0</span>].shape)</span><br><span class="line"></span><br><span class="line">mp.figure(<span class="string">&quot;SVM RBF Classifier&quot;</span>, facecolor=<span class="string">&quot;lightgray&quot;</span>)</span><br><span class="line">mp.title(<span class="string">&quot;SVM RBF Classifier&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.xlabel(<span class="string">&quot;x&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.ylabel(<span class="string">&quot;y&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.pcolormesh(grid_x[<span class="number">0</span>], grid_x[<span class="number">1</span>], grid_y, cmap=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line"></span><br><span class="line">C0, C1 = (y == <span class="number">0</span>), (y == <span class="number">1</span>)</span><br><span class="line">mp.scatter(x[C0][:, <span class="number">0</span>], x[C0][:, <span class="number">1</span>], c=<span class="string">&quot;orangered&quot;</span>, s=<span class="number">80</span>)</span><br><span class="line">mp.scatter(x[C1][:, <span class="number">0</span>], x[C1][:, <span class="number">1</span>], c=<span class="string">&quot;limegreen&quot;</span>, s=<span class="number">80</span>)</span><br><span class="line"></span><br><span class="line">mp.show()</span><br></pre></td></tr></table></figure>

<p>打印输出：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">best_score_:</span> <span class="number">0.95</span></span><br><span class="line"><span class="attr">best_params_:</span></span><br><span class="line"> &#123;<span class="attr">&#x27;C&#x27;:</span> <span class="number">1</span>, <span class="attr">&#x27;gamma&#x27;:</span> <span class="number">1</span>, <span class="attr">&#x27;kernel&#x27;:</span> <span class="string">&#x27;rbf&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>执行结果可视化：</p>
<img src="/images/ml/grid_search.png" alt="" width="400px" style="border:1px solid black;" />

<h5 id="随机搜索"><a href="#随机搜索" class="headerlink" title="随机搜索"></a>随机搜索</h5><p>随机搜索的思想与网格搜索比较相似，只是不再测试上界和下界之间的所有值，而是在搜索范围中随机选取样本点。它的理论依据是，如果样本点集足够大，那么通过随机采样也能大概率地找到全局最优值，或其近似值。随机搜索一般会比网格搜索要快一些，但是和网格搜索的快速版一样，它的结果没法保证。</p>
</div><script type="text/javascript" src="../../../../js/share.js?v=1.0.0" async></script><a class="article-share-link" data-url="https://deeplearner.top/2022/11/02/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-10-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E4%BC%98%E5%8C%96/" data-id="clkor69p20046c6s6aqbv6dmp" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAT4AAAE+CAAAAAAxUyPsAAAFO0lEQVR42u3aQZLiMBAEwPn/p9nLHtiYxVR1y1xInyY82LLSRNCq1s9PfDyejuczv//7fP7Vtdf3v77P779f3S259nrEYwc+fPjw4cMXPHoyZAJ0fT6HS85ff6a9T3ItPnz48OHDN+O7nvapR7zjzgnxdZmSvIaX5/Hhw4cPH76b+ZLFeVtktGO1kcH+ReLDhw8fPnyf52sHfgRHm4q3QX8eFuDDhw8fPnyf5MsfYha150F//gxt82A21rFeBz58+PDhwzcqGr7h71v29+HDhw8fvq/ne5THdUDfLtH3hUt+1VmHv/fEhw8fPnz4Jho/M7LZVraEOB+lXdLnI15/Eh8+fPjw4TvLd3aqLXpSpsxeZFJy5Zvt8OHDhw8fvg1fjpWXOJtwod3ilkcbm1jkZWSADx8+fPjwlRXIbNmfnN+XC7MYYvaC8eHDhw8fvrv5Ng/XTjh53CTCuCOeGIYL+PDhw4cP34LvbDSQQ+xb3bM2w2zDHD58+PDhwzfjy3/O2zPJYyWfbye5Ce5zVnz48OHDh2/Gtwnfk4X6fqqzSbZBwCyGwIcPHz58+Fq+ZGGfxwqzpvupjWX7CL6OP/Dhw4cPH755cn5LQJ9M/ixrMqP9Z4alDD58+PDhw7duV7dXnW1pzzbYtYFI9I3Dhw8fPnz4Ar6kmMjLjuKNbRrSwf3bBsOsVY8PHz58+PDN+M4Os5nq2VZ93j7PI49/rsKHDx8+fPhGfJuHaFvRZ6HzeKINNaInxIcPHz58+Eq+NtROwu5NeTErO2Zl1uaqKL7Hhw8fPnz4fp2fLZjbpnLbit7cM2+9J59/E5Hgw4cPHz58JV9R0SxKjfba4XK9HGsTOhy4HT58+PDh+0q+JFhPiow8HG+3guUEd3zyTfyBDx8+fPjwjfhmTLN4PY/FZzH93WP9J6zHhw8fPnz4Sr7riDz/Id9s/5oVLnlYkMccxSzw4cOHDx++km9WoGwKgrwE2T/DCiVvAODDhw8fPnwjvvxof/KTuLydfLSkL1sLx3YZ4MOHDx8+fJc7rJIFdh6a54v8TdSeN7/zdn4dJeDDhw8fPnxrvtmZtmWeb1lL/jvjaBsP+PDhw4cP355v1mZOFuebMD0vStowYlbu1BE/Pnz48OHDF//a5j/V+0V725hP7tC2/PMX8MYEHz58+PDhi/lmzeN2wZ+3t2ejb8hmjXN8+PDhw4dvz/coj/30ToX1yfO3YX1U3ODDhw8fPnwxX8txamKzJsFsu9uG700YgQ8fPnz48I34Zov/JMjOOTbL+1NBfFsS4cOHDx8+fC3fsVus295RoVA2xdsCpd0WgA8fPnz48LV8m6V+PsysJGpfwOae+Rci6nLgw4cPHz588Q6uuuopG975Y7Utgdnk91sB8OHDhw8fvrN8s01myVTzUqltFbQN8jYuwYcPHz58+PZ8m61jww1e6/u0TfFZHBCVL/jw4cOHD18gM1tC5+F1clXeks/HmkXwdXyADx8+fPjwjfj2ZUfbRK+TjNHr2b+SN/PFhw8fPnz41nz5z/YsDmhjglNR+2y9/+YqfPjw4cOHr+SblQj5kDlKAt1uRMsb8/kLHpZZ+PDhw4cPX1y+zAqCtkw5lYHvS5k2BMGHDx8+fPhmfG0psCkRji3F49fWbkorIn58+PDhw4fvg3yzgCAvm2Yb4FrQ2ZcGHz58+PDh+wxfO6U2iG/Lo01Z07YZDkQG+PDhw4cP39Gw/mzEsNlGNmsS1NEGPnz48OHDd0MqPisykoKgjRvaF5x/OTYhAj58+PDhwxfw/QEf1/KKtHAiZQAAAABJRU5ErkJggg==">分享</a><div class="tags"><a href="../../../../tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><i class="fa fa-tag"></i>机器学习笔记</a><a href="../../../../tags/%E5%91%A8%E5%BF%97%E5%8D%8E/"><i class="fa fa-tag"></i>周志华</a><a href="../../../../tags/%E5%90%B4%E6%81%A9%E8%BE%BE/"><i class="fa fa-tag"></i>吴恩达</a><a href="../../../../tags/%E6%9D%8E%E8%88%AA/"><i class="fa fa-tag"></i>李航</a></div><div class="post-nav"><a class="pre" href="../../03/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-11-%E8%81%9A%E7%B1%BB/">MachineLearning-11.聚类</a><a class="next" href="../../01/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-9-%E5%88%86%E7%B1%BB-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB/">MachineLearning-9.（分类）朴素贝叶斯分类</a></div><div class="nofancybox" id="waline"></div><script src="//unpkg.com/@waline/client@v2/dist/waline.js"></script><link rel="stylesheet" type="text/css" href="//unpkg.com/@waline/client@v2/dist/waline.css"><script>let metaInfo = ['nick', 'mail', 'link']
let requiredMeta = 'nick'.split(',').filter(item => {
  return metaInfo.indexOf(item) > -1
})
Waline.init({
  el: '#waline',
  comment: true,
  serverURL: 'https://waline-deeplearner.vercel.app',
  pageSize: '10',
  wordLimit: '500',
  requiredMeta,
})
</script></div></div></div><div class="pure-u-1 pure-u-md-1-4"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/images/blog/avatar_new.png"/></a><p>心外无物，知行合一</p><a class="info-icon" href="/resume/" title="个人简历" target="_blank" style="margin-inline:5px"> <i class="fa fa-share-square" style="margin-inline:5px"></i></a><a class="info-icon" href="mailto:conghaoyuan@gmail.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/conghaoyuan" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a><a class="info-icon" href="/atom.xml" title="RSS" target="_blank" style="margin-inline:5px"> <i class="fa fa-rss-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/AIGC/">AIGC</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Algorithm/">Algorithm</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/CV/">CV</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/GUI/">GUI</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/NLP/">NLP</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Python/">Python</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E5%AD%97%E4%BA%BA/">数字人</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E5%AD%A6/">数学</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/">深度学习框架</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B/">深度学习模型</a><span class="category-list-count">11</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="../../../../2025/03/06/AIGC-LLM-%E8%BE%9F%E9%82%AA%E5%89%91%E8%B0%B1%E4%B9%8BPrompt%20Engineering/">AIGC-LLM-辟邪剑谱之Prompt Engineering</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/11/18/AIGC-Agent-%E4%BD%9C%E6%96%87%E6%89%B9%E6%94%B9%E6%A0%87%E6%B3%A8/">AIGC-Agent-作文批改标注</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/09/27/LLama32%E8%B0%83%E7%A0%94/">LLama3.2调研报告</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/04/09/AIGC-LLM-Prompt%E6%8A%80%E8%83%BD/">AIGC-LLM-Prompt工程技能综述</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/03/05/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-BERT/">Deeeplearning模型-NLP-BERT</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/01/16/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E8%AF%AD%E6%96%99%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7/">Deeeplearning模型-NLP-大语言模型微调语料生成工具</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/12/05/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-Transformer%E6%A8%A1%E5%9E%8B/">Deeeplearning模型-NLP-Transformer模型</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/12/01/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-NLP%E5%9F%BA%E7%A1%80/">Deeeplearning模型-NLP-NLP基础</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/10/26/%E6%95%B0%E5%AD%97%E4%BA%BA-%E6%95%B0%E5%AD%97%E4%BA%BA%E6%8A%80%E6%9C%AF%E6%95%88%E6%9E%9C%E5%AF%B9%E6%AF%94/">数字人-数字人技术效果对比</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/10/13/GUI-%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E6%89%93%E5%8C%85%E4%B8%8E%E5%AE%89%E8%A3%85/">GUI-应用程序打包与安装</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://conghaoyuan.github.io" title="Fern[个人早期博客]" target="_blank">Fern[个人早期博客]</a></div><div class="widget"><div class="widget-title"><i class="fa fa-star"> 天文学</i></div><ul></ul><a href="/tools/tianwenli.html" title="天文历" target="_self">天文历</a></div><div class="widget"><div class="widget-title"><i class="fa fa-plus"> 数学小工具</i></div><ul></ul><a href="/tools/buy_house.html" title="丐版买房计算器" target="_self">丐版买房计算器</a><ul></ul><a href="/tools/equation_12.html" title="一元二次方程" target="_self">一元二次方程</a><ul></ul><a href="/tools/equation_line.html" title="直线方程" target="_self">直线方程</a><ul></ul><a href="/tools/equation_polynomial.html" title="多项式方程" target="_self">多项式方程</a><ul></ul><a href="/tools/regression_ridge.html" title="岭回归" target="_self">岭回归</a><ul></ul><a href="/tools/fourier_transform.html" title="傅里叶变换" target="_self">傅里叶变换</a><ul></ul><a href="/tools/gradient_descent.html" title="梯度下降" target="_self">梯度下降</a><ul></ul><a href="/tools/function_e.html" title="指数函数" target="_self">指数函数</a><ul></ul><a href="/tools/function_inverse_scale.html" title="反比例函数" target="_self">反比例函数</a><ul></ul><a href="/tools/function_log.html" title="对数函数" target="_self">对数函数</a><ul></ul><a href="/tools/function_sin.html" title="正弦函数" target="_self">正弦函数</a><ul></ul><a href="/tools/coord_grid.html" title="网格化坐标" target="_self">网格化坐标</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="../../../../." rel="nofollow">DeepLearner.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="../../../../js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="../../../../js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="../../../../css/search.css?v=1.0.0"><script type="text/javascript" src="../../../../js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="/static/js/MathJax.js?config=TeX-MML-AM_CHTML" async></script><div id="script" type="text/javascript" src="../../../../js/mathjaxs.js" async></div><script type="text/javascript" src="../../../../js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="../../../../js/smartresize.js?v=1.0.0"></script></div><!-- hexo injector body_end start -->
<script src="assets/prism-bundle.js"></script>
<script src="assets/prism-plus.js" data-pjax=""></script>
<!-- hexo injector body_end end --></body></html>