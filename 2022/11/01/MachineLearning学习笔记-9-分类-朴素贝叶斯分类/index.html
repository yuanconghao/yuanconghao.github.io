<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Just Do It"><title>MachineLearning-9.（分类）朴素贝叶斯分类 | DeepLearner</title><link rel="stylesheet" type="text/css" href="../../../../css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="/static/css/normalize.css"><link rel="stylesheet" type="text/css" href="/static/css/pure-min.css"><link rel="stylesheet" type="text/css" href="/static/css/grids-responsive-min.css"><link rel="stylesheet" href="/static/css/font-awesome.min.css"><script type="text/javascript" src="/static/js/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="../../../../favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="../../../../favicon.ico"><link rel="apple-touch-icon" href="../../../../apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="../../../../apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="../../../../atom.xml"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-83251621-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + 'b207d9febf3295d375e6e9b42006f9eb';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/static/js/clipboard.min.js"></script><script type="text/javascript" src="/static/js/toastr.min.js"></script><link rel="stylesheet" href="/static/css/toastr.min.css"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">MachineLearning-9.（分类）朴素贝叶斯分类</h1><a id="logo" href="../../../../.">DeepLearner</a><p class="description">Deep Learning Notes</p></div><div id="nav-menu"><a class="current" href="../../../../."><i class="fa fa-home"> 首页</i></a><a href="../../../../archives/"><i class="fa fa-archive"> 归档</i></a><a href="../../../../tagcloud/"><i class="fa fa-tags"> 标签</i></a><a href="../../../../resource/"><i class="fa fa-cloud"> 资源</i></a><a href="../../../../guestbook/"><i class="fa fa-wechat"> 留言</i></a><a href="../../../../codeline/"><i class="fa fa-circle"> 码迹</i></a><a href="../../../../resume/"><i class="fa fa-user"> 个人简历</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">MachineLearning-9.（分类）朴素贝叶斯分类</h1><div class="post-meta">created:2022-11-01</div><div class="post-meta">updated:2023-07-30<span> | </span><span class="category"><a href="../../../../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><a class="disqus-comment-count" href="#waline"><span class="waline-comment-count" id=""></span><span> 条评论</span></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="toc-number">1.</span> <span class="toc-text">概率基础知识</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E5%AE%9A%E4%B9%89"><span class="toc-number">1.1.</span> <span class="toc-text">概率定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%81%94%E5%90%88%E6%A6%82%E7%8E%87%E4%B8%8E%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87"><span class="toc-number">1.2.</span> <span class="toc-text">联合概率与条件概率</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%81%94%E5%90%88%E6%A6%82%E7%8E%87"><span class="toc-number">1.2.1.</span> <span class="toc-text">联合概率</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87"><span class="toc-number">1.2.2.</span> <span class="toc-text">条件概率</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BA%8B%E4%BB%B6%E7%9A%84%E7%8B%AC%E7%AB%8B%E6%80%A7"><span class="toc-number">1.2.3.</span> <span class="toc-text">事件的独立性</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87%E4%B8%8E%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87"><span class="toc-number">1.3.</span> <span class="toc-text">先验概率与后验概率</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87"><span class="toc-number">1.3.1.</span> <span class="toc-text">先验概率</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87"><span class="toc-number">1.3.2.</span> <span class="toc-text">后验概率</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%A4%E8%80%85%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">1.3.3.</span> <span class="toc-text">两者的关系</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86"><span class="toc-number">2.</span> <span class="toc-text">贝叶斯定理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86%E5%AE%9A%E4%B9%89"><span class="toc-number">2.1.</span> <span class="toc-text">贝叶斯定理定义</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">3.</span> <span class="toc-text">朴素贝叶斯分类器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%E5%8E%9F%E7%90%86"><span class="toc-number">3.1.</span> <span class="toc-text">朴素贝叶斯分类器原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.2.</span> <span class="toc-text">朴素贝叶斯分类器实现</span></a></li></ol></li></ol></div></div><div class="post-content"><p>朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法。“朴素”的含义为：假设问题的特征变量都是相互独立地作用于决策变量的，即问题的特征之间都是互不相关的。其为多用途分类器，广泛应用于垃圾邮件过滤、自然语言处理等. </p>
<p>朴素贝叶斯优点：逻辑性简单，易训练；算法较为稳定，当数据呈现不同特点时，其分类性能不会有太大差异；样本特征之间的关系相对比较独立时，朴素贝叶斯分类算法会有较好的效果。</p>
<p>朴素贝叶斯缺点：特征独立性很难满足，样本特征之间往往存在互相关联，会导致分类效果降低。</p>
<p>朴素贝叶斯使用场景：根据先验概率计算后验概率的情况，且样本特征之间独立性较强。</p>
<span id="more"></span>

<h3 id="概率基础知识"><a href="#概率基础知识" class="headerlink" title="概率基础知识"></a>概率基础知识</h3><h4 id="概率定义"><a href="#概率定义" class="headerlink" title="概率定义"></a>概率定义</h4><p>概率反映随机事件出现的可能性大小。随机事件是指在相同条件下，可能出现也可能不出现的事件。将随机事件记为A或B，P(A)，P(B)表示事件A或B的概率。</p>
<h4 id="联合概率与条件概率"><a href="#联合概率与条件概率" class="headerlink" title="联合概率与条件概率"></a>联合概率与条件概率</h4><h5 id="联合概率"><a href="#联合概率" class="headerlink" title="联合概率"></a>联合概率</h5><p>指包含多个条件且所有条件同时成立的概率，记作$P ( A , B )$ ，或$P(AB)$，或$P(A \bigcap B)$</p>
<h5 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h5><p>已知事件B发生的条件下，另一个事件A发生的概率称为条件概率，记为：$P(A|B)$</p>
<h5 id="事件的独立性"><a href="#事件的独立性" class="headerlink" title="事件的独立性"></a>事件的独立性</h5><p>事件A不影响事件B的发生，称这两个事件独立，记为：<br>$$<br>P(AB)&#x3D;P(A)P(B)<br>$$<br>因为A和B不相互影响，则有：<br>$$<br>P(A|B) &#x3D; P(A)<br>$$<br>可以理解为，给定或不给定B的条件下，A的概率都一样大。</p>
<h4 id="先验概率与后验概率"><a href="#先验概率与后验概率" class="headerlink" title="先验概率与后验概率"></a>先验概率与后验概率</h4><h5 id="先验概率"><a href="#先验概率" class="headerlink" title="先验概率"></a>先验概率</h5><p>先验概率也是根据以往经验和分析得到的概率，例如：在没有任何信息前提的情况下，猜测对面来的陌生人姓氏，姓李的概率最大（因为全国李姓为占比最高的姓氏），这便是先验概率. </p>
<h5 id="后验概率"><a href="#后验概率" class="headerlink" title="后验概率"></a>后验概率</h5><p>后验概率是指在接收了一定条件或信息的情况下的修正概率，例如：在知道对面的人来自“牛家村”的情况下，猜测他姓牛的概率最大，但不排除姓杨、李等等，这便是后验概率. </p>
<h5 id="两者的关系"><a href="#两者的关系" class="headerlink" title="两者的关系"></a>两者的关系</h5><p>事情还没有发生，求这件事情发生的可能性的大小，是先验概率（可以理解为由因求果）. 事情已经发生，求这件事情发生的原因是由某个因素引起的可能性的大小，是后验概率（由果求因）. 先验概率与后验概率有不可分割的联系，后验概率的计算要以先验概率为基础. </p>
<h3 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h3><h4 id="贝叶斯定理定义"><a href="#贝叶斯定理定义" class="headerlink" title="贝叶斯定理定义"></a>贝叶斯定理定义</h4><p>贝叶斯定理由英国数学家托马斯.贝叶斯 ( Thomas Bayes)提出，用来描述两个条件概率之间的关系，定理描述为：<br>$$<br>P(A|B) &#x3D; \frac{P(A)P(B|A)}{P(B)}<br>$$<br>其中，$P(A)$和$P(B)$是A事件和B事件发生的概率. $P(A|B)$称为条件概率，表示B事件发生条件下，A事件发生的概率. 推导过程：<br>$$<br>P(A,B) &#x3D;P(B)P(A|B)\<br>P(B,A) &#x3D;P(A)P(B|A)<br>$$<br>其中$P(A,B)$称为联合概率，指事件B发生的概率，乘以事件A在事件B发生的条件下发生的概率. 因为$P(A,B)&#x3D;P(B,A)$, 所以有：<br>$$<br>P(B)P(A|B)&#x3D;P(A)P(B|A)<br>$$<br>两边同时除以P(B)，则得到贝叶斯定理的表达式. 其中，$P(A)$是先验概率，$P(A|B)$是已知B发生后A的条件概率，也被称作后验概率. </p>
<h3 id="朴素贝叶斯分类器"><a href="#朴素贝叶斯分类器" class="headerlink" title="朴素贝叶斯分类器"></a>朴素贝叶斯分类器</h3><h4 id="朴素贝叶斯分类器原理"><a href="#朴素贝叶斯分类器原理" class="headerlink" title="朴素贝叶斯分类器原理"></a>朴素贝叶斯分类器原理</h4><p>朴素贝叶斯分类器就是根据贝叶斯公式计算结果进行分类的模型，“朴素”指事件之间相互独立无影响. 例如：有如下数据集：</p>
<table>
<thead>
<tr>
<th>Text</th>
<th>Category</th>
</tr>
</thead>
<tbody><tr>
<td>A great game（一个伟大的比赛）</td>
<td>Sports（体育运动）</td>
</tr>
<tr>
<td>The election was over（选举结束）</td>
<td>Not sports（不是体育运动）</td>
</tr>
<tr>
<td>Very clean match（没内幕的比赛）</td>
<td>Sports（体育运动）</td>
</tr>
<tr>
<td>A clean but forgettable game（一场难以忘记的比赛）</td>
<td>Sports（体育运动）</td>
</tr>
<tr>
<td>It was a close election（这是一场势均力敌的选举）</td>
<td>Not sports（不是体育运动）</td>
</tr>
</tbody></table>
<p>求：”A very close game“ 是体育运动的概率？数学上表示为 P(Sports | a very close game)​. 根据贝叶斯定理，是运动的概率可以表示为：<br>$$<br>P(Sports | a \ very \ close \ game) &#x3D; \frac{P(a \ very \ close \ game | sports) * P(sports)}{P(a \ very \ close \ game)}<br>$$<br>不是运动概率可以表示为：<br>$$<br>P(Not \ Sports | a \ very \ close \ game) &#x3D; \frac{P(a \ very \ close \ game | Not \ sports) * P(Not \ sports)}{P(a \ very \ close \ game)}<br>$$<br>概率更大者即为分类结果. 由于分母相同，即比较分子谁更大即可.  我们只需统计”A very close game“ 多少次出现在Sports类别中，就可以计算出上述两个概率.  但是”A very close game“ 并没有出现在数据集中，所以这个概率为0，要解决这个问题，就假设每个句子的单词出现都与其它单词无关（事件独立即朴素的含义），所以，P(a very close game)可以写成：<br>$$<br>P(a \ very \ close \ game) &#x3D; P(a) * P(very) * P(close) * P(game)<br>$$</p>
<p>$$<br>P（a \ very \ close \ game|Sports)&#x3D; \ P(a|Sports)*P(very|Sports)*P(close|Sports)*P(game|Sports)<br>$$</p>
<p>统计出“a”, “very”, “close”, “game”出现在”Sports”类别中的概率，就能算出其所属的类别. 具体计算过程如下：</p>
<ul>
<li><p>第一步：计算总词频：Sports类别词语总数14，Not Sports类别词语总数9</p>
</li>
<li><p>第二步：计算每个类别的先验概率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Sports和Not Sports概率</span></span><br><span class="line">P(Sports) = <span class="number">3</span> / <span class="number">5</span> = <span class="number">0.6</span> </span><br><span class="line">P(Not Sports) = <span class="number">2</span> / <span class="number">5</span> = <span class="number">0.4</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># Sports条件下各个词语概率</span></span><br><span class="line">P(a | Sports) = (<span class="number">2</span> + <span class="number">1</span>) / (<span class="number">11</span> + <span class="number">14</span>) = <span class="number">0.12</span></span><br><span class="line">P(very | Sports) = (<span class="number">1</span> + <span class="number">1</span>) / (<span class="number">11</span> + <span class="number">14</span>) = <span class="number">0.08</span></span><br><span class="line">P(close | Sports) = (<span class="number">0</span> + <span class="number">1</span>) / (<span class="number">11</span> + <span class="number">14</span>) = <span class="number">0.04</span></span><br><span class="line">P(game | Sports) = (<span class="number">2</span> + <span class="number">1</span>) / (<span class="number">11</span> + <span class="number">14</span>) = <span class="number">0.12</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Not Sports条件下各个词语概率</span></span><br><span class="line">P(a | Not Sports) = (<span class="number">1</span> + <span class="number">1</span>) / (<span class="number">9</span> + <span class="number">14</span>) = <span class="number">0.087</span></span><br><span class="line">P(very | Not Sports) = (<span class="number">0</span> + <span class="number">1</span>) / (<span class="number">9</span> + <span class="number">14</span>) = <span class="number">0.043</span></span><br><span class="line">P(close | Not Sports) = (<span class="number">1</span> + <span class="number">1</span>) / (<span class="number">9</span> + <span class="number">14</span>) =  = <span class="number">0.087</span></span><br><span class="line">P(game | Not Sports) = (<span class="number">0</span> + <span class="number">1</span>) / (<span class="number">9</span> + <span class="number">14</span>) = <span class="number">0.043</span></span><br></pre></td></tr></table></figure>

<p>其中，分子部分加1，是为了避免分子为0的情况；分母部分都加了词语总数14，是为了避免分子增大的情况下计算结果超过1的可能. </p>
</li>
<li><p>第三步：将先验概率带入贝叶斯定理，计算概率：</p>
<p>是体育运动的概率：</p>
</li>
</ul>
<p>$$<br>P（a \ very \ close \ game|Sports)&#x3D; \ P(a|Sports)*P(very|Sports)*P(close|Sports)*P(game|Sports)&#x3D; \<br>0.12 * 0.08 * 0.04 * 0.12 &#x3D; 0.00004608<br>$$</p>
<p>​       不是体育运动的概率：<br>$$<br>P（a \ very \ close \ game|Not \ Sports)&#x3D; \<br>P(a|Not \ Sports)*P(very|Not \ Sports)*P(close|Not \ Sports)*P(game|Not \ Sports)&#x3D; \<br>0.087 * 0.043 * 0.087 * 0.043 &#x3D; 0.000013996<br>$$<br>分类结果：P(Sports) &#x3D; 0.00004608 , P(Not Sports) &#x3D; 0.000013996， 是体育运动.</p>
<h4 id="朴素贝叶斯分类器实现"><a href="#朴素贝叶斯分类器实现" class="headerlink" title="朴素贝叶斯分类器实现"></a>朴素贝叶斯分类器实现</h4><p>在sklearn中，提供了三个朴素贝叶斯分类器，分别是：</p>
<ul>
<li>GaussianNB（高斯朴素贝叶斯分类器）：适合用于样本的值是连续的，数据呈正态分布的情况（比如人的身高、城市家庭收入、一次考试的成绩等等）</li>
<li>MultinominalNB（多项式朴素贝叶斯分类器）：适合用于大部分属性为离散值的数据集</li>
<li>BernoulliNB（伯努利朴素贝叶斯分类器）：适合用于特征值为二元离散值或是稀疏的多元离散值的数据集</li>
</ul>
<p>该示例中，样本的值为连续值，且呈正态分布，所以采用GaussianNB模型. 代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 朴素贝叶斯分类示例</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.naive_bayes <span class="keyword">as</span> nb</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> mp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入，输出</span></span><br><span class="line">x, y = [], []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据文件</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;../data/multiple1.txt&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">        data = [<span class="built_in">float</span>(substr) <span class="keyword">for</span> substr <span class="keyword">in</span> line.split(<span class="string">&quot;,&quot;</span>)]</span><br><span class="line">        x.append(data[:-<span class="number">1</span>])  <span class="comment"># 输入样本：取从第一列到倒数第二列</span></span><br><span class="line">        y.append(data[-<span class="number">1</span>])  <span class="comment"># 输出样本：取最后一列</span></span><br><span class="line"></span><br><span class="line">x = np.array(x)</span><br><span class="line">y = np.array(y, dtype=<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建高斯朴素贝叶斯分类器对象</span></span><br><span class="line">model = nb.GaussianNB()</span><br><span class="line">model.fit(x, y)  <span class="comment"># 训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算显示范围</span></span><br><span class="line">left = x[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span></span><br><span class="line">right = x[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">buttom = x[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span></span><br><span class="line">top = x[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">grid_x, grid_y = np.meshgrid(np.arange(left, right, <span class="number">0.01</span>),</span><br><span class="line">                             np.arange(buttom, top, <span class="number">0.01</span>))</span><br><span class="line"></span><br><span class="line">mesh_x = np.column_stack((grid_x.ravel(), grid_y.ravel()))</span><br><span class="line">mesh_z = model.predict(mesh_x)</span><br><span class="line">mesh_z = mesh_z.reshape(grid_x.shape)</span><br><span class="line"></span><br><span class="line">mp.figure(<span class="string">&#x27;Naive Bayes Classification&#x27;</span>, facecolor=<span class="string">&#x27;lightgray&#x27;</span>)</span><br><span class="line">mp.title(<span class="string">&#x27;Naive Bayes Classification&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">mp.xlabel(<span class="string">&#x27;x&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.ylabel(<span class="string">&#x27;y&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.pcolormesh(grid_x, grid_y, mesh_z, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">mp.scatter(x[:, <span class="number">0</span>], x[:, <span class="number">1</span>], c=y, cmap=<span class="string">&#x27;brg&#x27;</span>, s=<span class="number">80</span>)</span><br><span class="line">mp.show()</span><br></pre></td></tr></table></figure>

<p>执行结果：</p>
<img src="/images/ml/classification/naive_bayes.png" alt="" width="400px" style="border:1px solid black;" />


</div><script type="text/javascript" src="../../../../js/share.js?v=1.0.0" async></script><a class="article-share-link" data-url="https://deeplearner.top/2022/11/01/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-9-%E5%88%86%E7%B1%BB-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB/" data-id="clkor69po00itc6s62qn26mvn" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAT4AAAE+CAAAAAAxUyPsAAAFPUlEQVR42u3bwa4aMRAEQP7/p8klN2DpnvGiSClOEQ927TLSjnucxyN+PctX/t3XT75+Kxnbp3u9fuZ6bI87Xvjw4cOHD185vWuU68l8+uv1xD7dJZlwy5Hc5eM18eHDhw8fvhFfXhDkfPvCZTbt/VyS6+DDhw8fPny/4duUDtcDbe/4HL2SBcOHDx8+fPj+Bb58ku32Pt/Yz76bJ+348OHDhw/fb/hyiH1Y37bVZ1duC6nbex348OHDhw9f+YD/f/59+IUPHz58+PAtwu4kPsg3/LNi4r6ipBDAhw8fPnz4Rv3iNpS/I0ZPPj8L05MgfhaX4MOHDx8+fC1fcrwsoWkPhCWTaUP5Wayf/1C+lCz48OHDhw9furOu/3tVdNFFTJC8014hiQySGX2J7PHhw4cPH76j3d49/Sz63yQiydK2pcyb6g8fPnz48OGL+VqOTTR/6pNtuD+rOpJCBx8+fPjw4Wv58m3/b4LyvLzII4A2XCjGiQ8fPnz48I342oNfeU2UXz//7uyabTMgKrPw4cOHDx++mG8ffM8OkJ1dyNmY25G/+Ss+fPjw4cO3Tpv3be9ZWTA7WJYH8XlYny8kPnz48OHD1/Ll4XjysE8mmR93y5sHLcSsKf5mPPjw4cOHD9+Ir8j146NdbRixaYrnEUO+eNGhN3z48OHDh2/ENytBkjSiDc03IfsMMb/mx14HPnz48OHDV/LNbt8G3/sGwKzEyYOGduHx4cOHDx++lq+dRrtd3xxlmxU0efn1HL3w4cOHDx++DV/+OJ+FCzlZi94uT97az4N7fPjw4cOHr+XLG+F5q7u9TruZb9vbm4JpdRoNHz58+PDhC/q8s6dzsj55ED8rs9qyJl/+j5/Ehw8fPnz4Sr68IJgd/Mqnl993E+LnUcKB+AAfPnz48OELCpdT095E8DnKJjKYFUb48OHDhw/fhi+5XB61t6ybAqJ9fxZqRGEHPnz48OHDN+JrY+vkBvnmf9MkOHXNWasAHz58+PDhy/nazXkyxLxpvTlcnpRZ+XLmwUQxVXz48OHDh+8ysp8F7tcBdz7o2ba/pZ99Hh8+fPjw4TvLlwAlExgmFuvm/b7A2vxQ8OHDhw8fvpYvaXvPNttJZJ9fPymq2pIrKa3w4cOHDx++u/k2x8LakuK5frXjzJehCOvx4cOHDx++sk2eFAF58ZF/KwkFNu35+xrn+PDhw4cPX8s3m8Bme3+2QNksWx5kRGEEPnz48OHDF/DlJUL+13rdDk1m07wfEuPDhw8fPnxrvnzz3Ibvs88n5dGs0Z4vAD58+PDhw3cfX/7Ib4+IbdrteegwO/Q2nB0+fPjw4cM3ml37sN83nnPiWXzfNgxadHz48OHDh2/Dt9nqb6L5/Pja2Tu2ZVZxQA0fPnz48OELxrl58G+GMosS8shgEzHkzXt8+PDhw4ev5Wtj61lDOml+twRtK31zYC76DeLDhw8fPnyXfG0Tur3xfa30ttG+vxo+fPjw4cN3iq8tBZLoPF+YWTHRtgHasD66Lz58+PDhw7fmS0qWZNpnA4K2gZ3PYlay/P03Pnz48OHDN69D6oB+Vpoky5CXRG0ccF2ytD8RfPjw4cOHb8Y3e8zPiPfh+yzc33zry3jw4cOHDx++EV+y7Z9tto9tvNeF16krfDlrgA8fPnz48B3ia5vNefnSvr8pO9plHq4MPnz48OHDt+bbP+ZnLfBkDLOlTRb1Cy4+fPjw4cM34rv7ONesQPnN5n9T6ODDhw8fPnwt3+aW7UXbomTWEkjGcGo58eHDhw8fvvj9P6llAsHTT+OCAAAAAElFTkSuQmCC">分享</a><div class="tags"><a href="../../../../tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><i class="fa fa-tag"></i>机器学习笔记</a><a href="../../../../tags/%E5%91%A8%E5%BF%97%E5%8D%8E/"><i class="fa fa-tag"></i>周志华</a><a href="../../../../tags/%E5%90%B4%E6%81%A9%E8%BE%BE/"><i class="fa fa-tag"></i>吴恩达</a><a href="../../../../tags/%E6%9D%8E%E8%88%AA/"><i class="fa fa-tag"></i>李航</a></div><div class="post-nav"><a class="pre" href="../../02/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-10-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E4%BC%98%E5%8C%96/">MachineLearning-10.模型评估与优化</a><a class="next" href="../../../10/31/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-8-%E5%88%86%E7%B1%BB-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/">MachineLearning-8.（分类）支持向量机SVM</a></div><div class="nofancybox" id="waline"></div><script src="//unpkg.com/@waline/client@v2/dist/waline.js"></script><link rel="stylesheet" type="text/css" href="//unpkg.com/@waline/client@v2/dist/waline.css"><script>let metaInfo = ['nick', 'mail', 'link']
let requiredMeta = 'nick'.split(',').filter(item => {
  return metaInfo.indexOf(item) > -1
})
Waline.init({
  el: '#waline',
  comment: true,
  serverURL: 'https://waline-deeplearner.vercel.app',
  pageSize: '10',
  wordLimit: '500',
  requiredMeta,
})
</script></div></div></div><div class="pure-u-1 pure-u-md-1-4"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/images/blog/avatar_new.png"/></a><p>心外无物，知行合一</p><a class="info-icon" href="/resume/" title="个人简历" target="_blank" style="margin-inline:5px"> <i class="fa fa-share-square" style="margin-inline:5px"></i></a><a class="info-icon" href="mailto:conghaoyuan@gmail.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/conghaoyuan" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a><a class="info-icon" href="/atom.xml" title="RSS" target="_blank" style="margin-inline:5px"> <i class="fa fa-rss-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/AIGC/">AIGC</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Algorithm/">Algorithm</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/CV/">CV</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/GUI/">GUI</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/NLP/">NLP</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Python/">Python</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E5%AD%97%E4%BA%BA/">数字人</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E5%AD%A6/">数学</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/">深度学习框架</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B/">深度学习模型</a><span class="category-list-count">11</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="../../../../2025/03/10/AIGC-LLM-%E8%BE%9F%E9%82%AA%E5%89%91%E8%B0%B1%E4%B9%8B%E9%80%9A%E4%B9%89Prompt%E5%9B%9B%E5%8D%81%E5%BC%8F/">AIGC-LLM-辟邪剑谱之通义Prompt四十式</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2025/03/06/AIGC-LLM-%E8%BE%9F%E9%82%AA%E5%89%91%E8%B0%B1%E4%B9%8BPrompt%20Engineering/">AIGC-LLM-辟邪剑谱之Prompt Engineering</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/11/18/AIGC-Agent-%E4%BD%9C%E6%96%87%E6%89%B9%E6%94%B9%E6%A0%87%E6%B3%A8/">AIGC-Agent-作文批改标注</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/09/27/LLama32%E8%B0%83%E7%A0%94/">LLama3.2调研报告</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/04/09/AIGC-LLM-Prompt%E6%8A%80%E8%83%BD/">AIGC-LLM-Prompt工程技能综述</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/03/05/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-BERT/">Deeeplearning模型-NLP-BERT</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/01/16/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E8%AF%AD%E6%96%99%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7/">Deeeplearning模型-NLP-大语言模型微调语料生成工具</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/12/05/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-Transformer%E6%A8%A1%E5%9E%8B/">Deeeplearning模型-NLP-Transformer模型</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/12/01/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-NLP%E5%9F%BA%E7%A1%80/">Deeeplearning模型-NLP-NLP基础</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/10/26/%E6%95%B0%E5%AD%97%E4%BA%BA-%E6%95%B0%E5%AD%97%E4%BA%BA%E6%8A%80%E6%9C%AF%E6%95%88%E6%9E%9C%E5%AF%B9%E6%AF%94/">数字人-数字人技术效果对比</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://conghaoyuan.github.io" title="Fern[个人早期博客]" target="_blank">Fern[个人早期博客]</a></div><div class="widget"><div class="widget-title"><i class="fa fa-star"> 天文学</i></div><ul></ul><a href="/tools/tianwenli.html" title="天文历" target="_self">天文历</a></div><div class="widget"><div class="widget-title"><i class="fa fa-plus"> 数学小工具</i></div><ul></ul><a href="/tools/buy_house.html" title="丐版买房计算器" target="_self">丐版买房计算器</a><ul></ul><a href="/tools/equation_12.html" title="一元二次方程" target="_self">一元二次方程</a><ul></ul><a href="/tools/equation_line.html" title="直线方程" target="_self">直线方程</a><ul></ul><a href="/tools/equation_polynomial.html" title="多项式方程" target="_self">多项式方程</a><ul></ul><a href="/tools/regression_ridge.html" title="岭回归" target="_self">岭回归</a><ul></ul><a href="/tools/fourier_transform.html" title="傅里叶变换" target="_self">傅里叶变换</a><ul></ul><a href="/tools/gradient_descent.html" title="梯度下降" target="_self">梯度下降</a><ul></ul><a href="/tools/function_e.html" title="指数函数" target="_self">指数函数</a><ul></ul><a href="/tools/function_inverse_scale.html" title="反比例函数" target="_self">反比例函数</a><ul></ul><a href="/tools/function_log.html" title="对数函数" target="_self">对数函数</a><ul></ul><a href="/tools/function_sin.html" title="正弦函数" target="_self">正弦函数</a><ul></ul><a href="/tools/coord_grid.html" title="网格化坐标" target="_self">网格化坐标</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="../../../../." rel="nofollow">DeepLearner.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="../../../../js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="../../../../js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="../../../../css/search.css?v=1.0.0"><script type="text/javascript" src="../../../../js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="/static/js/MathJax.js?config=TeX-MML-AM_CHTML" async></script><div id="script" type="text/javascript" src="../../../../js/mathjaxs.js" async></div><script type="text/javascript" src="../../../../js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="../../../../js/smartresize.js?v=1.0.0"></script></div><!-- hexo injector body_end start -->
<script src="assets/prism-bundle.js"></script>
<script src="assets/prism-plus.js" data-pjax=""></script>
<!-- hexo injector body_end end --></body></html>