<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Just Do It"><title>MachineLearning-5.（回归）决策树回归 | DeepLearner</title><link rel="stylesheet" type="text/css" href="../../../../css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="/static/css/normalize.css"><link rel="stylesheet" type="text/css" href="/static/css/pure-min.css"><link rel="stylesheet" type="text/css" href="/static/css/grids-responsive-min.css"><link rel="stylesheet" href="/static/css/font-awesome.min.css"><script type="text/javascript" src="/static/js/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="../../../../favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="../../../../favicon.ico"><link rel="apple-touch-icon" href="../../../../apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="../../../../apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="../../../../atom.xml"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-83251621-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + 'b207d9febf3295d375e6e9b42006f9eb';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/static/js/clipboard.min.js"></script><script type="text/javascript" src="/static/js/toastr.min.js"></script><link rel="stylesheet" href="/static/css/toastr.min.css"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">MachineLearning-5.（回归）决策树回归</h1><a id="logo" href="../../../../.">DeepLearner</a><p class="description">Deep Learning Notes</p></div><div id="nav-menu"><a class="current" href="../../../../."><i class="fa fa-home"> 首页</i></a><a href="../../../../archives/"><i class="fa fa-archive"> 归档</i></a><a href="../../../../tagcloud/"><i class="fa fa-tags"> 标签</i></a><a href="../../../../resource/"><i class="fa fa-cloud"> 资源</i></a><a href="../../../../guestbook/"><i class="fa fa-wechat"> 留言</i></a><a href="../../../../codeline/"><i class="fa fa-circle"> 码迹</i></a><a href="../../../../resume/"><i class="fa fa-user"> 个人简历</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">MachineLearning-5.（回归）决策树回归</h1><div class="post-meta">created:2022-10-28</div><div class="post-meta">updated:2023-07-30<span> | </span><span class="category"><a href="../../../../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><a class="disqus-comment-count" href="#waline"><span class="waline-comment-count" id=""></span><span> 条评论</span></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E6%A0%91"><span class="toc-number">1.</span> <span class="toc-text">回归树</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Cart%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">1.1.</span> <span class="toc-text">Cart决策树</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%EF%BC%88%E5%88%92%E5%88%86%E8%AE%AD%E7%BB%83%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%EF%BC%89"><span class="toc-number">1.2.</span> <span class="toc-text">读取数据（划分训练集和测试集）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E5%86%B3%E7%AD%96%E6%A0%91%E5%9B%9E%E5%BD%92%E5%99%A8%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.3.</span> <span class="toc-text">创建决策树回归器模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E5%90%88%E7%AE%97%E6%B3%95%E2%80%8B"><span class="toc-number">2.</span> <span class="toc-text">集合算法​</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Boosting%E7%B1%BB%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.1.</span> <span class="toc-text">Boosting类模型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#AdaBoost%E6%A8%A1%E5%9E%8B%EF%BC%88%E6%AD%A3%E5%90%91%E6%BF%80%E5%8A%B1%EF%BC%89"><span class="toc-number">2.1.1.</span> <span class="toc-text">AdaBoost模型（正向激励）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#GBDT"><span class="toc-number">2.1.2.</span> <span class="toc-text">GBDT</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Bagging%E7%B1%BB%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.2.</span> <span class="toc-text">Bagging类模型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%87%AA%E5%8A%A9%E8%81%9A%E5%90%88"><span class="toc-number">2.2.1.</span> <span class="toc-text">自助聚合</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-number">2.2.2.</span> <span class="toc-text">随机森林</span></a></li></ol></li></ol></li></ol></div></div><div class="post-content"><p>决策树回归核心：划分点选择 + 输出值确定 <font color="#ff0000"><sup>[<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/42505644">1</a>]</sup></font>。<br>决策树是一种基本的分类与回归方法，回归决策树主要指CART(classification and regression tree)算法，内部结点特征的取值为“是”和“否”， 为二叉树结构。</p>
<span id="more"></span>

<h3 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h3><h4 id="Cart决策树"><a href="#Cart决策树" class="headerlink" title="Cart决策树"></a>Cart决策树</h4><p>sklearn提供的决策树底层为Cart树（Classification and Regression Tree），Cart回归树在解决回归问题时的步骤如下：</p>
<ol>
<li>原始数据集S，此时树的深度depth&#x3D;0；</li>
<li>针对集合S，遍历每一个特征的每一个value（遍历数据中的所有离散值（12个））<br>用该value将原数据集S分裂成2个集合：左集合left(&lt;&#x3D;value的样本)、右集合right(&gt;value的样本)，<br>分别计算这2个集合的mse(均方误差)，找到使（left_mse+right_mse）最小的那个value，记录下此时的特征名称和value，这个就是最佳分割特征以及最佳分割值；</li>
<li>找到最佳分割特征以及最佳分割value之后，用该value将集合S分裂成2个集合，depth+&#x3D;1；</li>
<li>针对集合left、right分别重复步骤2,3，直到达到终止条件。</li>
</ol>
<p>决策树底层结构为二叉树</p>
<figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">终止条件有如下几种：</span><br><span class="line">    <span class="number">1</span>.特征已经用完了：没有可供使用的特征再进行分裂了，则树停止分裂；</span><br><span class="line">    <span class="number">2</span>.子节点中没有样本了：此时该结点已经没有样本可供划分，该结点停止分裂；</span><br><span class="line">    <span class="number">3</span>.树达到了人为预先设定的最大深度：depth &gt;<span class="operator">=</span> max_depth，树停止分裂。</span><br><span class="line">    <span class="number">4</span>.节点的样本数量达到了人为设定的阈值：样本数量 &lt; min_samples_split ，则该节点停止分裂；</span><br></pre></td></tr></table></figure>

<p>决策树回归器模型相关API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.tree <span class="keyword">as</span> st</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建决策树回归器模型  决策树的最大深度为4</span></span><br><span class="line">model = st.DecisionTreeRegressor(max_depth=<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 训练模型  </span></span><br><span class="line"><span class="comment"># train_x： 二维数组样本数据</span></span><br><span class="line"><span class="comment"># train_y： 训练集中对应每行样本的结果</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 测试模型</span></span><br><span class="line">pred_test_y = model.predict(test_x)</span><br></pre></td></tr></table></figure>

<p>案例：预测波士顿地区房屋价格。</p>
<h4 id="读取数据（划分训练集和测试集）"><a href="#读取数据（划分训练集和测试集）" class="headerlink" title="读取数据（划分训练集和测试集）"></a>读取数据（划分训练集和测试集）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.datasets <span class="keyword">as</span> sd</span><br><span class="line"><span class="keyword">import</span> sklearn.utils <span class="keyword">as</span> su</span><br><span class="line"><span class="comment"># 加载波士顿地区房价数据集</span></span><br><span class="line">boston = sd.load_boston()</span><br><span class="line"><span class="built_in">print</span>(boston.feature_names)</span><br><span class="line"><span class="comment"># |CRIM|ZN|INDUS|CHAS|NOX|RM|AGE|DIS|RAD|TAX|PTRATIO|B|LSTAT|</span></span><br><span class="line"><span class="comment"># 犯罪率|住宅用地比例|商业用地比例|是否靠河|空气质量|房间数|年限|距中心区距离|路网密度|房产税|师生比|黑人比例|低地位人口比例|</span></span><br><span class="line"><span class="comment"># 打乱原始数据集的输入和输出</span></span><br><span class="line">x, y = su.shuffle(boston.data, boston.target, random_state=<span class="number">7</span>)</span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">train_size = <span class="built_in">int</span>(<span class="built_in">len</span>(x) * <span class="number">0.8</span>)</span><br><span class="line">train_x, test_x, train_y, test_y = \</span><br><span class="line">    x[:train_size], x[train_size:], \</span><br><span class="line">    y[:train_size], y[train_size:]</span><br></pre></td></tr></table></figure>

<h4 id="创建决策树回归器模型"><a href="#创建决策树回归器模型" class="headerlink" title="创建决策树回归器模型"></a>创建决策树回归器模型</h4><p>使用训练集训练模型，使用测试集测试模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.tree <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> sklearn.metrics <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建决策树回归模型</span></span><br><span class="line">model = st.DecisionTreeRegressor(max_depth=<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 测试模型</span></span><br><span class="line">pred_test_y = model.predict(test_x)</span><br><span class="line"><span class="built_in">print</span>(sm.r2_score(test_y, pred_test_y))</span><br></pre></td></tr></table></figure>

<h3 id="集合算法​"><a href="#集合算法​" class="headerlink" title="集合算法​"></a>集合算法​</h3><p>单个模型得到的预测结果总是片面的，根据多个不同模型给出的预测结果，利用平均(回归)或者投票(分类)的方法，得出最终预测结果。</p>
<p>基于决策树的集合算法，就是按照某种规则，构建多棵彼此不同的决策树模型，分别给出针对未知样本的预测结果，最后通过平均或投票得到相对综合的结论。常用的集合模型包括Boosting类模型（AdaBoost、GBDT）与Bagging（自助聚合、随机森林）类模型。</p>
<h4 id="Boosting类模型"><a href="#Boosting类模型" class="headerlink" title="Boosting类模型"></a>Boosting类模型</h4><h5 id="AdaBoost模型（正向激励）"><a href="#AdaBoost模型（正向激励）" class="headerlink" title="AdaBoost模型（正向激励）"></a>AdaBoost模型（正向激励）</h5><p>首先为样本矩阵中的样本随机分配初始权重，由此构建一棵带有权重的决策树，在由该决策树提供预测输出时，通过加权平均或者加权投票的方式产生预测值。</p>
<p>将训练样本代入模型，预测其输出，对那些预测值与实际值不同的样本，提高其权重，由此形成第二棵决策树。重复以上过程，构建出不同权重的若干棵决策树。</p>
<p>正向激励相关API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.tree <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> sklearn.ensemble <span class="keyword">as</span> se</span><br><span class="line"><span class="comment"># model: 决策树模型（一颗）</span></span><br><span class="line">model = st.DecisionTreeRegressor(max_depth=<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 自适应增强决策树回归模型	</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">model = se.AdaBoostRegressor(model, n_estimators=<span class="number">400</span>, random_state=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">正向激励 的基础模型 ： 决策树</span><br><span class="line">n_estimators：构建<span class="number">400</span>棵不同权重的决策树，训练模型</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 测试模型</span></span><br><span class="line">pred_test_y = model.predict(test_x)</span><br></pre></td></tr></table></figure>

<p>案例：基于正向激励训练预测波士顿地区房屋价格的模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建基于决策树的正向激励回归器模型</span></span><br><span class="line">model = se.AdaBoostRegressor(</span><br><span class="line">	st.DecisionTreeRegressor(max_depth=<span class="number">4</span>), n_estimators=<span class="number">400</span>, random_state=<span class="number">7</span>)</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 测试模型</span></span><br><span class="line">pred_test_y = model.predict(test_x)</span><br><span class="line"><span class="built_in">print</span>(sm.r2_score(test_y, pred_test_y))</span><br></pre></td></tr></table></figure>

<p><strong>特征重要性</strong></p>
<p>作为决策树模型训练过程的副产品，根据划分子表时选择特征的顺序标志了该特征的重要程度，此即为该特征重要性指标。训练得到的模型对象提供了属性：feature_importances_来存储每个特征的重要性。</p>
<p>获取样本矩阵特征重要性属性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.fit(train_x, train_y)</span><br><span class="line">fi = model.feature_importances_</span><br></pre></td></tr></table></figure>

<p>案例：获取普通决策树与正向激励决策树训练的两个模型的特征重要性值，按照从大到小顺序输出绘图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> mp</span><br><span class="line"></span><br><span class="line">model = st.DecisionTreeRegressor(max_depth=<span class="number">4</span>)</span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 决策树回归器给出的特征重要性</span></span><br><span class="line">fi_dt = model.feature_importances_</span><br><span class="line">model = se.AdaBoostRegressor(</span><br><span class="line">    st.DecisionTreeRegressor(max_depth=<span class="number">4</span>), n_estimators=<span class="number">400</span>, random_state=<span class="number">7</span>)</span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 基于决策树的正向激励回归器给出的特征重要性</span></span><br><span class="line">fi_ab = model.feature_importances_</span><br><span class="line"></span><br><span class="line">mp.figure(<span class="string">&#x27;Feature Importance&#x27;</span>, facecolor=<span class="string">&#x27;lightgray&#x27;</span>)</span><br><span class="line">mp.subplot(<span class="number">211</span>)</span><br><span class="line">mp.title(<span class="string">&#x27;Decision Tree&#x27;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">mp.ylabel(<span class="string">&#x27;Importance&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.grid(axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">sorted_indices = fi_dt.argsort()[::-<span class="number">1</span>]</span><br><span class="line">pos = np.arange(sorted_indices.size)</span><br><span class="line">mp.bar(pos, fi_dt[sorted_indices], facecolor=<span class="string">&#x27;deepskyblue&#x27;</span>, edgecolor=<span class="string">&#x27;steelblue&#x27;</span>)</span><br><span class="line">mp.xticks(pos, feature_names[sorted_indices], rotation=<span class="number">30</span>)</span><br><span class="line">mp.subplot(<span class="number">212</span>)</span><br><span class="line">mp.title(<span class="string">&#x27;AdaBoost Decision Tree&#x27;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">mp.ylabel(<span class="string">&#x27;Importance&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.grid(axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">sorted_indices = fi_ab.argsort()[::-<span class="number">1</span>]</span><br><span class="line">pos = np.arange(sorted_indices.size)</span><br><span class="line">mp.bar(pos, fi_ab[sorted_indices], facecolor=<span class="string">&#x27;lightcoral&#x27;</span>, edgecolor=<span class="string">&#x27;indianred&#x27;</span>)</span><br><span class="line">mp.xticks(pos, feature_names[sorted_indices], rotation=<span class="number">30</span>)</span><br><span class="line">mp.tight_layout()</span><br><span class="line">mp.show()</span><br></pre></td></tr></table></figure>

<h5 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h5><p>GBDT（Gradient Boosting Decision Tree 梯度提升树）通过多轮迭代，每轮迭代产生一个弱分类器，每个分类器在上一轮分类器的残差<strong>（残差在数理统计中是指实际观察值与估计值（拟合值）之间的差）</strong>基础上进行训练。基于预测结果的残差设计损失函数。GBDT训练的过程即是求该损失函数最小值的过程。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.tree <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> sklearn.ensemble <span class="keyword">as</span> se</span><br><span class="line"><span class="comment"># 自适应增强决策树回归模型	</span></span><br><span class="line"><span class="comment"># n_estimators：构建400棵不同权重的决策树，训练模型</span></span><br><span class="line">model = se.GridientBoostingRegressor(</span><br><span class="line">    	max_depth=<span class="number">10</span>, n_estimators=<span class="number">1000</span>, min_samples_split=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 测试模型</span></span><br><span class="line">pred_test_y = model.predict(test_x)</span><br></pre></td></tr></table></figure>

<figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">boosting : <span class="type">Adaboost</span>  GBDT</span><br></pre></td></tr></table></figure>

<h4 id="Bagging类模型"><a href="#Bagging类模型" class="headerlink" title="Bagging类模型"></a>Bagging类模型</h4><h5 id="自助聚合"><a href="#自助聚合" class="headerlink" title="自助聚合"></a>自助聚合</h5><p>每次从总样本矩阵中以有放回抽样的方式随机抽取部分样本构建决策树，这样形成多棵包含不同训练样本的决策树，以削弱某些强势样本对模型预测结果的影响，提高模型的泛化特性。</p>
<h5 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h5><p>在自助聚合的基础上，每次构建决策树模型时，不仅随机选择部分样本，而且还随机选择部分特征，这样的集合算法，不仅规避了强势样本对预测结果的影响，而且也削弱了强势特征的影响，使模型的预测能力更加泛化。</p>
<p>随机森林相关API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.ensemble <span class="keyword">as</span> se</span><br><span class="line"><span class="comment"># 随机森林回归模型	（属于集合算法的一种）</span></span><br><span class="line"><span class="comment"># max_depth：决策树最大深度10</span></span><br><span class="line"><span class="comment"># n_estimators：构建1000棵决策树，训练模型</span></span><br><span class="line"><span class="comment"># min_samples_split: 子表中最小样本数 若小于这个数字，则不再继续向下拆分</span></span><br><span class="line">model = se.RandomForestRegressor(</span><br><span class="line">    max_depth=<span class="number">10</span>, n_estimators=<span class="number">1000</span>, min_samples_split=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p>案例：分析共享单车的需求，从而判断如何进行共享单车的投放。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1。加载并整理数据集</span><br><span class="line">2.特征分析</span><br><span class="line">3.打乱数据集，划分训练集，测试集</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.utils <span class="keyword">as</span> su</span><br><span class="line"><span class="keyword">import</span> sklearn.ensemble <span class="keyword">as</span> se</span><br><span class="line"><span class="keyword">import</span> sklearn.metrics <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> mp</span><br><span class="line"></span><br><span class="line">data = np.loadtxt(<span class="string">&#x27;../data/bike_day.csv&#x27;</span>, unpack=<span class="literal">False</span>, dtype=<span class="string">&#x27;U20&#x27;</span>, delimiter=<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">day_headers = data[<span class="number">0</span>, <span class="number">2</span>:<span class="number">13</span>]</span><br><span class="line">x = np.array(data[<span class="number">1</span>:, <span class="number">2</span>:<span class="number">13</span>], dtype=<span class="built_in">float</span>)</span><br><span class="line">y = np.array(data[<span class="number">1</span>:, -<span class="number">1</span>], dtype=<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">x, y = su.shuffle(x, y, random_state=<span class="number">7</span>)</span><br><span class="line"><span class="built_in">print</span>(x.shape, y.shape)</span><br><span class="line">train_size = <span class="built_in">int</span>(<span class="built_in">len</span>(x) * <span class="number">0.9</span>)</span><br><span class="line">train_x, test_x, train_y, test_y = \</span><br><span class="line">    x[:train_size], x[train_size:], y[:train_size], y[train_size:]</span><br><span class="line"><span class="comment"># 随机森林回归器</span></span><br><span class="line">model = se.RandomForestRegressor( max_depth=<span class="number">10</span>, n_estimators=<span class="number">1000</span>, min_samples_split=<span class="number">2</span>)</span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 基于“天”数据集的特征重要性</span></span><br><span class="line">fi_dy = model.feature_importances_</span><br><span class="line">pred_test_y = model.predict(test_x)</span><br><span class="line"><span class="built_in">print</span>(sm.r2_score(test_y, pred_test_y))</span><br><span class="line"></span><br><span class="line">data = np.loadtxt(<span class="string">&#x27;../data/bike_hour.csv&#x27;</span>, unpack=<span class="literal">False</span>, dtype=<span class="string">&#x27;U20&#x27;</span>, delimiter=<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">hour_headers = data[<span class="number">0</span>, <span class="number">2</span>:<span class="number">13</span>]</span><br><span class="line">x = np.array(data[<span class="number">1</span>:, <span class="number">2</span>:<span class="number">13</span>], dtype=<span class="built_in">float</span>)</span><br><span class="line">y = np.array(data[<span class="number">1</span>:, -<span class="number">1</span>], dtype=<span class="built_in">float</span>)</span><br><span class="line">x, y = su.shuffle(x, y, random_state=<span class="number">7</span>)</span><br><span class="line">train_size = <span class="built_in">int</span>(<span class="built_in">len</span>(x) * <span class="number">0.9</span>)</span><br><span class="line">train_x, test_x, train_y, test_y = \</span><br><span class="line">    x[:train_size], x[train_size:], \</span><br><span class="line">    y[:train_size], y[train_size:]</span><br><span class="line"><span class="comment"># 随机森林回归器</span></span><br><span class="line">model = se.RandomForestRegressor(</span><br><span class="line">    max_depth=<span class="number">10</span>, n_estimators=<span class="number">1000</span>,</span><br><span class="line">    min_samples_split=<span class="number">2</span>)</span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 基于“小时”数据集的特征重要性</span></span><br><span class="line">fi_hr = model.feature_importances_</span><br><span class="line">pred_test_y = model.predict(test_x)</span><br><span class="line"><span class="built_in">print</span>(sm.r2_score(test_y, pred_test_y))</span><br></pre></td></tr></table></figure>

<p>画图显示两组样本数据的特征重要性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">mp.figure(<span class="string">&#x27;Bike&#x27;</span>, facecolor=<span class="string">&#x27;lightgray&#x27;</span>)</span><br><span class="line">mp.subplot(<span class="number">211</span>)</span><br><span class="line">mp.title(<span class="string">&#x27;Day&#x27;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">mp.ylabel(<span class="string">&#x27;Importance&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.grid(axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">sorted_indices = fi_dy.argsort()[::-<span class="number">1</span>]</span><br><span class="line">pos = np.arange(sorted_indices.size)</span><br><span class="line">mp.bar(pos, fi_dy[sorted_indices], facecolor=<span class="string">&#x27;deepskyblue&#x27;</span>, edgecolor=<span class="string">&#x27;steelblue&#x27;</span>)</span><br><span class="line">mp.xticks(pos, day_headers[sorted_indices], rotation=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">mp.subplot(<span class="number">212</span>)</span><br><span class="line">mp.title(<span class="string">&#x27;Hour&#x27;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">mp.ylabel(<span class="string">&#x27;Importance&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.grid(axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">sorted_indices = fi_hr.argsort()[::-<span class="number">1</span>]</span><br><span class="line">pos = np.arange(sorted_indices.size)</span><br><span class="line">mp.bar(pos, fi_hr[sorted_indices], facecolor=<span class="string">&#x27;lightcoral&#x27;</span>, edgecolor=<span class="string">&#x27;indianred&#x27;</span>)</span><br><span class="line">mp.xticks(pos, hour_headers[sorted_indices], rotation=<span class="number">30</span>)</span><br><span class="line">mp.tight_layout()</span><br><span class="line">mp.show()</span><br></pre></td></tr></table></figure>


</div><script type="text/javascript" src="../../../../js/share.js?v=1.0.0" async></script><a class="article-share-link" data-url="https://deeplearner.top/2022/10/28/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-5-%E5%9B%9E%E5%BD%92-%E5%86%B3%E7%AD%96%E6%A0%91%E5%9B%9E%E5%BD%92/" data-id="clkor69p4004pc6s67u5l6tkv" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAT4AAAE+CAAAAAAxUyPsAAAFSElEQVR42u3awXLiMBAEUP7/p5NrUoDpnhHkkMdpi8WS9Zwqj3p0u8Wfrx+f+2+eff/zm3z8+xHux7keM7/2esZjH3z48OHDhy+49XzKZGHJCNdwyffXv2nHSa7Fhw8fPnz4ZnzJgq8h2qvygqMtffLH1hZb+PDhw4cP3+f58qInuaqNA2aRwezPAh8+fPjw4ftbvvybzS22KEmEkYQF+PDhw4cP3yf5NjcxC/3bxzAbYd/sP9brwIcPHz58+EZFw3/49+EPPnz48OHDF0ftbbCeFwHJCMkvZ5v/mcCv8fHhw4cPH76Jxm1Ptg8g2tb4bEvfzhVF9vjw4cOHD9+ab9aEbpvcSdO9XUx7n20Rhg8fPnz48G349u3w4inFxcdsY58/sH0Ugg8fPnz48G342smS8mIWsudFTPtQ25IIHz58+PDhezff7MBWSzyL+9tiKD9gNwPFhw8fPnz41rn0bVOazFjzWD9ZRlRqjMqdaBX48OHDhw9fwPeZRvU+aGhjhT3uMHHBhw8fPnz44jb59QWbzXbbIM9x81g/X2NeQuHDhw8fPnwtX/Gj0Qa7PTQ2a9jnoUBboEQH6fDhw4cPH76Yb7bVnwFtovZZUTKL7PNYHx8+fPjw4Zvx5UuaLWx/KG11dCy+Ni+k8OHDhw8fvhnfrNRIbqJl3ZdHdZN78WBeJC748OHDhw9fXEXkRcCpZvPs8VzPOIskNo8THz58+PDha/nyl3d7mGy24Bl0EkZsjqPhw4cPHz58Z/nay64b6u0C9nFDfm+zP5SnM+LDhw8fPnwBXz5osuB2o54vL3kAs4A+L3QerAsfPnz48OEr+YoGcDlxsoE/tl0/VGzloUPd38CHDx8+fPguX/Z5HDB78edBQFte5E39lhUfPnz48OE7xZcH7m1AkAf3eTQ/K4BOzfUgrMeHDx8+fPhKvlnhcipk3xQueVhwat5iGnz48OHDh2/U2E4C91kZMYvgN1v9U3Phw4cPHz58e77k04bm7Wibrf7sUeVNhRenDPDhw4cPH76Sr42899v4Nu7ftBaitvcsSsCHDx8+fPhivvxFnoTyecExawnMxmnb4UUsgg8fPnz48JV8beSdb+PbEmHTXG83/Hl4UZ84wIcPHz58+AK+dtnF6zwerS042jAi/6Op14sPHz58+PDF68035Plbe1YWtJFE/oA3B9perBofPnz48OEr+dqtdVt87IOGNjrftxby2fHhw4cPH76Wr31t5030fNO+OSo3Ox63KVaKUwb48OHDhw9fHNNvttab6HwW9J8K4ut4Ah8+fPjw4Zsk28WrPY/p8634/pen7jAp2l4kLvjw4cOHD9+IL48PNsVH3lB/R5N+ttKnv8SHDx8+fPhivvzlvYnLk3Ik3/Bv2u15+yH608GHDx8+fPhivnzBq+305et/Fj0kY+ZH0/LGQNHrwIcPHz58+OI+b1umbIKAHCVvY89mXx2zw4cPHz58+AK+Uxv1s63rzWOI+hLrQgofPnz48OHb8LVb9Nlmfl/i5HFG/khmxc2vsB4fPnz48OFb8OUN4zaTuN78J6ybMmi23x+eL8CHDx8+fPjSTL4oEfKGdHJDLWtRXqyb/bNyBx8+fPjw4Xs2Qs7xjoAgLyBa6Fkpkzce8OHDhw8fvg1f20hObr0NFGa/2Xw/Y31QuODDhw8fPnxv45v979kyJS81Zlj5IQB8+PDhw4fv3Xz5ks5SbjoP+xDkcGSADx8+fPj+PV8e1rdt6VPLmBUrbRlUxxb48OHDhw/fNhVfXZYvb7bh33O3UcKs6Y4PHz58+PDdjfYNKXfTmx1yBIAAAAAASUVORK5CYII=">分享</a><div class="tags"><a href="../../../../tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><i class="fa fa-tag"></i>机器学习笔记</a><a href="../../../../tags/%E5%91%A8%E5%BF%97%E5%8D%8E/"><i class="fa fa-tag"></i>周志华</a><a href="../../../../tags/%E5%90%B4%E6%81%A9%E8%BE%BE/"><i class="fa fa-tag"></i>吴恩达</a><a href="../../../../tags/%E6%9D%8E%E8%88%AA/"><i class="fa fa-tag"></i>李航</a></div><div class="post-nav"><a class="pre" href="../../29/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-6-%E5%88%86%E7%B1%BB-Logistic%E5%9B%9E%E5%BD%92/">MachineLearning-6.（分类）Logistic回归</a><a class="next" href="../../26/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-4-%E5%9B%9E%E5%BD%92-%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92/">MachineLearning-4.（回归）多项式回归</a></div><div class="nofancybox" id="waline"></div><script src="//unpkg.com/@waline/client@v2/dist/waline.js"></script><link rel="stylesheet" type="text/css" href="//unpkg.com/@waline/client@v2/dist/waline.css"><script>let metaInfo = ['nick', 'mail', 'link']
let requiredMeta = 'nick'.split(',').filter(item => {
  return metaInfo.indexOf(item) > -1
})
Waline.init({
  el: '#waline',
  comment: true,
  serverURL: 'https://waline-deeplearner.vercel.app',
  pageSize: '10',
  wordLimit: '500',
  requiredMeta,
})
</script></div></div></div><div class="pure-u-1 pure-u-md-1-4"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/images/blog/avatar_new.png"/></a><p>心外无物，知行合一</p><a class="info-icon" href="/resume/" title="个人简历" target="_blank" style="margin-inline:5px"> <i class="fa fa-share-square" style="margin-inline:5px"></i></a><a class="info-icon" href="mailto:conghaoyuan@gmail.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/conghaoyuan" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a><a class="info-icon" href="/atom.xml" title="RSS" target="_blank" style="margin-inline:5px"> <i class="fa fa-rss-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/AIGC/">AIGC</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Algorithm/">Algorithm</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/CV/">CV</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/GUI/">GUI</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/NLP/">NLP</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Python/">Python</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E5%AD%97%E4%BA%BA/">数字人</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E5%AD%A6/">数学</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/">深度学习框架</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B/">深度学习模型</a><span class="category-list-count">11</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="../../../../2025/03/06/AIGC-LLM-%E8%BE%9F%E9%82%AA%E5%89%91%E8%B0%B1%E4%B9%8BPrompt%20Engineering/">AIGC-LLM-辟邪剑谱之Prompt Engineering</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/11/18/AIGC-Agent-%E4%BD%9C%E6%96%87%E6%89%B9%E6%94%B9%E6%A0%87%E6%B3%A8/">AIGC-Agent-作文批改标注</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/09/27/LLama32%E8%B0%83%E7%A0%94/">LLama3.2调研报告</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/04/09/AIGC-LLM-Prompt%E6%8A%80%E8%83%BD/">AIGC-LLM-Prompt工程技能综述</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/03/05/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-BERT/">Deeeplearning模型-NLP-BERT</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/01/16/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E8%AF%AD%E6%96%99%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7/">Deeeplearning模型-NLP-大语言模型微调语料生成工具</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/12/05/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-Transformer%E6%A8%A1%E5%9E%8B/">Deeeplearning模型-NLP-Transformer模型</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/12/01/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-NLP%E5%9F%BA%E7%A1%80/">Deeeplearning模型-NLP-NLP基础</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/10/26/%E6%95%B0%E5%AD%97%E4%BA%BA-%E6%95%B0%E5%AD%97%E4%BA%BA%E6%8A%80%E6%9C%AF%E6%95%88%E6%9E%9C%E5%AF%B9%E6%AF%94/">数字人-数字人技术效果对比</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/10/13/GUI-%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E6%89%93%E5%8C%85%E4%B8%8E%E5%AE%89%E8%A3%85/">GUI-应用程序打包与安装</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://conghaoyuan.github.io" title="Fern[个人早期博客]" target="_blank">Fern[个人早期博客]</a></div><div class="widget"><div class="widget-title"><i class="fa fa-star"> 天文学</i></div><ul></ul><a href="/tools/tianwenli.html" title="天文历" target="_self">天文历</a></div><div class="widget"><div class="widget-title"><i class="fa fa-plus"> 数学小工具</i></div><ul></ul><a href="/tools/buy_house.html" title="丐版买房计算器" target="_self">丐版买房计算器</a><ul></ul><a href="/tools/equation_12.html" title="一元二次方程" target="_self">一元二次方程</a><ul></ul><a href="/tools/equation_line.html" title="直线方程" target="_self">直线方程</a><ul></ul><a href="/tools/equation_polynomial.html" title="多项式方程" target="_self">多项式方程</a><ul></ul><a href="/tools/regression_ridge.html" title="岭回归" target="_self">岭回归</a><ul></ul><a href="/tools/fourier_transform.html" title="傅里叶变换" target="_self">傅里叶变换</a><ul></ul><a href="/tools/gradient_descent.html" title="梯度下降" target="_self">梯度下降</a><ul></ul><a href="/tools/function_e.html" title="指数函数" target="_self">指数函数</a><ul></ul><a href="/tools/function_inverse_scale.html" title="反比例函数" target="_self">反比例函数</a><ul></ul><a href="/tools/function_log.html" title="对数函数" target="_self">对数函数</a><ul></ul><a href="/tools/function_sin.html" title="正弦函数" target="_self">正弦函数</a><ul></ul><a href="/tools/coord_grid.html" title="网格化坐标" target="_self">网格化坐标</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="../../../../." rel="nofollow">DeepLearner.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="../../../../js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="../../../../js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="../../../../css/search.css?v=1.0.0"><script type="text/javascript" src="../../../../js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="/static/js/MathJax.js?config=TeX-MML-AM_CHTML" async></script><div id="script" type="text/javascript" src="../../../../js/mathjaxs.js" async></div><script type="text/javascript" src="../../../../js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="../../../../js/smartresize.js?v=1.0.0"></script></div><!-- hexo injector body_end start -->
<script src="assets/prism-bundle.js"></script>
<script src="assets/prism-plus.js" data-pjax=""></script>
<!-- hexo injector body_end end --></body></html>