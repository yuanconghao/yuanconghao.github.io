<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Just Do It"><title>MachineLearning-4.（回归）多项式回归 | DeepLearner</title><link rel="stylesheet" type="text/css" href="../../../../css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="/static/css/normalize.css"><link rel="stylesheet" type="text/css" href="/static/css/pure-min.css"><link rel="stylesheet" type="text/css" href="/static/css/grids-responsive-min.css"><link rel="stylesheet" href="/static/css/font-awesome.min.css"><script type="text/javascript" src="/static/js/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="../../../../favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="../../../../favicon.ico"><link rel="apple-touch-icon" href="../../../../apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="../../../../apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="../../../../atom.xml"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-83251621-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + 'b207d9febf3295d375e6e9b42006f9eb';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/static/js/clipboard.min.js"></script><script type="text/javascript" src="/static/js/toastr.min.js"></script><link rel="stylesheet" href="/static/css/toastr.min.css"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">MachineLearning-4.（回归）多项式回归</h1><a id="logo" href="../../../../.">DeepLearner</a><p class="description">Deep Learning Notes</p></div><div id="nav-menu"><a class="current" href="../../../../."><i class="fa fa-home"> 首页</i></a><a href="../../../../archives/"><i class="fa fa-archive"> 归档</i></a><a href="../../../../tagcloud/"><i class="fa fa-tags"> 标签</i></a><a href="../../../../resource/"><i class="fa fa-cloud"> 资源</i></a><a href="../../../../guestbook/"><i class="fa fa-wechat"> 留言</i></a><a href="../../../../codeline/"><i class="fa fa-circle"> 码迹</i></a><a href="../../../../resume/"><i class="fa fa-user"> 个人简历</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">MachineLearning-4.（回归）多项式回归</h1><div class="post-meta">created:2022-10-26</div><div class="post-meta">updated:2023-07-30<span> | </span><span class="category"><a href="../../../../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><a class="disqus-comment-count" href="#waline"><span class="waline-comment-count" id=""></span><span> 条评论</span></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89"><span class="toc-number">1.</span> <span class="toc-text">多项式模型定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">2.</span> <span class="toc-text">与线性回归的关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.</span> <span class="toc-text">多项式回归实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88"><span class="toc-number">4.</span> <span class="toc-text">过拟合与欠拟合</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%AC%A0%E6%8B%9F%E5%90%88%E3%80%81%E8%BF%87%E6%8B%9F%E5%90%88"><span class="toc-number">4.1.</span> <span class="toc-text">什么是欠拟合、过拟合</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E6%AC%A0%E6%8B%9F%E5%90%88%E3%80%81%E8%BF%87%E6%8B%9F%E5%90%88"><span class="toc-number">4.2.</span> <span class="toc-text">如何处理欠拟合、过拟合</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">5.</span> <span class="toc-text">正则化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-number">5.1.</span> <span class="toc-text">正则化的定义</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Lasso%E5%9B%9E%E5%BD%92%E4%B8%8E%E5%B2%AD%E5%9B%9E%E5%BD%92"><span class="toc-number">6.</span> <span class="toc-text">Lasso回归与岭回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD"><span class="toc-number">7.</span> <span class="toc-text">模型保存与加载</span></a></li></ol></div></div><div class="post-content"><p>线性回归适用于数据呈线性分布的回归问题。如果数据样本呈明显非线性分布，线性回归模型就不再适用（下图左），而采用多项式回归可能更好（下图右）。</p>
<img src="/images/ml/regression/poly_1.png" width="400px" style="border:1px solid black;" />

<span id="more"></span>

<h3 id="多项式模型定义"><a href="#多项式模型定义" class="headerlink" title="多项式模型定义"></a>多项式模型定义</h3><p>与线性模型相比，多项式模型引入了高次项，自变量的指数大于1，例如一元二次方程：<br>$$<br>y &#x3D; w_0 + w_1x + w_2x^2<br>$$<br>一元三次方程：<br>$$<br>y &#x3D; w_0 + w_1x + w_2x^2 + w_3x ^ 3<br>$$<br>推广到一元n次方程：<br>$$<br>y &#x3D; w_0 + w_1x + w_2x^2 + w_3x ^ 3 + … + w_nx^n<br>$$<br>上述表达式可以简化为：<br>$$<br>y &#x3D; \sum_{i&#x3D;1}^N w_ix^i<br>$$</p>
<h3 id="与线性回归的关系"><a href="#与线性回归的关系" class="headerlink" title="与线性回归的关系"></a>与线性回归的关系</h3><p>多项式回归可以理解为线性回归的扩展，在线性回归模型中添加了新的特征值.例如，要预测一栋房屋的价格，有$x_1, x_2, x_3$三个特征值，分别表示房子长、宽、高，则房屋价格可表示为以下线性模型：<br>$$<br>y &#x3D; w_1 x_1 + w_2 x_2 + w_3 x_3 + b<br>$$<br>对于房屋价格，也可以用房屋的体积，而不直接使用$x_1, x_2, x_3$三个特征：<br>$$<br>y &#x3D; w_0 + w_1x + w_2x^2 + w_3x ^ 3<br>$$<br>相当于创造了新的特征$x, x$ &#x3D; 长 * 宽 * 高.  以上两个模型可以解释为：</p>
<ul>
<li>房屋价格是关于长、宽、高三个特征的线性模型</li>
<li>房屋价格是关于体积的多项式模型</li>
</ul>
<p>因此，可以将一元n次多项式变换成n元一次线性模型.</p>
<h3 id="多项式回归实现"><a href="#多项式回归实现" class="headerlink" title="多项式回归实现"></a>多项式回归实现</h3><p>对于一元n次多项式，同样可以利用梯度下降对损失值最小化的方法，寻找最优的模型参数$w_0, w_1, w_2, …, w_n$。可以将一元n次多项式，变换成n元一次线性模型，求线性回归。多项式回归的实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多项式回归示例</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 线性模型</span></span><br><span class="line"><span class="keyword">import</span> sklearn.linear_model <span class="keyword">as</span> lm</span><br><span class="line"><span class="comment"># 模型性能评价模块</span></span><br><span class="line"><span class="keyword">import</span> sklearn.metrics <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> mp</span><br><span class="line"><span class="comment"># 管线模块</span></span><br><span class="line"><span class="keyword">import</span> sklearn.pipeline <span class="keyword">as</span> pl</span><br><span class="line"><span class="keyword">import</span> sklearn.preprocessing <span class="keyword">as</span> sp</span><br><span class="line"></span><br><span class="line">train_x, train_y = [], []   <span class="comment"># 输入、输出样本</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;poly_sample.txt&quot;</span>, <span class="string">&quot;rt&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">        data = [<span class="built_in">float</span>(substr) <span class="keyword">for</span> substr <span class="keyword">in</span> line.split(<span class="string">&quot;,&quot;</span>)]</span><br><span class="line">        train_x.append(data[:-<span class="number">1</span>])</span><br><span class="line">        train_y.append(data[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">train_x = np.array(train_x)  <span class="comment"># 二维数据形式的输入矩阵，一行一样本，一列一特征</span></span><br><span class="line">train_y = np.array(train_y)  <span class="comment"># 一维数组形式的输出序列，每个元素对应一个输入样本</span></span><br><span class="line"><span class="comment"># print(train_x)</span></span><br><span class="line"><span class="comment"># print(train_y)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将多项式特征扩展预处理，和一个线性回归器串联为一个管线</span></span><br><span class="line"><span class="comment"># 多项式特征扩展：对现有数据进行的一种转换，通过将数据映射到更高维度的空间中</span></span><br><span class="line"><span class="comment"># 进行多项式扩展后，我们就可以认为，模型由以前的直线变成了曲线</span></span><br><span class="line"><span class="comment"># 从而可以更灵活的去拟合数据</span></span><br><span class="line"><span class="comment"># pipeline连接两个模型</span></span><br><span class="line">model = pl.make_pipeline(sp.PolynomialFeatures(<span class="number">3</span>), <span class="comment"># 多项式特征扩展，扩展最高次项为3</span></span><br><span class="line">                         lm.LinearRegression())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用已知输入、输出数据集训练回归器</span></span><br><span class="line">model.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># print(model[1].coef_)</span></span><br><span class="line"><span class="comment"># print(model[1].intercept_)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据训练模型预测输出</span></span><br><span class="line">pred_train_y = model.predict(train_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估指标</span></span><br><span class="line">err4 = sm.r2_score(train_y, pred_train_y)  <span class="comment"># R2得分, 范围[0, 1], 分值越大越好</span></span><br><span class="line"><span class="built_in">print</span>(err4)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在训练集之外构建测试集</span></span><br><span class="line">test_x = np.linspace(train_x.<span class="built_in">min</span>(), train_x.<span class="built_in">max</span>(), <span class="number">1000</span>)</span><br><span class="line">pre_test_y = model.predict(test_x.reshape(-<span class="number">1</span>, <span class="number">1</span>)) <span class="comment"># 对新样本进行预测</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化回归曲线</span></span><br><span class="line">mp.figure(<span class="string">&#x27;Polynomial Regression&#x27;</span>, facecolor=<span class="string">&#x27;lightgray&#x27;</span>)</span><br><span class="line">mp.title(<span class="string">&#x27;Polynomial Regression&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">mp.xlabel(<span class="string">&#x27;x&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.ylabel(<span class="string">&#x27;y&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.grid(linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">mp.scatter(train_x, train_y, c=<span class="string">&#x27;dodgerblue&#x27;</span>, alpha=<span class="number">0.8</span>, s=<span class="number">60</span>, label=<span class="string">&#x27;Sample&#x27;</span>)</span><br><span class="line"></span><br><span class="line">mp.plot(test_x, pre_test_y, c=<span class="string">&#x27;orangered&#x27;</span>, label=<span class="string">&#x27;Regression&#x27;</span>)</span><br><span class="line"></span><br><span class="line">mp.legend()</span><br><span class="line">mp.show()</span><br></pre></td></tr></table></figure>

<p>打印输出：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">0</span>.<span class="number">9224401504764776</span></span><br></pre></td></tr></table></figure>

<p>执行结果：</p>
<img src="/images/ml/regression/poly_2.png" width="400" alt="多项式回归实现"/>

<h3 id="过拟合与欠拟合"><a href="#过拟合与欠拟合" class="headerlink" title="过拟合与欠拟合"></a>过拟合与欠拟合</h3><h4 id="什么是欠拟合、过拟合"><a href="#什么是欠拟合、过拟合" class="headerlink" title="什么是欠拟合、过拟合"></a>什么是欠拟合、过拟合</h4><p>在上一小节多项式回归示例中，多项特征扩展器PolynomialFeatures()进行多项式扩展时，指定了最高次数为3，该参数为多项式扩展的重要参数，如果选取不当，则可能导致不同的拟合效果。下图显示了该参数分别设为1、20时模型的拟合图像：</p>
<img src="/images/ml/regression/poly_3.png" width="600" alt="线性模型拟合"/>

<p>这两种其实都不是好的模型。前者没有学习到数据分布规律，模型拟合程度不够，预测准确度过低，这种现象称为“欠拟合”；后者过于拟合更多样本，以致模型泛化能力（新样本的适应性）变差，这种现象称为“过拟合”。<strong>欠拟合模型一般表现为训练集、测试集下准确度都比较低；过拟合模型一般表现为训练集下准确度较高、测试集下准确度较低</strong>。一个好的模型，不论是对于训练数据还是测试数据，都有接近的预测精度，而且精度不能太低。</p>
<p><img src="/images/ml/regression/overfit.png" width="600px" alt="过拟合、欠拟合比较" style="border:1px solid black"></img></p>
<p>第一个模型欠拟合；第三个模型过拟合；第二个模型拟合较好.</p>
<h4 id="如何处理欠拟合、过拟合"><a href="#如何处理欠拟合、过拟合" class="headerlink" title="如何处理欠拟合、过拟合"></a>如何处理欠拟合、过拟合</h4><ul>
<li>欠拟合：提高模型复杂度，如增加特征、增加模型最高次幂等等；</li>
<li>过拟合：降低模型复杂度，如减少特征、降低模型最高次幂等等.</li>
</ul>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>过拟合还有一个常见的原因，就是模型参数值太大，所以可以通过抑制参数的方式来解决过拟合问题。如上图所示，右图产生了一定程度过拟合，可以通过弱化高次项的系数（但不删除）来降低过拟合。</p>
<p>例如，可以通过在$\theta_3, \theta_4$的系数上添加一定的系数，来压制这两个高次项的系数，这种方法称为正则化。但在实际问题中，可能有更多的系数，且并不知道应该压制哪些系数，所以，可以通过收缩所有系数来避免过拟合。</p>
<h4 id="正则化的定义"><a href="#正则化的定义" class="headerlink" title="正则化的定义"></a>正则化的定义</h4><p>正则化是指，在目标函数后面添加一个范数，来防止过拟合的手段，这个范数定义为：</p>
<p>$$<br>||x||_{p}&#x3D;(\sum _{i&#x3D;1}^{N}|x|^{p})^{\frac{1}{p}}<br>$$</p>
<p>当p&#x3D;1时，称为L1范数（即所有系数绝对值之和）：</p>
<p>$$<br>||x||_{1}&#x3D;(\sum _{i&#x3D;1}^N |x|)<br>$$</p>
<p>当p&#x3D;2是，称为L2范数（即所有系数平方之和再开方）：</p>
<p>$$<br>||x||_{2}&#x3D;(\sum _{i&#x3D;1}^N |x|^2)^{\frac{1}{2}}<br>$$</p>
<p>通过对目标函数添加正则项，整体上压缩了参数的大小，从而防止过拟合。</p>
<h3 id="Lasso回归与岭回归"><a href="#Lasso回归与岭回归" class="headerlink" title="Lasso回归与岭回归"></a>Lasso回归与岭回归</h3><p>Lasso回归和岭回归（Ridge Regression）都是在标准线性回归的基础上修改了损失函数的回归算法。Lasso回归全称为 Least absolute shrinkage and selection operator，又译“最小绝对值收敛和选择算子”、“套索算法”，其损失函数如下所示：</p>
<p>$$<br>E &#x3D; \frac{1}{n}(\sum _{i&#x3D;1}^N y_i - y_i’)^2 + \lambda ||w||_1<br>$$</p>
<p>岭回归损失函数为：<br>$$<br>E &#x3D; \frac{1}{n}(\sum _{i&#x3D;1}^N y_i - y_i’)^2 + \lambda ||w||_2<br>$$</p>
<p>从逻辑上说，Lasso回归和岭回归都可以理解为通过调整损失函数，减小函数的系数，从而避免过于拟合于样本，降低偏差较大的样本的权重和对模型的影响程度。</p>
<p><strong>线性模型变种模型：</strong></p>
<ul>
<li><p>损失函数后面 + 正则项	</p>
</li>
<li><p>Lasso回归：损失函数  + L1范数</p>
</li>
<li><p>岭回归：损失函数  + L2范数</p>
</li>
</ul>
<p>以下关于Lasso回归于岭回归的sklearn实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Lasso回归和岭回归示例</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 线性模型</span></span><br><span class="line"><span class="keyword">import</span> sklearn.linear_model <span class="keyword">as</span> lm</span><br><span class="line"><span class="comment"># 模型性能评价模块</span></span><br><span class="line"><span class="keyword">import</span> sklearn.metrics <span class="keyword">as</span> sm</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> mp</span><br><span class="line"></span><br><span class="line">x, y = [], []  <span class="comment"># 输入、输出样本</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;abnormal.txt&quot;</span>, <span class="string">&quot;rt&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">        data = [<span class="built_in">float</span>(substr) <span class="keyword">for</span> substr <span class="keyword">in</span> line.split(<span class="string">&quot;,&quot;</span>)]</span><br><span class="line">        x.append(data[:-<span class="number">1</span>])</span><br><span class="line">        y.append(data[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">x = np.array(x)  <span class="comment"># 二维数据形式的输入矩阵，一行一样本，一列一特征</span></span><br><span class="line">y = np.array(y)  <span class="comment"># 一维数组形式的输出序列，每个元素对应一个输入样本</span></span><br><span class="line"><span class="comment"># print(x)</span></span><br><span class="line"><span class="comment"># print(y)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建线性回归器</span></span><br><span class="line">model = lm.LinearRegression()</span><br><span class="line"><span class="comment"># 用已知输入、输出数据集训练回归器</span></span><br><span class="line">model.fit(x, y)</span><br><span class="line"><span class="comment"># 根据训练模型预测输出</span></span><br><span class="line">pred_y = model.predict(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建岭回归器并进行训练</span></span><br><span class="line"><span class="comment"># Ridge: 第一个参数为正则强度，该值越大，异常样本权重就越小</span></span><br><span class="line">model_2 = lm.Ridge(alpha=<span class="number">200</span>, max_iter=<span class="number">1000</span>)  <span class="comment"># 创建对象, max_iter为最大迭代次数</span></span><br><span class="line">model_2.fit(x, y)  <span class="comment"># 训练</span></span><br><span class="line">pred_y2 = model_2.predict(x)  <span class="comment"># 预测</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># lasso回归</span></span><br><span class="line">model_3 = lm.Lasso(alpha=<span class="number">0.5</span>,  <span class="comment"># L1范数相乘的系数</span></span><br><span class="line">                   max_iter=<span class="number">1000</span>)  <span class="comment"># 最大迭代次数</span></span><br><span class="line">model_3.fit(x, y)  <span class="comment"># 训练</span></span><br><span class="line">pred_y3 = model_3.predict(x)  <span class="comment"># 预测</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化回归曲线</span></span><br><span class="line">mp.figure(<span class="string">&#x27;Linear &amp; Ridge &amp; Lasso&#x27;</span>, facecolor=<span class="string">&#x27;lightgray&#x27;</span>)</span><br><span class="line">mp.title(<span class="string">&#x27;Linear &amp; Ridge &amp; Lasso&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">mp.xlabel(<span class="string">&#x27;x&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.ylabel(<span class="string">&#x27;y&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.grid(linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">mp.scatter(x, y, c=<span class="string">&#x27;dodgerblue&#x27;</span>, alpha=<span class="number">0.8</span>, s=<span class="number">60</span>, label=<span class="string">&#x27;Sample&#x27;</span>)</span><br><span class="line">sorted_idx = x.T[<span class="number">0</span>].argsort()</span><br><span class="line"></span><br><span class="line">mp.plot(x[sorted_idx], pred_y[sorted_idx], c=<span class="string">&#x27;orangered&#x27;</span>, label=<span class="string">&#x27;Linear&#x27;</span>)  <span class="comment"># 线性回归</span></span><br><span class="line">mp.plot(x[sorted_idx], pred_y2[sorted_idx], c=<span class="string">&#x27;limegreen&#x27;</span>, label=<span class="string">&#x27;Ridge&#x27;</span>)  <span class="comment"># 岭回归</span></span><br><span class="line">mp.plot(x[sorted_idx], pred_y3[sorted_idx], c=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;Lasso&#x27;</span>)  <span class="comment"># Lasso回归</span></span><br><span class="line"></span><br><span class="line">mp.legend()</span><br><span class="line">mp.show()</span><br></pre></td></tr></table></figure>

<p>执行结果：<br><img src="/images/ml/regression/linear_9.png" width="500px" alt="线性回归、Lasso回归、岭回归" /></p>
<h3 id="模型保存与加载"><a href="#模型保存与加载" class="headerlink" title="模型保存与加载"></a>模型保存与加载</h3><p>可使用Python提供的功能对模型对象进行保存。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">pickle.dump(模型对象, 文件对象)   </span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">model_obj = pickle.load(文件对象)</span><br></pre></td></tr></table></figure>

<p>保存训练模型应该在训练完成或评估完成之后，完整代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型保存示例</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.linear_model <span class="keyword">as</span> lm <span class="comment"># 线性模型</span></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">0.5</span>], [<span class="number">0.6</span>], [<span class="number">0.8</span>], [<span class="number">1.1</span>], [<span class="number">1.4</span>]])  <span class="comment"># 输入集</span></span><br><span class="line">y = np.array([<span class="number">5.0</span>, <span class="number">5.5</span>, <span class="number">6.0</span>, <span class="number">6.8</span>, <span class="number">7.0</span>])  <span class="comment"># 输出集</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建线性回归器</span></span><br><span class="line">model = lm.LinearRegression()</span><br><span class="line"><span class="comment"># 用已知输入、输出数据集训练回归器</span></span><br><span class="line">model.fit(x, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练完成.&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存训练后的模型</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;linear_model.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(model, f)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;保存模型完成.&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>执行完成后，可以看到与源码相同目录下多了一个名称为linear_model.pkl的文件，这就是保存的训练模型。使用该模型代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型加载示例</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.linear_model <span class="keyword">as</span> lm  <span class="comment"># 线性模型</span></span><br><span class="line"><span class="keyword">import</span> sklearn.metrics <span class="keyword">as</span> sm  <span class="comment"># 模型性能评价模块</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">0.5</span>], [<span class="number">0.6</span>], [<span class="number">0.8</span>], [<span class="number">1.1</span>], [<span class="number">1.4</span>]])  <span class="comment"># 输入集</span></span><br><span class="line">y = np.array([<span class="number">5.0</span>, <span class="number">5.5</span>, <span class="number">6.0</span>, <span class="number">6.8</span>, <span class="number">7.0</span>])  <span class="comment"># 输出集</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;linear_model.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    model = pickle.load(f)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;加载模型完成.&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据加载的模型预测输出</span></span><br><span class="line">pred_y = model.predict(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化回归曲线</span></span><br><span class="line">mp.figure(<span class="string">&#x27;Linear Regression&#x27;</span>, facecolor=<span class="string">&#x27;lightgray&#x27;</span>)</span><br><span class="line">mp.title(<span class="string">&#x27;Linear Regression&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">mp.xlabel(<span class="string">&#x27;x&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.ylabel(<span class="string">&#x27;y&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">mp.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line">mp.grid(linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">mp.scatter(x, y, c=<span class="string">&#x27;blue&#x27;</span>, alpha=<span class="number">0.8</span>, s=<span class="number">60</span>, label=<span class="string">&#x27;Sample&#x27;</span>)</span><br><span class="line"></span><br><span class="line">mp.plot(x, pred_y, c=<span class="string">&#x27;orangered&#x27;</span>, label=<span class="string">&#x27;Regression&#x27;</span>)</span><br><span class="line"></span><br><span class="line">mp.legend()</span><br><span class="line">mp.show()</span><br></pre></td></tr></table></figure>

<p>执行结果和训练模型预测结果一样.</p>
</div><script type="text/javascript" src="../../../../js/share.js?v=1.0.0" async></script><a class="article-share-link" data-url="https://deeplearner.top/2022/10/26/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-4-%E5%9B%9E%E5%BD%92-%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92/" data-id="clkor69p4004rc6s67ygr14xs" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAT4AAAE+CAAAAAAxUyPsAAAFRUlEQVR42u3aQW4bSxQDQN//0vnbAIYlkm/0s3B5ZSSyZrpagDh8/fUV//z566d9zZ9vP3//+/dX5ld8/Vf53+avH3/w4cOHDx++l2+RL/U1Wc6Ub0my4HwV+VV+vCI+fPjw4cM38eWBILnFhPv18trY8dRa8vfBhw8fPnz4/h++NqzkTG10uPxvfif48OHDhw/fv+J79oE/DyhJ9dBW/JdyAR8+fPjw4bvz5SHgUqZv5UI+AMjr+Lz4eGzWgQ8fPnz48JWnsH7P7w//4MOHDx8+fMHXc/613b6mDQ1tzGoH+aMDPnz48OHDNzm0Q+u26N+K+HwA0Nb3+WA+GjDgw4cPHz58Md8WRPKIkBwUyw+NbXFnu59oGIAPHz58+PBNfC1TPvbOh9nbg33bnF8G6l9Pfcrw4cOHD9+v56u/sMtH8fYYXBIvLkfZ2g9HVBngw4cPHz58D/Hdi/t2wW3ouQwAtk3Chw8fPnz4Lnz5aDw/2tUW8cmW5KOFtrZ4zffjneDDhw8fPnwlX16ybze6bUPOvV33gvjVXgYfPnz48OErv8Iv8aXYw0PJ3uJuo/qiMsCHDx8+fPjKsv6pmjsZfrev2TZmO6L3pvTHhw8fPnz4Sr78izxfzD24bIu5HHo7hTB8+PDhw4cv5ttq7kt8yYfonzim1t7hm83Dhw8fPnz4znxbTd/+noeMPGDl75AHrzf3jA8fPnz48JV8l/65DTF5cLkMALaolG/JY/U9Pnz48OH7lXxtVZ1cLF9kW5e36MnD/1bW48OHDx8+fBe+y8N2EhS2kXmbudqiPy81ijkAPnz48OHDF9zzpW9oQ8820m4jyP3+i8Nz+PDhw4cP34GvjRdtRX6PMm3kGucVwTvgw4cPHz58Ld9WZ7evKXYyrtG32HQfHuDDhw8fPnx3viQEnC4Tk11+T0YIl/W+2Wd8+PDhw4cv7gE2pm1SnB9326LGFk3y6xZlPT58+PDhw/eSbyuvN+6tLv9EBX8fD+DDhw8fPnw5X7vIpCDI37ONFNsgPC/u6w8BPnz48OHDt+SHh0fj2/j52dH4ZfO20T4+fPjw4cOX8LVBIV/YU4Pt+/tcPihvcPHhw4cPH76S71LN57d1PxyW3/on7jAZ7ePDhw8fPnwJ3xYO8so+jybJ8toC4vIJOs068OHDhw8fvunsVj54bgftW0lRHyCLY0pefxSI+PDhw4cP37c73x7gW+jLAbJ8TN6WCPmBgB9fjw8fPnz48E18yYD5HjVyiHyT2oF3PoSINgkfPnz48OGb+PKv6q0QbyPI61tvhwf5JuV3jg8fPnz48G1820G0e7Bol5S/WxJoLsPvN6/Hhw8fPnz4Xq6xrcLbL/u8gLgHoMt7tuj48OHDhw/fxncZfueVQVKLJwHiEj4uYauu7PHhw4cPH76Yb4sybXDZtiS/Yhut8tVFu4oPHz58+PAF2SCvrfN6vR1I51fcqo2toI+U8OHDhw8fvnjO+7lq+x5K7nz3KPbjRwEfPnz48OGb+C5RYAsN+eD8Ei/aTaoP7eHDhw8fPnxnvrZ8Tx7Fn9qYdoC9raX4MOHDhw8fPnx7DhkL+qe48983uPaw2lPlPj58+PDhw7cd4XpqKH45mvZUKfDUCAEfPnz48OG78LVf5Pkj+lMP3k/97f1o2puzBvjw4cOHD99DfAniFj62oLPFjqcCEz58+PDhw/dpvhYoDz1JuEnuJ48sl6ECPnz48OHDd+fbHvi3I26vl3cJSfm/b+v6sTLAhw8fPnz4Yr5L2b29aXtD22Z8oqp4oOnHhw8fPny/l+8/XJxfjqw5/6QAAAAASUVORK5CYII=">分享</a><div class="tags"><a href="../../../../tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><i class="fa fa-tag"></i>机器学习笔记</a><a href="../../../../tags/%E5%91%A8%E5%BF%97%E5%8D%8E/"><i class="fa fa-tag"></i>周志华</a><a href="../../../../tags/%E5%90%B4%E6%81%A9%E8%BE%BE/"><i class="fa fa-tag"></i>吴恩达</a><a href="../../../../tags/%E6%9D%8E%E8%88%AA/"><i class="fa fa-tag"></i>李航</a></div><div class="post-nav"><a class="pre" href="../../28/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-5-%E5%9B%9E%E5%BD%92-%E5%86%B3%E7%AD%96%E6%A0%91%E5%9B%9E%E5%BD%92/">MachineLearning-5.（回归）决策树回归</a><a class="next" href="../../25/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-3-%E5%9B%9E%E5%BD%92-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">MachineLearning-3.（回归）线性回归</a></div><div class="nofancybox" id="waline"></div><script src="//unpkg.com/@waline/client@v2/dist/waline.js"></script><link rel="stylesheet" type="text/css" href="//unpkg.com/@waline/client@v2/dist/waline.css"><script>let metaInfo = ['nick', 'mail', 'link']
let requiredMeta = 'nick'.split(',').filter(item => {
  return metaInfo.indexOf(item) > -1
})
Waline.init({
  el: '#waline',
  comment: true,
  serverURL: 'https://waline-deeplearner.vercel.app',
  pageSize: '10',
  wordLimit: '500',
  requiredMeta,
})
</script></div></div></div><div class="pure-u-1 pure-u-md-1-4"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/images/blog/avatar_new.png"/></a><p>心外无物，知行合一</p><a class="info-icon" href="/resume/" title="个人简历" target="_blank" style="margin-inline:5px"> <i class="fa fa-share-square" style="margin-inline:5px"></i></a><a class="info-icon" href="mailto:conghaoyuan@gmail.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/conghaoyuan" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a><a class="info-icon" href="/atom.xml" title="RSS" target="_blank" style="margin-inline:5px"> <i class="fa fa-rss-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/AIGC/">AIGC</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Algorithm/">Algorithm</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/CV/">CV</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/GUI/">GUI</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/NLP/">NLP</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Python/">Python</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E5%AD%97%E4%BA%BA/">数字人</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E5%AD%A6/">数学</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/">深度学习框架</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B/">深度学习模型</a><span class="category-list-count">11</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="../../../../2025/03/06/AIGC-LLM-%E8%BE%9F%E9%82%AA%E5%89%91%E8%B0%B1%E4%B9%8BPrompt%20Engineering/">AIGC-LLM-辟邪剑谱之Prompt Engineering</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/11/18/AIGC-Agent-%E4%BD%9C%E6%96%87%E6%89%B9%E6%94%B9%E6%A0%87%E6%B3%A8/">AIGC-Agent-作文批改标注</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/09/27/LLama32%E8%B0%83%E7%A0%94/">LLama3.2调研报告</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/04/09/AIGC-LLM-Prompt%E6%8A%80%E8%83%BD/">AIGC-LLM-Prompt工程技能综述</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/03/05/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-BERT/">Deeeplearning模型-NLP-BERT</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/01/16/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E8%AF%AD%E6%96%99%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7/">Deeeplearning模型-NLP-大语言模型微调语料生成工具</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/12/05/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-Transformer%E6%A8%A1%E5%9E%8B/">Deeeplearning模型-NLP-Transformer模型</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/12/01/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-NLP%E5%9F%BA%E7%A1%80/">Deeeplearning模型-NLP-NLP基础</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/10/26/%E6%95%B0%E5%AD%97%E4%BA%BA-%E6%95%B0%E5%AD%97%E4%BA%BA%E6%8A%80%E6%9C%AF%E6%95%88%E6%9E%9C%E5%AF%B9%E6%AF%94/">数字人-数字人技术效果对比</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/09/15/AIGC-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83-LLama2-Lora%E5%8C%BB%E5%AD%A6%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%832/">AIGC-大模型微调-LLama2-Lora医学大模型微调【风格学习】</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://conghaoyuan.github.io" title="Fern[个人早期博客]" target="_blank">Fern[个人早期博客]</a></div><div class="widget"><div class="widget-title"><i class="fa fa-star"> 天文学</i></div><ul></ul><a href="/tools/tianwenli.html" title="天文历" target="_self">天文历</a></div><div class="widget"><div class="widget-title"><i class="fa fa-plus"> 数学小工具</i></div><ul></ul><a href="/tools/buy_house.html" title="丐版买房计算器" target="_self">丐版买房计算器</a><ul></ul><a href="/tools/equation_12.html" title="一元二次方程" target="_self">一元二次方程</a><ul></ul><a href="/tools/equation_line.html" title="直线方程" target="_self">直线方程</a><ul></ul><a href="/tools/equation_polynomial.html" title="多项式方程" target="_self">多项式方程</a><ul></ul><a href="/tools/regression_ridge.html" title="岭回归" target="_self">岭回归</a><ul></ul><a href="/tools/fourier_transform.html" title="傅里叶变换" target="_self">傅里叶变换</a><ul></ul><a href="/tools/gradient_descent.html" title="梯度下降" target="_self">梯度下降</a><ul></ul><a href="/tools/function_e.html" title="指数函数" target="_self">指数函数</a><ul></ul><a href="/tools/function_inverse_scale.html" title="反比例函数" target="_self">反比例函数</a><ul></ul><a href="/tools/function_log.html" title="对数函数" target="_self">对数函数</a><ul></ul><a href="/tools/function_sin.html" title="正弦函数" target="_self">正弦函数</a><ul></ul><a href="/tools/coord_grid.html" title="网格化坐标" target="_self">网格化坐标</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="../../../../." rel="nofollow">DeepLearner.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="../../../../js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="../../../../js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="../../../../css/search.css?v=1.0.0"><script type="text/javascript" src="../../../../js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="/static/js/MathJax.js?config=TeX-MML-AM_CHTML" async></script><div id="script" type="text/javascript" src="../../../../js/mathjaxs.js" async></div><script type="text/javascript" src="../../../../js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="../../../../js/smartresize.js?v=1.0.0"></script></div><!-- hexo injector body_end start -->
<script src="assets/prism-bundle.js"></script>
<script src="assets/prism-plus.js" data-pjax=""></script>
<!-- hexo injector body_end end --></body></html>