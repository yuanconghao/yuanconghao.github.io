<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Just Do It"><title>MachineLearning-2.数据预处理 | DeepLearner</title><link rel="stylesheet" type="text/css" href="../../../../css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="/static/css/normalize.css"><link rel="stylesheet" type="text/css" href="/static/css/pure-min.css"><link rel="stylesheet" type="text/css" href="/static/css/grids-responsive-min.css"><link rel="stylesheet" href="/static/css/font-awesome.min.css"><script type="text/javascript" src="/static/js/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="../../../../favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="../../../../favicon.ico"><link rel="apple-touch-icon" href="../../../../apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="../../../../apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="../../../../atom.xml"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-83251621-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + 'b207d9febf3295d375e6e9b42006f9eb';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/static/js/clipboard.min.js"></script><script type="text/javascript" src="/static/js/toastr.min.js"></script><link rel="stylesheet" href="/static/css/toastr.min.css"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">MachineLearning-2.数据预处理</h1><a id="logo" href="../../../../.">DeepLearner</a><p class="description">Deep Learning Notes</p></div><div id="nav-menu"><a class="current" href="../../../../."><i class="fa fa-home"> 首页</i></a><a href="../../../../archives/"><i class="fa fa-archive"> 归档</i></a><a href="../../../../tagcloud/"><i class="fa fa-tags"> 标签</i></a><a href="../../../../resource/"><i class="fa fa-cloud"> 资源</i></a><a href="../../../../guestbook/"><i class="fa fa-wechat"> 留言</i></a><a href="../../../../codeline/"><i class="fa fa-circle"> 码迹</i></a><a href="../../../../resume/"><i class="fa fa-user"> 个人简历</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">MachineLearning-2.数据预处理</h1><div class="post-meta">created:2022-10-23</div><div class="post-meta">updated:2023-07-30<span> | </span><span class="category"><a href="../../../../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><a class="disqus-comment-count" href="#waline"><span class="waline-comment-count" id=""></span><span> 条评论</span></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%9A%84%E7%9B%AE%E7%9A%84"><span class="toc-number">1.</span> <span class="toc-text">数据预处理的目的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E6%9E%90"><span class="toc-number">2.</span> <span class="toc-text">数据集分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E5%9F%BA%E6%9C%AC%E4%BF%A1%E6%81%AF"><span class="toc-number">2.1.</span> <span class="toc-text">查看数据集基本信息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BC%BA%E5%A4%B1%E6%95%B0%E6%8D%AE"><span class="toc-number">2.2.</span> <span class="toc-text">分析数据集缺失数据</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%83%AD%E5%9B%BE%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%88%86%E6%9E%90"><span class="toc-number">2.2.1.</span> <span class="toc-text">热图缺失值分析</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%99%BE%E5%88%86%E6%AF%94%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%88%86%E6%9E%90"><span class="toc-number">2.2.2.</span> <span class="toc-text">百分比缺失值分析</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8D%E8%A7%84%E5%88%99%E6%95%B0%E6%8D%AE"><span class="toc-number">2.3.</span> <span class="toc-text">分析数据集不规则数据</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%99%BE%E5%88%86%E6%AF%94%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%88%86%E6%9E%90-1"><span class="toc-number">2.3.1.</span> <span class="toc-text">百分比缺失值分析</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%AE%B1%E5%9E%8B%E5%9B%BE%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%88%86%E6%9E%90"><span class="toc-number">2.3.2.</span> <span class="toc-text">箱型图缺失值分析</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8D%E5%BF%85%E8%A6%81%E6%95%B0%E6%8D%AE"><span class="toc-number">2.4.</span> <span class="toc-text">分析数据集不必要数据</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%99%BE%E5%88%86%E6%AF%94%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%88%86%E6%9E%90-2"><span class="toc-number">2.4.1.</span> <span class="toc-text">百分比缺失值分析</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8D%E5%A4%8D%E8%A1%8C%E6%95%B0%E6%8D%AE%E3%80%81%E5%85%B3%E9%94%AE%E7%89%B9%E5%BE%81%E9%87%8D%E5%A4%8D%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"><span class="toc-number">2.5.</span> <span class="toc-text">重复行数据、关键特征重复行数据分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8D%E4%B8%80%E8%87%B4%E6%95%B0%E6%8D%AE"><span class="toc-number">2.6.</span> <span class="toc-text">分析数据集不一致数据</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95"><span class="toc-number">3.</span> <span class="toc-text">数据预处理方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%B8%85%E7%90%86"><span class="toc-number">3.1.</span> <span class="toc-text">数据清理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%A4%84%E7%90%86"><span class="toc-number">3.1.1.</span> <span class="toc-text">缺失值处理</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%A6%BB%E6%95%A3%E7%82%B9%E5%A4%84%E7%90%86"><span class="toc-number">3.1.2.</span> <span class="toc-text">离散点处理</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90"><span class="toc-number">3.2.</span> <span class="toc-text">数据集成</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%8F%98%E6%8D%A2%EF%BC%88%E8%A7%84%E8%8C%83%E5%8C%96%E5%A4%84%E7%90%86%EF%BC%89"><span class="toc-number">3.3.</span> <span class="toc-text">数据变换（规范化处理）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1%EF%BC%89%E6%A0%87%E5%87%86%E5%8C%96%EF%BC%88%E5%9D%87%E5%80%BC%E7%A7%BB%E9%99%A4%EF%BC%89"><span class="toc-number">3.3.1.</span> <span class="toc-text">1）标准化（均值移除）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2%EF%BC%89%E8%8C%83%E5%9B%B4%E7%BC%A9%E6%94%BE"><span class="toc-number">3.3.2.</span> <span class="toc-text">2）范围缩放</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3%EF%BC%89%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-number">3.3.3.</span> <span class="toc-text">3）归一化</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4%EF%BC%89%E4%BA%8C%E5%80%BC%E5%8C%96"><span class="toc-number">3.3.4.</span> <span class="toc-text">4）二值化</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5%EF%BC%89%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81"><span class="toc-number">3.3.5.</span> <span class="toc-text">5）独热编码</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6%EF%BC%89%E6%A0%87%E7%AD%BE%E7%BC%96%E7%A0%81"><span class="toc-number">3.3.6.</span> <span class="toc-text">6）标签编码</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%A7%84%E7%BA%A6"><span class="toc-number">3.4.</span> <span class="toc-text">数据规约</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BB%B4%E5%BA%A6%E8%A7%84%E7%BA%A6"><span class="toc-number">3.4.1.</span> <span class="toc-text">维度规约</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2"><span class="toc-number">3.4.2.</span> <span class="toc-text">维度变换</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F"><span class="toc-number">4.</span> <span class="toc-text">注意</span></a></li></ol></div></div><div class="post-content"><p>笔记数据集采用Kaggle竞赛<a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/sberbank-russian-housing-market/data">Sberbank俄罗斯房地产价值预测竞赛数据</a>，预测Russian房价波动。选取部分样本使用。数据集已统一放入Github中方便下载使用。<a target="_blank" rel="noopener" href="https://github.com/yuanconghao/deeplearning-datasets/tree/main/kaggle/sberbank-russian-housing-market">train.csv</a>，数据集共有30471行、292列。</p>
<h3 id="数据预处理的目的"><a href="#数据预处理的目的" class="headerlink" title="数据预处理的目的"></a>数据预处理的目的</h3><ul>
<li>去除不必要数据（重复、错误数据）；不一致数据（大写、地址）；不规则数据（异常值、脏数据）</li>
<li>补齐缺失值</li>
<li>对数据范围、量纲、格式、类型进行统一化处理，方便进行后续计算</li>
</ul>
<span id="more"></span>

<h3 id="数据集分析"><a href="#数据集分析" class="headerlink" title="数据集分析"></a>数据集分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.mlab <span class="keyword">as</span> mlab</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> figure</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br></pre></td></tr></table></figure>

<h4 id="查看数据集基本信息"><a href="#查看数据集基本信息" class="headerlink" title="查看数据集基本信息"></a>查看数据集基本信息</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(df.shape)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<p><img src="/images/ml/ml_data_preprocess_basic.png" width="800px" alt="" style="border:1px solid black"></img></p>
<h4 id="分析数据集缺失数据"><a href="#分析数据集缺失数据" class="headerlink" title="分析数据集缺失数据"></a>分析数据集缺失数据</h4><h5 id="热图缺失值分析"><a href="#热图缺失值分析" class="headerlink" title="热图缺失值分析"></a>热图缺失值分析</h5><p>展示所有特征（所有列）的缺失数据，横轴代表特征名称，纵轴代表观察值，<font color="#CC3636">红色代表缺失数据</font>，<font color="#367E18">绿色代表非缺失数据</font>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cols = df.columns[:df.shape[<span class="number">1</span>]]  <span class="comment"># all columns</span></span><br><span class="line">colours = [<span class="string">&#x27;#367E18&#x27;</span>, <span class="string">&#x27;#CC3636&#x27;</span>] <span class="comment"># red is missing. green is not missing.</span></span><br><span class="line">sns.heatmap(df[cols].isnull(), cmap=sns.color_palette(colours))</span><br></pre></td></tr></table></figure>
<p><img src="/images/ml/ml_data_preprocess_hot.png" width="800px" alt="" style="border:1px solid black"></img></p>
<p><font color="ff0000">注：图片颜色搭配使用<a target="_blank" rel="noopener" href="https://colorhunt.co/palette/ffe9a0367e18f57328cc3636">Color Hunt</a></font></p>
<p>通过该缺失值热图，可以观察到在<strong>第0行至第7623行</strong>的<strong>material</strong>特征上全部缺失。第30000行后不缺失，可验证结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(df.iloc[<span class="number">693</span>][<span class="string">&#x27;material&#x27;</span>])     <span class="comment"># nan</span></span><br><span class="line"><span class="built_in">print</span>(df.iloc[<span class="number">30000</span>][<span class="string">&#x27;material&#x27;</span>])   <span class="comment"># 1.0</span></span><br></pre></td></tr></table></figure>
<h5 id="百分比缺失值分析"><a href="#百分比缺失值分析" class="headerlink" title="百分比缺失值分析"></a>百分比缺失值分析</h5><p>在热图的基础上，可通过对缺失值百分比列表来总结每个特征的的缺失百分比情况。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create Series datastruct</span></span><br><span class="line">s = pd.Series(dtype=<span class="built_in">float</span>)</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    pct_missing = np.mean(df[col].isnull())</span><br><span class="line">    <span class="keyword">if</span> pct_missing &gt; <span class="number">0</span>:</span><br><span class="line">        s[col] = <span class="built_in">round</span>(pct_missing*<span class="number">100</span>, <span class="number">2</span>)</span><br><span class="line"><span class="comment"># values sorted by desc </span></span><br><span class="line"><span class="built_in">print</span>(s.sort_values(ascending=<span class="literal">False</span>).to_string(float_format=<span class="keyword">lambda</span> e:<span class="built_in">str</span>(e)+<span class="string">&#x27;%&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/images/ml/ml_data_preprocess_pec.png" width="300px" alt="" style="border:1px solid black"></img></p>
<p>可根据特征缺失百分比，选择要数据清理的特征。</p>
<h4 id="分析数据集不规则数据"><a href="#分析数据集不规则数据" class="headerlink" title="分析数据集不规则数据"></a>分析数据集不规则数据</h4><h5 id="百分比缺失值分析-1"><a href="#百分比缺失值分析-1" class="headerlink" title="百分比缺失值分析"></a>百分比缺失值分析</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">index = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    <span class="keyword">if</span> index &gt; <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">if</span> col == <span class="string">&#x27;id&#x27;</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">        </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;col=%s:&quot;</span> %col)</span><br><span class="line">    <span class="built_in">print</span>(df[col].describe(), <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    index+=<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/ml/ml_data_preprocess_pec1.png" width="300px" alt="" style="border:1px solid black"></img></p>
<p>取了两列（timestamp和full_sq特征）的描述统计数据，可以看到full_sq在各分位数据的占比，以及最大、最小值。通过观察，最大值为5326，而在四分位（75个百分位）数据为63，因此最大值5326为异常值。</p>
<h5 id="箱型图缺失值分析"><a href="#箱型图缺失值分析" class="headerlink" title="箱型图缺失值分析"></a>箱型图缺失值分析</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># box plot.</span></span><br><span class="line">df.boxplot(column=[<span class="string">&#x27;full_sq&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p><img src="/images/ml/ml_data_preprocess_box.png" width="300px" alt="" style="border:1px solid black"></img></p>
<p>通过箱型图可以观察到最高位置点5326为异常值，其他均小于1000。</p>
<p>其他查找异常值的方法还有散点图、z-score和聚类等，视情况选择。</p>
<h4 id="分析数据集不必要数据"><a href="#分析数据集不必要数据" class="headerlink" title="分析数据集不必要数据"></a>分析数据集不必要数据</h4><h5 id="百分比缺失值分析-2"><a href="#百分比缺失值分析-2" class="headerlink" title="百分比缺失值分析"></a>百分比缺失值分析</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">num_rows = <span class="built_in">len</span>(df.index)</span><br><span class="line">cols_percentage = []</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    cnts = df[col].value_counts(dropna=<span class="literal">False</span>)</span><br><span class="line">    top_pct = (cnts / num_rows).iloc[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 99%的行是相同的特征值</span></span><br><span class="line">    <span class="keyword">if</span> top_pct &gt; <span class="number">0.99</span>:</span><br><span class="line">        cols_percentage.append(col)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#123;0&#125;: &#123;1:.5f&#125;%&#x27;</span>.<span class="built_in">format</span>(col, top_pct * <span class="number">100</span>))</span><br><span class="line">        <span class="built_in">print</span>(cnts)</span><br><span class="line">        <span class="built_in">print</span>()</span><br></pre></td></tr></table></figure>
<p><img src="/images/ml/ml_data_preprocess_pec2.png" width="300px" alt="" style="border:1px solid black"></img></p>
<p>上图展示了99%的行是相同值的特征，所以需要逐一查看这些变量，了解背后的原因，以确认这些特征是否提供有用信息，如果无法提供有用信息，便可丢弃该特征。</p>
<h4 id="重复行数据、关键特征重复行数据分析"><a href="#重复行数据、关键特征重复行数据分析" class="headerlink" title="重复行数据、关键特征重复行数据分析"></a>重复行数据、关键特征重复行数据分析</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># drop duplicates rows except id column</span></span><br><span class="line">df_dedupped = df.drop(<span class="string">&#x27;id&#x27;</span>, axis=<span class="number">1</span>).drop_duplicates()</span><br><span class="line"></span><br><span class="line"><span class="comment"># original datas</span></span><br><span class="line"><span class="built_in">print</span>(df.shape)</span><br><span class="line"><span class="comment"># dropped duplicates datas</span></span><br><span class="line"><span class="built_in">print</span>(df_dedupped.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(30471, 292)</span></span><br><span class="line"><span class="string">(30461, 291)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>可以看到除了id该列外（id自增，要先剔除掉），有10行数据为重复的，可以直接删除。</p>
<p>另外，还可以选中一组特征作为唯一标识符，然后基于这些特征检查是否存在复制数据。</p>
<h4 id="分析数据集不一致数据"><a href="#分析数据集不一致数据" class="headerlink" title="分析数据集不一致数据"></a>分析数据集不一致数据</h4><p>比如地名大小写不一致，应该全部转换为小写；时间格式不一致，可以统一转换为时间戳等；地址数据格式不一致等。</p>
<h3 id="数据预处理方法"><a href="#数据预处理方法" class="headerlink" title="数据预处理方法"></a>数据预处理方法</h3><p>参考《数据挖掘概念与技术：韩家炜》第三章数据预处理。</p>
<p><img src="/images/ml/ml_data_preprocess.png" width="400px" alt="" style="border:1px solid black"></img></p>
<h4 id="数据清理"><a href="#数据清理" class="headerlink" title="数据清理"></a>数据清理</h4><h5 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h5><ul>
<li><p>删除变量&#x2F;特征：缺失率较高（80%以上），且重要性较低，可以直接将变量&#x2F;特征删除。(删除行或列)</p>
</li>
<li><p>统计量填充：缺失率较低（小于95%），且重要性较低，可根据数据分布，采用中位数进行填补。</p>
</li>
<li><p>插值法填充：随机插值、多重插补法、拉格朗日插值、牛顿插值。</p>
</li>
<li><p>模型填充：回归、贝叶斯、随机森林、决策树等对缺失值进行预测。</p>
</li>
<li><p>哑变量填充：变量为离散且不同值较少，可转换为哑变量。</p>
</li>
</ul>
<h5 id="离散点处理"><a href="#离散点处理" class="headerlink" title="离散点处理"></a>离散点处理</h5><ul>
<li><p>简单统计分析：如上边用过的箱线图，可分析离散点是否存在，pandas的describe函数也可快速发现异常值。</p>
</li>
<li><p>3$\sigma$原则：当数据量（样本）足够大时，数据会存在正态分布（高斯分布）99.7%以上的数据会在3$\sigma$区间内，在3$\sigma$范围外的点为离散点。</p>
</li>
</ul>
<p>要根据实际情况考虑离散点的数量和影响，是否需要。</p>
<h4 id="数据集成"><a href="#数据集成" class="headerlink" title="数据集成"></a>数据集成</h4><p>数据集成将多个数据源中的数据结合合成，存放在一个一致的数据仓库。不同的数据源，在合并时，保持规范化、去重。</p>
<h4 id="数据变换（规范化处理）"><a href="#数据变换（规范化处理）" class="headerlink" title="数据变换（规范化处理）"></a>数据变换（规范化处理）</h4><h5 id="1）标准化（均值移除）"><a href="#1）标准化（均值移除）" class="headerlink" title="1）标准化（均值移除）"></a>1）标准化（均值移除）</h5><p><a href="http://deeplearner.top/2021/12/22/DeepLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-3-%E6%A6%82%E7%8E%87%E4%B8%8E%E4%BF%A1%E6%81%AF%E8%AE%BA/#%E6%9C%9F%E6%9C%9B%E3%80%81%E6%96%B9%E5%B7%AE%E5%92%8C%E5%8D%8F%E6%96%B9%E5%B7%AE">DeepLearning学习笔记-3-概率与信息论&#x2F;#期望、方差和协方差</a>已总结过知识点。代码举例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据预处理之：均值移除示例</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.preprocessing <span class="keyword">as</span> sp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 样本数据</span></span><br><span class="line">raw_samples = np.array([</span><br><span class="line">    [<span class="number">3.0</span>, -<span class="number">1.0</span>, <span class="number">2.0</span>],</span><br><span class="line">    [<span class="number">0.0</span>, <span class="number">4.0</span>, <span class="number">3.0</span>],</span><br><span class="line">    [<span class="number">1.0</span>, -<span class="number">4.0</span>, <span class="number">2.0</span>]</span><br><span class="line">])</span><br><span class="line"><span class="built_in">print</span>(raw_samples)</span><br><span class="line"><span class="built_in">print</span>(raw_samples.mean(axis=<span class="number">0</span>))  <span class="comment"># 求每列的平均值</span></span><br><span class="line"><span class="built_in">print</span>(raw_samples.std(axis=<span class="number">0</span>))  <span class="comment"># 求每列标准差</span></span><br><span class="line"></span><br><span class="line">std_samples = raw_samples.copy()  <span class="comment"># 复制样本数据</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> std_samples.T:  <span class="comment"># 遍历每列</span></span><br><span class="line">    col_mean = col.mean()  <span class="comment"># 计算平均数</span></span><br><span class="line">    col_std = col.std()  <span class="comment"># 求标准差</span></span><br><span class="line">    col -= col_mean  <span class="comment"># 减平均值</span></span><br><span class="line">    col /= col_std  <span class="comment"># 除标准差</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(std_samples)</span><br><span class="line"><span class="built_in">print</span>(std_samples.mean(axis=<span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(std_samples.std(axis=<span class="number">0</span>))</span><br></pre></td></tr></table></figure>

<p>通过sklearn提供sp.scale函数实现同样的功能，代码所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">std_samples = sp.scale(raw_samples) <span class="comment"># 求标准移除</span></span><br><span class="line"><span class="built_in">print</span>(std_samples)</span><br><span class="line"><span class="built_in">print</span>(std_samples.mean(axis=<span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(std_samples.std(axis=<span class="number">0</span>))</span><br></pre></td></tr></table></figure>

<h5 id="2）范围缩放"><a href="#2）范围缩放" class="headerlink" title="2）范围缩放"></a>2）范围缩放</h5><p>将样本矩阵中的每一列最小值和最大值设定为相同的区间，统一各特征值的范围.如有a, b, c三个数，其中b为最小值，c为最大值，则：<br>$$<br>a’ &#x3D; a - b<br>$$</p>
<p>$$<br>b’ &#x3D; b - b<br>$$</p>
<p>$$<br>c’ &#x3D; c - b<br>$$</p>
<p>缩放计算方式如下公式所示：</p>
<p>$$<br>a’’ &#x3D; a’ &#x2F; c’<br>$$</p>
<p>$$<br>b’’ &#x3D; b’ &#x2F; c’<br>$$</p>
<p>$$<br>c’’ &#x3D; c’ &#x2F; c’<br>$$</p>
<p>计算完成后，最小值为0，最大值为1.以下是一个范围缩放的示例.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据预处理之：范围缩放</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.preprocessing <span class="keyword">as</span> sp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 样本数据</span></span><br><span class="line">raw_samples = np.array([</span><br><span class="line">    [<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>],</span><br><span class="line">    [<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>],</span><br><span class="line">    [<span class="number">7.0</span>, <span class="number">8.0</span>, <span class="number">9.0</span>]]).astype(<span class="string">&quot;float64&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(raw_samples)</span></span><br><span class="line">mms_samples = raw_samples.copy()  <span class="comment"># 复制样本数据</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> mms_samples.T:</span><br><span class="line">    col_min = col.<span class="built_in">min</span>()</span><br><span class="line">    col_max = col.<span class="built_in">max</span>()</span><br><span class="line">    col -= col_min</span><br><span class="line">    col /= (col_max - col_min)</span><br><span class="line"><span class="built_in">print</span>(mms_samples)</span><br></pre></td></tr></table></figure>

<p>我们也可以通过sklearn提供的对象实现同样的功能，如下面代码所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据给定范围创建一个范围缩放器对象</span></span><br><span class="line">mms = sp.MinMaxScaler(feature_range=(<span class="number">0</span>, <span class="number">1</span>))<span class="comment"># 定义对象(修改范围观察现象)</span></span><br><span class="line"><span class="comment"># 使用范围缩放器实现特征值范围缩放</span></span><br><span class="line">mms_samples = mms.fit_transform(raw_samples) <span class="comment"># 缩放</span></span><br><span class="line"><span class="built_in">print</span>(mms_samples)</span><br></pre></td></tr></table></figure>

<p>执行结果：</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[[0.  0.  0. ]</span></span><br><span class="line"><span class="string"> [0.5 0.5 0.5]</span></span><br><span class="line"><span class="string"> [1.  1.  1. ]]</span></span><br><span class="line"><span class="string">[[0.  0.  0. ]</span></span><br><span class="line"><span class="string"> [0.5 0.5 0.5]</span></span><br><span class="line"><span class="string"> [1.  1.  1. ]]</span></span><br></pre></td></tr></table></figure>

<h5 id="3）归一化"><a href="#3）归一化" class="headerlink" title="3）归一化"></a>3）归一化</h5><p>为了统一量纲，将所有的特征都统一到大致相同的数值范围内。常用方法：</p>
<ul>
<li>Min-Max Scaling标准化：对原始数据进行线性变换，将结果映射到[0, 1]范围，实现对原始数据的等比缩放。</li>
<li>Z-Score Normalization标准化：将原始数据映射到均值为0、标准差为1的分布上，无量纲。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据预处理之：归一化</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.preprocessing <span class="keyword">as</span> sp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 样本数据</span></span><br><span class="line">raw_samples = np.array([[<span class="number">1.</span>, -<span class="number">1.</span>, <span class="number">2.</span>],</span><br><span class="line">                        [<span class="number">2.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">                        [<span class="number">0.</span>, <span class="number">1.</span>, -<span class="number">1.</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Min-Max-Scaling (0, 1)</span></span><br><span class="line">min_max_samples = sp.MinMaxScaler().fit_transform(raw_samples)</span><br><span class="line"><span class="built_in">print</span>(min_max_samples)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">[[0.5        0.         1.        ]</span></span><br><span class="line"><span class="string"> [1.         0.5        0.33333333]</span></span><br><span class="line"><span class="string"> [0.         1.         0.        ]]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Z-Score</span></span><br><span class="line">z_score_samples = sp.scale(raw_samples)</span><br><span class="line"><span class="built_in">print</span>(z_score_samples)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">[[ 0.         -1.22474487  1.33630621]</span></span><br><span class="line"><span class="string"> [ 1.22474487  0.         -0.26726124]</span></span><br><span class="line"><span class="string"> [-1.22474487  1.22474487 -1.06904497]]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 均值</span></span><br><span class="line"><span class="built_in">print</span>(z_score_samples.mean(axis=<span class="number">0</span>))</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">[0. 0. 0.]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 标准差</span></span><br><span class="line"><span class="built_in">print</span>(z_score_samples.std(axis=<span class="number">0</span>))</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">[1. 1. 1.]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p><font color="#ff0000">归一化适用的模型：通过梯度下降的模型通常需要归一化，包括线性模型、逻辑回归、支持向量机、神经网络等；决策树模型不适用归一化</font></p>
<h5 id="4）二值化"><a href="#4）二值化" class="headerlink" title="4）二值化"></a>4）二值化</h5><p>根据一个事先给定的阈值，用0和1来表示特征值是否超过阈值.以下是实现二值化预处理的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 二值化</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.preprocessing <span class="keyword">as</span> sp</span><br><span class="line"></span><br><span class="line">raw_samples = np.array([[<span class="number">65.5</span>, <span class="number">89.0</span>, <span class="number">73.0</span>],</span><br><span class="line">                        [<span class="number">55.0</span>, <span class="number">99.0</span>, <span class="number">98.5</span>],</span><br><span class="line">                        [<span class="number">45.0</span>, <span class="number">22.5</span>, <span class="number">60.0</span>]])</span><br><span class="line">bin_samples = raw_samples.copy()  <span class="comment"># 复制数组</span></span><br><span class="line"><span class="comment"># 生成掩码数组</span></span><br><span class="line">mask1 = bin_samples &lt; <span class="number">60</span></span><br><span class="line">mask2 = bin_samples &gt;= <span class="number">60</span></span><br><span class="line"><span class="comment"># 通过掩码进行二值化处理</span></span><br><span class="line">bin_samples[mask1] = <span class="number">0</span></span><br><span class="line">bin_samples[mask2] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(bin_samples)  <span class="comment"># 打印结果</span></span><br></pre></td></tr></table></figure>

<p>同样，也可以利用sklearn库来处理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">bin</span> = sp.Binarizer(threshold=<span class="number">59</span>) <span class="comment"># 创建二值化对象(注意边界值)</span></span><br><span class="line">bin_samples = <span class="built_in">bin</span>.transform(raw_samples) <span class="comment"># 二值化预处理</span></span><br><span class="line"><span class="built_in">print</span>(bin_samples)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[1. 1. 1.]</span></span><br><span class="line"><span class="string"> [0. 1. 1.]</span></span><br><span class="line"><span class="string"> [0. 0. 1.]]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>二值化编码会导致信息损失，是不可逆的数值转换.如果进行可逆转换，则需要用到独热编码.</p>
<h5 id="5）独热编码"><a href="#5）独热编码" class="headerlink" title="5）独热编码"></a>5）独热编码</h5><p><a href="http://deeplearner.top/2022/02/10/DeepLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-6-%E6%B7%B1%E5%BA%A6%E5%89%8D%E9%A6%88%E7%BD%91%E7%BB%9C/#One-hot%E7%BC%96%E7%A0%81">DeepLearning学习笔记-6-深度前馈网络&#x2F;#One-hot编码</a>已做过简单介绍。<br>根据一个特征中值的个数来建立一个由一个1和若干个0组成的序列，用来序列对所有的特征值进行编码.例如有如下样本：</p>
<p>$$\left[\begin{matrix}<br>    1 &amp; 3 &amp; 2 \\<br>    7 &amp; 5 &amp; 4 \\<br>    1 &amp; 8 &amp; 6 \\<br>    7 &amp; 3 &amp; 9 \\<br>\end{matrix}\right]$$</p>
<p>对于第一列，有两个值，1使用10编码，7使用01编码</p>
<p>对于第二列，有三个值，3使用100编码，5使用010编码，8使用001编码</p>
<p>对于第三列，有四个值，2使用1000编码，4使用0100编码，6使用0010编码，9使用0001编码</p>
<p>编码字段，根据特征值的个数来进行编码，通过位置加以区分.通过独热编码后的结果为：<br>$$\left[\begin{matrix}<br>    10 &amp; 100 &amp; 1000 \\<br>    01 &amp; 010 &amp; 0100 \\<br>    10 &amp; 001 &amp; 0010 \\<br>    01 &amp; 100  &amp; 0001 \\<br>\end{matrix}\right]$$<br>使用sklearn库提供的功能进行独热编码的代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 独热编码示例</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.preprocessing <span class="keyword">as</span> sp</span><br><span class="line"></span><br><span class="line">raw_samples = np.array([[<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>],</span><br><span class="line">                        [<span class="number">7</span>, <span class="number">5</span>, <span class="number">4</span>],</span><br><span class="line">                        [<span class="number">1</span>, <span class="number">8</span>, <span class="number">6</span>],</span><br><span class="line">                        [<span class="number">7</span>, <span class="number">3</span>, <span class="number">9</span>]])</span><br><span class="line"></span><br><span class="line">one_hot_encoder = sp.OneHotEncoder(</span><br><span class="line">    sparse=<span class="literal">False</span>, <span class="comment"># 是否采用稀疏格式</span></span><br><span class="line">    dtype=<span class="string">&quot;int32&quot;</span>,</span><br><span class="line">    categories=<span class="string">&quot;auto&quot;</span>)<span class="comment"># 自动编码</span></span><br><span class="line">oh_samples = one_hot_encoder.fit_transform(raw_samples) <span class="comment"># 执行独热编码</span></span><br><span class="line"><span class="built_in">print</span>(oh_samples)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(one_hot_encoder.inverse_transform(oh_samples)) <span class="comment"># 解码</span></span><br></pre></td></tr></table></figure>

<p>执行结果：</p>
<figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[[1<span class="number"> 0 </span>1<span class="number"> 0 </span>0<span class="number"> 1 </span>0<span class="number"> 0 </span>0]</span><br><span class="line"> [0<span class="number"> 1 </span>0<span class="number"> 1 </span>0<span class="number"> 0 </span>1<span class="number"> 0 </span>0]</span><br><span class="line"> [1<span class="number"> 0 </span>0<span class="number"> 0 </span>1<span class="number"> 0 </span>0<span class="number"> 1 </span>0]</span><br><span class="line"> [0<span class="number"> 1 </span>1<span class="number"> 0 </span>0<span class="number"> 0 </span>0<span class="number"> 0 </span>1]]</span><br><span class="line"> </span><br><span class="line">[[1<span class="number"> 3 </span>2]</span><br><span class="line"> [7<span class="number"> 5 </span>4]</span><br><span class="line"> [1<span class="number"> 8 </span>6]</span><br><span class="line"> [7<span class="number"> 3 </span>9]]</span><br></pre></td></tr></table></figure>

<h5 id="6）标签编码"><a href="#6）标签编码" class="headerlink" title="6）标签编码"></a>6）标签编码</h5><p>根据字符串形式的特征值在特征序列中的位置，来为其指定一个数字标签，用于提供给基于数值算法的学习模型.代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标签编码</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.preprocessing <span class="keyword">as</span> sp</span><br><span class="line"></span><br><span class="line">raw_samples = np.array([<span class="string">&#x27;audi&#x27;</span>, <span class="string">&#x27;ford&#x27;</span>, <span class="string">&#x27;audi&#x27;</span>,</span><br><span class="line">                        <span class="string">&#x27;bmw&#x27;</span>,<span class="string">&#x27;ford&#x27;</span>, <span class="string">&#x27;bmw&#x27;</span>])</span><br><span class="line"></span><br><span class="line">lb_encoder = sp.LabelEncoder() <span class="comment"># 定义标签编码对象</span></span><br><span class="line">lb_samples = lb_encoder.fit_transform(raw_samples) <span class="comment"># 执行标签编码</span></span><br><span class="line"><span class="built_in">print</span>(lb_samples)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lb_encoder.inverse_transform(lb_samples)) <span class="comment"># 逆向转换</span></span><br></pre></td></tr></table></figure>

<p>执行结果：</p>
<figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="name">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span>]</span><br><span class="line">[<span class="symbol">&#x27;audi</span>&#x27; <span class="symbol">&#x27;ford</span>&#x27; <span class="symbol">&#x27;audi</span>&#x27; <span class="symbol">&#x27;bmw</span>&#x27; <span class="symbol">&#x27;ford</span>&#x27; <span class="symbol">&#x27;bmw</span>&#x27;]</span><br></pre></td></tr></table></figure>

<h4 id="数据规约"><a href="#数据规约" class="headerlink" title="数据规约"></a>数据规约</h4><h5 id="维度规约"><a href="#维度规约" class="headerlink" title="维度规约"></a>维度规约</h5><p>将不相关的特征、属性删除，减少数据量的同时要保证损失最小。</p>
<h5 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h5><p>降维，并且要保证数据的信息完整性。方法有主成分分析（PCA）和因子分析（FA）；奇异值分解（SVD）；聚类；流形学习等。</p>
<h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><ul>
<li><font color="#ff0000">matplotlib&#x3D;&#x3D;3.5.0</font></li>
</ul>
</div><script type="text/javascript" src="../../../../js/share.js?v=1.0.0" async></script><a class="article-share-link" data-url="https://deeplearner.top/2022/10/23/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-2-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/" data-id="clkor69p3004dc6s6bpu73v13" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASYAAAEmCAAAAADqr2IGAAAEiUlEQVR42u3aS47bMBAFwLn/pR0gqwCJnfe65cTUlFaGxhbF4gBkf76+4uvx8/r18693Xn/n9/vPnvN4crWj/P79Z+9w8YUJEyZMmD6S6fHyek2Tv267GJulSt42nzsmTJgwYboH0+xx7fb/etz8KHDtwSVaMEyYMGHC9A2YksAygctB27B58ytMmDBhwoQpf8UELt/gZwuZh/SYMGHChOk7MOWPa7fY1xPIDwr5nTwN/ZZcOCZMmDBh+jCmWePOPT6/vb8JEyZMmDD9V6ZHeW3C47ZcmofNm3eLZo0JEyZMmI5lasPOtp20SKGOnpOE07OjT5QhwIQJEyZMH8+UtOO0E05Suski7VuL2nbVp++DCRMmTJgOZ8pfdFbm3Cdh22/OAu+nS4sJEyZMmI5lattc8u/k6dpNq81VTUXDEB0TJkyYMB3LNEvyXlXC3BwsZn04s3IsJkyYMGH6fKYk9ZlsyTO+fPS8qriheToiJkyYMGE6lul18XI2cF6GTNpG8yPLrHhZLC0mTJgwYTqQaROI1pF0eZiYpYmHrTmvlwETJkyYMB3OtGmgacPRJPi8KqxtjwJFkhcTJkyYMB3C1LbI5EHshvLfhMptOI0JEyZMmM5lendJsm3fmbEmz5m1+GDChAkTpnOZrm152bDmE06Kr23y+i93MGHChAnTsUxXBbSb8DhPts5aVzdHAUyYMGHCdDrTo7xmQey1BcvNdj5sA8KECRMmTMcy5Y0vSWj67uJiu0hf5YUJEyZMmO7K1KZ3Z002SSi7b9CZLXMS3mPChAkTptOZ8kRqG1LOKNtVzZt1VuNiwoQJE6ajmJIU5+tNetOysylb7jmKWWPChAkTppsyzRKj7avMxpot7fD5mDBhwoTpWKZ9wTLZpGcFzrxQOiuLtnPBhAkTJkwnMuXh4qYQmLS35hO4KvQtRsSECRMmTMcytRtnsgEnf20TvrMAuz00FM/EhAkTJkyHMLUFy9kBYlZizI8R9XYeH2IwYcKECdPpTHnpsQ0m2623PWpsfjU89GDChAkTpmOZ2sC1LQfOyo0Jaz7VZPmLdiJMmDBhwnQU0yxAvapvaBNO56F73u5zQfsOJkyYMGH6eKY2DXrtVNujRv7bthSKCRMmTJjuwZQM2QaZ+814E9bmZc58FpgwYcKE6USm/LXaNGteIEx+1T5ntv3XGWhMmDBhwnQUUxvctinX932+9s4f/ooJEyZMmG7HNCtStlPKk79XlU7bt8WECRMmTHdiSgLFR3nlydbNUs3KpQkcJkyYMGE6nWkG1GZH66TqaAtPWGcpb0yYMGHCdC7TbINvA9p2qvtWodm/wtO/YsKECROmY5k2vSsbsk3Zchbizj5jwoQJE6Z7MLWJ2rbl9KqQe3NAmTUkYcKECROmOzG1G3YbOr47TZzMYnYAwoQJEyZM34dpM2TbLrNvUc3nGM0UEyZMmDB9M6Y2FbvPQLch8QU0mDBhwoTpRkyzJO8mlM3bTGdb+z4ZfVkuHBMmTJgw/VemWePOBrQNWfMDRxsqf117YcKECROmz2L6AV3GV0hzk5dJAAAAAElFTkSuQmCC">分享</a><div class="tags"><a href="../../../../tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><i class="fa fa-tag"></i>机器学习笔记</a><a href="../../../../tags/%E5%91%A8%E5%BF%97%E5%8D%8E/"><i class="fa fa-tag"></i>周志华</a><a href="../../../../tags/%E5%90%B4%E6%81%A9%E8%BE%BE/"><i class="fa fa-tag"></i>吴恩达</a><a href="../../../../tags/%E6%9D%8E%E8%88%AA/"><i class="fa fa-tag"></i>李航</a></div><div class="post-nav"><a class="pre" href="../../25/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-3-%E5%9B%9E%E5%BD%92-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">MachineLearning-3.（回归）线性回归</a><a class="next" href="../../../06/14/MachineLearning%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0/">MachineLearning-1.机器学习概述</a></div><div class="nofancybox" id="waline"></div><script src="//unpkg.com/@waline/client@v2/dist/waline.js"></script><link rel="stylesheet" type="text/css" href="//unpkg.com/@waline/client@v2/dist/waline.css"><script>let metaInfo = ['nick', 'mail', 'link']
let requiredMeta = 'nick'.split(',').filter(item => {
  return metaInfo.indexOf(item) > -1
})
Waline.init({
  el: '#waline',
  comment: true,
  serverURL: 'https://waline-deeplearner.vercel.app',
  pageSize: '10',
  wordLimit: '500',
  requiredMeta,
})
</script></div></div></div><div class="pure-u-1 pure-u-md-1-4"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/images/blog/avatar_new.png"/></a><p>心外无物，知行合一</p><a class="info-icon" href="/resume/" title="个人简历" target="_blank" style="margin-inline:5px"> <i class="fa fa-share-square" style="margin-inline:5px"></i></a><a class="info-icon" href="mailto:conghaoyuan@gmail.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/conghaoyuan" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a><a class="info-icon" href="/atom.xml" title="RSS" target="_blank" style="margin-inline:5px"> <i class="fa fa-rss-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/AIGC/">AIGC</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Algorithm/">Algorithm</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/CV/">CV</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/GUI/">GUI</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/NLP/">NLP</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Python/">Python</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E5%AD%97%E4%BA%BA/">数字人</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E5%AD%A6/">数学</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/">深度学习框架</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B/">深度学习模型</a><span class="category-list-count">11</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="../../../../2025/03/10/AIGC-LLM-%E8%BE%9F%E9%82%AA%E5%89%91%E8%B0%B1%E4%B9%8B%E9%80%9A%E4%B9%89Prompt%E5%9B%9B%E5%8D%81%E5%BC%8F/">AIGC-LLM-辟邪剑谱之通义Prompt四十式</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2025/03/06/AIGC-LLM-%E8%BE%9F%E9%82%AA%E5%89%91%E8%B0%B1%E4%B9%8BPrompt%20Engineering/">AIGC-LLM-辟邪剑谱之Prompt Engineering</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/11/18/AIGC-Agent-%E4%BD%9C%E6%96%87%E6%89%B9%E6%94%B9%E6%A0%87%E6%B3%A8/">AIGC-Agent-作文批改标注</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/09/27/LLama32%E8%B0%83%E7%A0%94/">LLama3.2调研报告</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/04/09/AIGC-LLM-Prompt%E6%8A%80%E8%83%BD/">AIGC-LLM-Prompt工程技能综述</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/03/05/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-BERT/">Deeeplearning模型-NLP-BERT</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2024/01/16/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E8%AF%AD%E6%96%99%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7/">Deeeplearning模型-NLP-大语言模型微调语料生成工具</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/12/05/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-Transformer%E6%A8%A1%E5%9E%8B/">Deeeplearning模型-NLP-Transformer模型</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/12/01/Deeeplearning%E6%A8%A1%E5%9E%8B-NLP-NLP%E5%9F%BA%E7%A1%80/">Deeeplearning模型-NLP-NLP基础</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2023/10/26/%E6%95%B0%E5%AD%97%E4%BA%BA-%E6%95%B0%E5%AD%97%E4%BA%BA%E6%8A%80%E6%9C%AF%E6%95%88%E6%9E%9C%E5%AF%B9%E6%AF%94/">数字人-数字人技术效果对比</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://conghaoyuan.github.io" title="Fern[个人早期博客]" target="_blank">Fern[个人早期博客]</a></div><div class="widget"><div class="widget-title"><i class="fa fa-star"> 天文学</i></div><ul></ul><a href="/tools/tianwenli.html" title="天文历" target="_self">天文历</a></div><div class="widget"><div class="widget-title"><i class="fa fa-plus"> 数学小工具</i></div><ul></ul><a href="/tools/buy_house.html" title="丐版买房计算器" target="_self">丐版买房计算器</a><ul></ul><a href="/tools/equation_12.html" title="一元二次方程" target="_self">一元二次方程</a><ul></ul><a href="/tools/equation_line.html" title="直线方程" target="_self">直线方程</a><ul></ul><a href="/tools/equation_polynomial.html" title="多项式方程" target="_self">多项式方程</a><ul></ul><a href="/tools/regression_ridge.html" title="岭回归" target="_self">岭回归</a><ul></ul><a href="/tools/fourier_transform.html" title="傅里叶变换" target="_self">傅里叶变换</a><ul></ul><a href="/tools/gradient_descent.html" title="梯度下降" target="_self">梯度下降</a><ul></ul><a href="/tools/function_e.html" title="指数函数" target="_self">指数函数</a><ul></ul><a href="/tools/function_inverse_scale.html" title="反比例函数" target="_self">反比例函数</a><ul></ul><a href="/tools/function_log.html" title="对数函数" target="_self">对数函数</a><ul></ul><a href="/tools/function_sin.html" title="正弦函数" target="_self">正弦函数</a><ul></ul><a href="/tools/coord_grid.html" title="网格化坐标" target="_self">网格化坐标</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2025 <a href="../../../../." rel="nofollow">DeepLearner.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="../../../../js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="../../../../js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="../../../../css/search.css?v=1.0.0"><script type="text/javascript" src="../../../../js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="/static/js/MathJax.js?config=TeX-MML-AM_CHTML" async></script><div id="script" type="text/javascript" src="../../../../js/mathjaxs.js" async></div><script type="text/javascript" src="../../../../js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="../../../../js/smartresize.js?v=1.0.0"></script></div><!-- hexo injector body_end start -->
<script src="assets/prism-bundle.js"></script>
<script src="assets/prism-plus.js" data-pjax=""></script>
<!-- hexo injector body_end end --></body></html>